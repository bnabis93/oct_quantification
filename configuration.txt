# gen dice loss + aug / change lr
[raw data]
mode = test_train

# data folder
# inha oct 
[data paths]
# 5 class
#path_local =  ./data/hdf5_data/inha_oct_5classes/

#train
#train_imgs_original = inha_oct_5classes_train.hdf5
#train_groundTruth = inha_oct_5classes_groundTruth_train.hdf5

#resized train
#train_imgs_original = inha_oct_5classes_resized_train.hdf5
#train_groundTruth = inha_oct_5classes_resized_groundTruth_train.hdf5

#predict
#test_imgs_original = inha_oct_5classes_test.hdf5


# 2class bmo lc
path_local =  ./data/hdf5_data/inha_oct/train/

#train
train_imgs_original = fine_seg_180_train.hdf5
train_groundTruth = fine_seg_180_groundTruth_train.hdf5

#predict
#test_imgs_original =64_test_lc_patch.hdf5
#test_imgs_original =64_test_bmo_patch.hdf5
test_imgs_original =yolo_bmo.hdf5


[experiment name]
result_save_path = result
name = 20_0621_fine_segmentor_180_Data_focal_gamma_07

[data attributes]
#Dimensions of the patches extracted from the full imagess
patch_height = 64
patch_width = 64


[training settings]
#number of total patches:
num_subimgs = 240000

#if patches are extracted only inside the field of view:
inside_FOV = False

#Number of training epochs
num_epochs = 200
batch_size = 16

#if running with nohup
nohup = True



[testing settings]
#Choose the model to test: best==epoch with min loss, last==last epoch
# mode => over_train or test
# best_last => choice your model weights (best? last?)
mode = test
best_last = best

#number of full images for the test (max 20, DRIVE datasets)
full_images_to_test = 20

#How many original-groundTruth-prediction images are visualized in each image
num_group_visual = 1

#Compute average in the prediction, improve results but require more patches to be predicted
average_mode = False
#Only if average_mode==True. Stride for patch extraction, lower value require more patches to be predicted
stride_height = 20
stride_width = 20
#if running with nohup
nohup = False
