{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"2stage_model.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Stage model test  \n",
    "This .ipynb is test for 2 stage model  \n",
    "\n",
    "#### 1. Load yolo output\n",
    "- Input : yolo format txt results (class xmin ymin xmax ymax)\n",
    "- Description : \n",
    "    - load yolo txt information and interpretation\n",
    "    - classify bmo and lc and load images\n",
    "    - make array and padding for fitted segmentor input\n",
    "- Output : padded yolo results array, padding information\n",
    "\n",
    "#### 2. Inference fine segmentor\n",
    "- Input : padded yolo results array\n",
    "- Description : \n",
    "    - overlap-tile inference\n",
    "    - reconstruction images\n",
    "- Output : Inferenced bmo, lc patch coordinate\n",
    "\n",
    "#### 3. Reconstruction on test images\n",
    "- Input : Inferenced bmo, lc patch coordinate, padding information\n",
    "- Description : reconstruction images using coordinate info and padding info\n",
    "- Output : Save reconstrcted images \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load yolo output\n",
    "- Input : yolo format txt results (class xmin ymin xmax ymax)\n",
    "- Description : \n",
    "    - load yolo txt information and interpretation\n",
    "    - classify bmo and lc and load images\n",
    "    - make array and padding for fitted segmentor input\n",
    "- Output : padded yolo results array, padding information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "\n",
    "#if not sys.warnoptions:\n",
    "#    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import configparser\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "\n",
    "sys.path.insert(0, './lib_keras/')\n",
    "from help_functions import *\n",
    "\n",
    "VALID_TEST = 'valid'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_imgs(yolo_img_path,num_imgs,shape_imgs):\n",
    "    img_h, img_w = shape_imgs[0], shape_imgs[1]\n",
    "    yolo_imgs = np.zeros((num_imgs, img_h, img_w,3),dtype=np.uint8)    \n",
    "    idx =0 \n",
    "    \n",
    "    for count, filename in enumerate(sorted(os.listdir(yolo_img_path)), start=0):\n",
    "        if filename.startswith(\".ipynb\") == False:\n",
    "            temp = cv2.imread(yolo_img_path + filename)\n",
    "            yolo_imgs[idx] = temp.astype(np.uint8)\n",
    "            idx = idx+1\n",
    "            \n",
    "    return yolo_imgs  \n",
    "    \n",
    "def load_and_classify_yolo_txt(yolo_txt_path):\n",
    "    yolo_table = pd.DataFrame(columns=['lc_xmin', 'lc_ymin', 'lc_xmax', 'lc_ymax',\n",
    "                                       'bmo1_xmin', 'bmo1_ymin', 'bmo1_xmax', 'bmo1_ymax',\n",
    "                                      'bmo2_xmin', 'bmo2_ymin', 'bmo2_xmax', 'bmo2_ymax'])\n",
    "\n",
    "    for count, filename in enumerate(sorted(os.listdir(yolo_txt_path)), start=0):\n",
    "        if filename.startswith(\".ipynb\") == False:\n",
    "            txt_data = pd.read_csv(yolo_txt_path + filename, sep=\"\\n\", header=None)\n",
    "            txt_info_01 = (txt_data.loc[0])[0].split(' ')\n",
    "            txt_info_02 = (txt_data.loc[1])[0].split(' ')\n",
    "            txt_info_03 = (txt_data.loc[2])[0].split(' ')\n",
    "            \n",
    "            yolo_table.loc[count, 'lc_xmin'] = int(txt_info_01[2])\n",
    "            yolo_table.loc[count, 'lc_ymin'] = int(txt_info_01[3])\n",
    "            yolo_table.loc[count, 'lc_xmax'] = int(txt_info_01[4])\n",
    "            yolo_table.loc[count, 'lc_ymax'] = int(txt_info_01[5])\n",
    "            \n",
    "            yolo_table.loc[count, 'bmo1_xmin'] = int(txt_info_02[2])\n",
    "            yolo_table.loc[count, 'bmo1_ymin'] = int(txt_info_02[3])\n",
    "            yolo_table.loc[count, 'bmo1_xmax'] = int(txt_info_02[4])\n",
    "            yolo_table.loc[count, 'bmo1_ymax'] = int(txt_info_02[5])\n",
    "            \n",
    "            yolo_table.loc[count, 'bmo2_xmin'] = int(txt_info_03[2])\n",
    "            yolo_table.loc[count, 'bmo2_ymin'] = int(txt_info_03[3])\n",
    "            yolo_table.loc[count, 'bmo2_xmax'] = int(txt_info_03[4])\n",
    "            yolo_table.loc[count, 'bmo2_ymax'] = int(txt_info_03[5])\n",
    "                                  \n",
    "    return yolo_table\n",
    "\n",
    "def count_num_files(FILE_PATH):\n",
    "    num_files = 0\n",
    "    for count, filename in enumerate(sorted(os.listdir(FILE_PATH)), start=0):\n",
    "        if filename.startswith(\".ipynb\") == False:\n",
    "            num_files = num_files+1\n",
    "    return num_files\n",
    "\n",
    "def get_shape_of_imgs(SEG_PATH):\n",
    "    for count, filename in enumerate(sorted(os.listdir(SEG_PATH)), start=0):\n",
    "        if filename.startswith(\".ipynb\") == False:\n",
    "            temp_imgs = cv2.imread(SEG_PATH + filename)\n",
    "            return np.shape(temp_imgs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 760, 3)\n",
      "(20, 500, 760, 3)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparam, constant\n",
    "\n",
    "if VALID_TEST == 'valid':\n",
    "    YOLO_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/pred_fine_test/'\n",
    "    YOLO_TXT_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/pred_fine_testTxt/'\n",
    "    ORI_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/fine_test/'\n",
    "    GROUND_TRUTH_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/fine_test_label/'\n",
    "    INFERENCE_SHAPE  = (64,64)\n",
    "\n",
    "    '''\n",
    "    Clinical test\n",
    "    '''\n",
    "    #YOLO_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/ambi_test_0709/'\n",
    "    #YOLO_TXT_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/ambi_test_txt_0709/'\n",
    "    #ORI_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/Final_clinical/ambiguos/'\n",
    "    #GROUND_TRUTH_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/Final_clinical/ambiguos_label/'\n",
    "\n",
    "    #YOLO_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/test_0709/'\n",
    "    #YOLO_TXT_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/test_txt_0709/'\n",
    "    #ORI_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/Final_clinical/final_fine_clinical_test/'\n",
    "    #GROUND_TRUTH_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/Final_clinical/final_fine_clinical_label/'\n",
    "\n",
    "    #latest\n",
    "    #YOLO_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/best_0709/'\n",
    "    #YOLO_TXT_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/best_txt_0709/'\n",
    "    #ORI_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/Final_clinical/best_0709/'\n",
    "    #GROUND_TRUTH_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/Final_clinical/best_label_0709/'\n",
    "\n",
    "    #YOLO_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/test/'\n",
    "    #YOLO_TXT_PATH = '/home/bono/Desktop/mellab_project/bono_hw/keras-yolo3/test/clinical_data/test_txt/'\n",
    "    #ORI_IMG_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/fine_clinical_test/'\n",
    "    #GROUND_TRUTH_PATH = '/home/bono/Desktop/mellab_project/bono_hw/oct_segmentation/data/fine_segmentor_data/fine_clinical_test_label/'\n",
    "\n",
    "    # processing\n",
    "    NUM_YOLO_RESULT = count_num_files(YOLO_IMG_PATH)\n",
    "    SHAPE_YOLO_RESULT = get_shape_of_imgs(YOLO_IMG_PATH)\n",
    "    print(SHAPE_YOLO_RESULT)\n",
    "    YOLO_IMGS = load_yolo_imgs(YOLO_IMG_PATH, NUM_YOLO_RESULT, SHAPE_YOLO_RESULT) \n",
    "    ORI_IMGS = load_yolo_imgs(ORI_IMG_PATH, NUM_YOLO_RESULT, SHAPE_YOLO_RESULT)\n",
    "\n",
    "    YOLO_RESULT_TABLE = load_and_classify_yolo_txt(YOLO_TXT_PATH)\n",
    "    BMO_GROUND_TRUTH_IMGS = load_yolo_imgs(GROUND_TRUTH_PATH, NUM_YOLO_RESULT,SHAPE_YOLO_RESULT )\n",
    "\n",
    "    # Result image (BMO + LC, 3ch)\n",
    "    RESULT_IMGS = ORI_IMGS.copy()\n",
    "    RESULT_IMGS_MASKS = np.zeros((NUM_YOLO_RESULT, SHAPE_YOLO_RESULT[0], SHAPE_YOLO_RESULT[1], SHAPE_YOLO_RESULT[2]), dtype=np.uint16)\n",
    "\n",
    "    # BMO -> Center points (255,0,0)\n",
    "    # LC -> fitted curve (0,255,0)\n",
    "    print(np.shape(ORI_IMGS))\n",
    "    \n",
    "elif VALID_TEST == 'test':\n",
    "    file_num = \"050\"\n",
    "    YOLO_IMG_PATH =  '/home/bono/Desktop/mellab_project/data/set1_inhaHos/detect_result/' + file_num +'/'+'detect'+'/'\n",
    "    YOLO_TXT_PATH =  '/home/bono/Desktop/mellab_project/data/set1_inhaHos/detect_result/'+ file_num +'/'+'detect_txt'+'/'\n",
    "    ORI_IMG_PATH =  '/home/bono/Desktop/mellab_project/data/set1_inhaHos/proc_data/' + file_num +'/'\n",
    "    \n",
    "    INFERENCE_SHAPE  = (64,64)\n",
    "    \n",
    "    # processing\n",
    "    NUM_YOLO_RESULT = count_num_files(YOLO_IMG_PATH)\n",
    "    SHAPE_YOLO_RESULT = get_shape_of_imgs(YOLO_IMG_PATH)\n",
    "    print(SHAPE_YOLO_RESULT)\n",
    "    YOLO_IMGS = load_yolo_imgs(YOLO_IMG_PATH, NUM_YOLO_RESULT, SHAPE_YOLO_RESULT) \n",
    "    ORI_IMGS = load_yolo_imgs(ORI_IMG_PATH, NUM_YOLO_RESULT, SHAPE_YOLO_RESULT)\n",
    "\n",
    "    YOLO_RESULT_TABLE = load_and_classify_yolo_txt(YOLO_TXT_PATH)\n",
    "\n",
    "    # Result image (BMO + LC, 3ch)\n",
    "    RESULT_IMGS = ORI_IMGS.copy()\n",
    "    RESULT_IMGS_MASKS = np.zeros((NUM_YOLO_RESULT, SHAPE_YOLO_RESULT[0], SHAPE_YOLO_RESULT[1], SHAPE_YOLO_RESULT[2]), dtype=np.uint16)\n",
    "\n",
    "    # BMO -> Center points (255,0,0)\n",
    "    # LC -> fitted curve (0,255,0)\n",
    "    print(np.shape(ORI_IMGS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO_RESULT_TABLE Inference fine segmentor\n",
    "- Input : padded yolo results array\n",
    "- Description : \n",
    "    - bmo -> center crop (64 x 64)\n",
    "    - lc -> overlap-tile 이용해야할듯\n",
    "    - overlap-tile inference\n",
    "    - reconstruction images\n",
    "- Output : Inferenced bmo, lc patch coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMO processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./result/20_0621_fine_segmentor_180_Data_focal_gamma_07\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('configuration.txt')\n",
    "name_experiment = config.get('experiment name', 'name')\n",
    "path_experiment = './'+'result/'+ name_experiment\n",
    "best_last = config.get('testing settings', 'best_last')\n",
    "model = model_from_json(open(path_experiment+'/'+ name_experiment +'_architecture.json').read())\n",
    "print(path_experiment)\n",
    "model.load_weights(path_experiment+'/'+best_last+'_weights.h5')\n",
    "\n",
    "def bmo_centerCrop_patch(ori_imgs,num_imgs, patch_shape ,yolo_table, save_folder, debug_flag):\n",
    "    bmo01_patch = np.zeros((num_imgs, patch_shape[0], patch_shape[1], 1))\n",
    "    bmo02_patch = np.zeros((num_imgs, patch_shape[0], patch_shape[1], 1))\n",
    "    \n",
    "    bmo01_init_points_info = []\n",
    "    bmo02_init_points_info = []\n",
    "    \n",
    "    print('shape ori imgs : {} shape patch01 : {} shape patch02 : {}'.format(np.shape(ori_imgs), \n",
    "                                                                             np.shape(bmo01_patch),\n",
    "                                                                            np.shape(bmo02_patch)))\n",
    "    \n",
    "    for idx in range(num_imgs):\n",
    "        bmo01_xmin = yolo_table.iloc[idx]['bmo1_xmin'].astype(int)\n",
    "        bmo01_ymin = yolo_table.iloc[idx]['bmo1_ymin'].astype(int)\n",
    "        bmo01_xmax = yolo_table.iloc[idx]['bmo1_xmax'].astype(int)\n",
    "        bmo01_ymax = yolo_table.iloc[idx]['bmo1_ymax'].astype(int)\n",
    "        bmo01_center_x = int((bmo01_xmax + bmo01_xmin)/2) ;bmo01_center_y = int((bmo01_ymax + bmo01_ymin)/2)\n",
    "        #print('bmo01 center x : {} bmo01 center y : {}'.format(bmo01_center_x, bmo01_center_y))\n",
    "        \n",
    "        bmo02_xmin = yolo_table.iloc[idx]['bmo2_xmin'].astype(int)\n",
    "        bmo02_ymin = yolo_table.iloc[idx]['bmo2_ymin'].astype(int)\n",
    "        bmo02_xmax = yolo_table.iloc[idx]['bmo2_xmax'].astype(int)\n",
    "        bmo02_ymax = yolo_table.iloc[idx]['bmo2_ymax'].astype(int)\n",
    "        bmo02_center_x = int((bmo02_xmax + bmo02_xmin)/2) ;bmo02_center_y = int((bmo02_ymax + bmo02_ymin)/2)\n",
    "        #print('bmo01 center x : {} bmo01 center y : {}'.format(bmo02_center_x, bmo02_center_y))\n",
    "        bmo01_init_points_info.append((bmo01_center_y-32,bmo01_center_x-32 ))\n",
    "        bmo02_init_points_info.append((bmo02_center_y-32,bmo02_center_x-32 ))\n",
    "        \n",
    "        ori_bmo01_crop = ori_imgs[idx, bmo01_center_y-32 : bmo01_center_y+32, bmo01_center_x-32 : bmo01_center_x+32,0]\n",
    "        ori_bmo02_crop = ori_imgs[idx, bmo02_center_y-32 : bmo02_center_y+32, bmo02_center_x-32 : bmo02_center_x+32,0]\n",
    "        \n",
    "        ori_bmo01_crop = np.expand_dims(ori_bmo01_crop,-1)\n",
    "        ori_bmo02_crop = np.expand_dims(ori_bmo02_crop,-1)\n",
    "        \n",
    "        bmo01_patch[idx] = ori_bmo01_crop\n",
    "        bmo02_patch[idx] = ori_bmo02_crop\n",
    "        \n",
    "        if debug_flag == True:\n",
    "            copy_img = ori_imgs[idx].copy()\n",
    "            \n",
    "            tempRC01 = tuple([bmo01_center_x-32,bmo01_center_y-32])\n",
    "            tempRC02 = tuple([bmo02_center_x-32,bmo02_center_y-32])\n",
    "            \n",
    "            cv2.circle(copy_img,tempRC01, 3,(0,0,255))\n",
    "            cv2.circle(copy_img,tempRC02, 3,(0,0,255))\n",
    "            \n",
    "            cv2.imwrite(save_folder+'center_crop_debug_'+str(idx)+'_.png', copy_img)\n",
    "\n",
    "        \n",
    "    return bmo01_patch, bmo02_patch, bmo01_init_points_info, bmo02_init_points_info\n",
    "\n",
    "def bmo_groundTruth_patch(gt_imgs,num_imgs, patch_shape ,yolo_table, save_folder, debug_flag):\n",
    "    #ori_img = ground_Truth\n",
    "    left_bmo_patch = np.zeros((num_imgs, patch_shape[0], patch_shape[1], 1))\n",
    "    right_bmo_patch = np.zeros((num_imgs, patch_shape[0], patch_shape[1], 1))\n",
    "    \n",
    "    left_bmo_init_points_info = []\n",
    "    right_bmo_init_points_info = []\n",
    "    \n",
    "    print('shape ori imgs : {} shape patch01 : {} shape patch02 : {}'.format(np.shape(gt_imgs), \n",
    "                                                                             np.shape(left_bmo_patch),\n",
    "                                                                            np.shape(right_bmo_patch)))\n",
    "\n",
    "    for idx in range(num_imgs):\n",
    "        bmo01_xmin = yolo_table.iloc[idx]['bmo1_xmin'].astype(int)\n",
    "        bmo01_ymin = yolo_table.iloc[idx]['bmo1_ymin'].astype(int)\n",
    "        bmo01_xmax = yolo_table.iloc[idx]['bmo1_xmax'].astype(int)\n",
    "        bmo01_ymax = yolo_table.iloc[idx]['bmo1_ymax'].astype(int)\n",
    "        bmo01_center_x = int((bmo01_xmax + bmo01_xmin)/2) ;bmo01_center_y = int((bmo01_ymax + bmo01_ymin)/2)\n",
    "        #print('bmo01 center x : {} bmo01 center y : {}'.format(bmo01_center_x, bmo01_center_y))\n",
    "        \n",
    "        bmo02_xmin = yolo_table.iloc[idx]['bmo2_xmin'].astype(int)\n",
    "        bmo02_ymin = yolo_table.iloc[idx]['bmo2_ymin'].astype(int)\n",
    "        bmo02_xmax = yolo_table.iloc[idx]['bmo2_xmax'].astype(int)\n",
    "        bmo02_ymax = yolo_table.iloc[idx]['bmo2_ymax'].astype(int)\n",
    "        bmo02_center_x = int((bmo02_xmax + bmo02_xmin)/2) ;bmo02_center_y = int((bmo02_ymax + bmo02_ymin)/2)\n",
    "        #print('bmo01 center x : {} bmo01 center y : {}'.format(bmo02_center_x, bmo02_center_y))\n",
    "        \n",
    "        \n",
    "        if bmo01_xmin > bmo02_xmin:\n",
    "            print('reverse! : {} and {}'.format(bmo01_xmin, bmo02_xmin))\n",
    "            left_bmo_init_points_info.append((bmo02_center_y-32,bmo02_center_x-32 ))\n",
    "            right_bmo_init_points_info.append((bmo01_center_y-32,bmo01_center_x-32 ))\n",
    "        else:\n",
    "            left_bmo_init_points_info.append((bmo01_center_y-32,bmo01_center_x-32 ))\n",
    "            right_bmo_init_points_info.append((bmo02_center_y-32,bmo02_center_x-32 ))\n",
    "        \n",
    "        ori_bmo01_crop = gt_imgs[idx, bmo01_center_y-32 : bmo01_center_y+32, bmo01_center_x-32 : bmo01_center_x+32,2]\n",
    "        ori_bmo02_crop = gt_imgs[idx, bmo02_center_y-32 : bmo02_center_y+32, bmo02_center_x-32 : bmo02_center_x+32,2]\n",
    "        ori_bmo01_crop = np.expand_dims(ori_bmo01_crop,-1)\n",
    "        ori_bmo02_crop = np.expand_dims(ori_bmo02_crop,-1)\n",
    "        \n",
    "        left_bmo_patch[idx] = ori_bmo01_crop\n",
    "        right_bmo_patch[idx] = ori_bmo02_crop\n",
    "        \n",
    "        if bmo01_xmin > bmo02_xmin:\n",
    "            left_bmo_patch[idx] = ori_bmo02_crop\n",
    "            right_bmo_patch[idx] = ori_bmo01_crop\n",
    "        \n",
    "        if debug_flag == True:\n",
    "            #copy_img = gt_imgs[idx].copy()\n",
    "            cv2.imwrite(save_folder+'gt_left_crop_debug_'+str(idx)+'_.png', left_bmo_patch[idx])\n",
    "            cv2.imwrite(save_folder+'gt_right_crop_debug_'+str(idx)+'_.png', right_bmo_patch[idx])\n",
    "        \n",
    "    return left_bmo_patch, right_bmo_patch, left_bmo_init_points_info, right_bmo_init_points_info\n",
    "\n",
    "def decoding(labels,class_num):\n",
    "    '''\n",
    "    input : patchs (ch first images)\n",
    "            (ch, H, W)\n",
    "    \n",
    "    mapping example : \n",
    "        mapping = {\n",
    "            (0,0,0) : 0,\n",
    "            (255,0,0) : 1,\n",
    "            (0,0,255) : 2\n",
    "            }\n",
    "    \n",
    "    return patches (num, class-1,H, W)\n",
    "    '''\n",
    "    #print('[ch-wise one hot encoding] label shape : ', np.shape(labels))\n",
    "    c, h, w = labels.shape\n",
    "    decoded_labels = np.zeros((h,w,3)) # RGB format\n",
    "    \n",
    "    ch_cnt =0 \n",
    "    temp_label = np.transpose(labels, (1,2,0))\n",
    "    #print(np.shape(temp_label))\n",
    "\n",
    "    '''\n",
    "    mapping 순서 이슈\n",
    "    '''\n",
    "    #print('[ch wise one hot] shape label : ', np.shape(temp_label))\n",
    "    #print('[ch wise one hot] shape encoded label : ',np.shape(encoded_labels))\n",
    "    for k in range(class_num):\n",
    "        '''\n",
    "        temp label\n",
    "            (H,W)\n",
    "        '''\n",
    "        row,col = np.nonzero(temp_label[:,:,k])\n",
    "        #print(len(row))\n",
    "        if k==0:\n",
    "            class_01_info = (row, col)\n",
    "        elif k==1:\n",
    "            class_02_info = (row, col)\n",
    "            \n",
    "    decoded_labels[class_01_info] = (255,0,0)\n",
    "    decoded_labels[class_02_info] = (0,255,0)\n",
    "    \n",
    "    return decoded_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_experiment = 'final_paper_debug/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist the folder in this path : ./pipe_result/final_paper_debug//\n",
      "already exist the folder in this path : ./pipe_result/final_paper_debug//\n",
      "already exist the folder in this path : ./pipe_result/final_paper_debug//center_crop/\n",
      "already exist the folder in this path : ./pipe_result/final_paper_debug//bmo_patch/\n",
      "shape ori imgs : (20, 500, 760, 3) shape patch01 : (20, 64, 64, 1) shape patch02 : (20, 64, 64, 1)\n",
      "shape ori imgs : (20, 500, 760, 3) shape patch01 : (20, 64, 64, 1) shape patch02 : (20, 64, 64, 1)\n",
      "reverse! : 396 and 237\n",
      "reverse! : 523 and 402\n",
      "reverse! : 610 and 488\n",
      "reverse! : 513 and 316\n",
      "reverse! : 431 and 293\n",
      "reverse! : 371 and 205\n",
      "reverse! : 499 and 344\n",
      "reverse! : 469 and 295\n",
      "reverse! : 351 and 217\n",
      "reverse! : 449 and 311\n",
      "reverse! : 532 and 383\n",
      "reverse! : 344 and 211\n",
      "pred bmo shape :  (20, 4096, 3)\n",
      "pred imgs shape :  (20, 4096, 2)\n",
      "pred imgs shape :  (20, 4096, 2)\n",
      "pred bmo shape :  (20, 2, 64, 64)\n",
      "pred imgs shape :  (20, 4096, 2)\n",
      "pred imgs shape :  (20, 4096, 2)\n"
     ]
    }
   ],
   "source": [
    "# hyperparam\n",
    "dir_checker('./pipe_result/'+str(name_experiment)+'/')\n",
    "debug_flag = True\n",
    "save_folder2 = './pipe_result/'+str(name_experiment)+'/center_crop/'\n",
    "save_folder = './pipe_result/'+str(name_experiment)+'/'\n",
    "dir_checker(save_folder)\n",
    "dir_checker(save_folder2)\n",
    "\n",
    "save_bmo_result = 'bmo_patch/'\n",
    "dir_checker(save_folder + save_bmo_result)\n",
    "N_visual = int(config.get('testing settings', 'num_group_visual'))\n",
    "\n",
    "# bmo processing\n",
    "bmo01_patch, bmo02_patch, BMO01_INIT_POINTS, BMO02_INIT_POINTS= bmo_centerCrop_patch(ORI_IMGS,NUM_YOLO_RESULT, INFERENCE_SHAPE, YOLO_RESULT_TABLE,\n",
    "                                                                                    save_folder2 ,debug_flag)\n",
    "\n",
    "if VALID_TEST == 'valid':\n",
    "    left_bmoGT_patch, right_bmoGT_patch, L_BMO_GT_INIT_POINTS, R_BMO_GT_INIT_POINTS= bmo_groundTruth_patch(BMO_GROUND_TRUTH_IMGS,NUM_YOLO_RESULT, INFERENCE_SHAPE, YOLO_RESULT_TABLE,\n",
    "                                                                                    save_folder2 ,debug_flag)\n",
    "\n",
    "if debug_flag == True:\n",
    "    for idx in range(np.shape(bmo01_patch)[0]):\n",
    "        cv2.imwrite(save_folder + save_bmo_result +'bmo01_patch_'+str(idx)+'_.png', bmo01_patch[idx])\n",
    "        cv2.imwrite(save_folder + save_bmo_result +'bmo02_patch_'+str(idx)+'_.png', bmo02_patch[idx])\n",
    "\n",
    "bmo01_patch = np.transpose(bmo01_patch, (0,3,1,2)); bmo02_patch = np.transpose(bmo02_patch, (0,3,1,2))\n",
    "bmo01_patch = bmo01_patch /255.0 ; bmo02_patch = bmo02_patch/255.0\n",
    "\n",
    "predictions_bmo01 = model.predict(bmo01_patch, batch_size=64, verbose=2)\n",
    "predictions_bmo02 = model.predict(bmo02_patch, batch_size=64, verbose=2)\n",
    "\n",
    "print('pred bmo shape : ',np.shape(predictions_bmo01))\n",
    "\n",
    "pred_patches_bmo01 = pred_to_imgs(predictions_bmo01, INFERENCE_SHAPE[0], INFERENCE_SHAPE[1], \"original\")\n",
    "pred_patches_bmo02 = pred_to_imgs(predictions_bmo02, INFERENCE_SHAPE[0], INFERENCE_SHAPE[1], \"original\")\n",
    "\n",
    "print('pred bmo shape : ',np.shape(pred_patches_bmo01))\n",
    "\n",
    "\n",
    "pred_patches_thr_bmo01 = pred_to_imgs(predictions_bmo01, INFERENCE_SHAPE[0], INFERENCE_SHAPE[1], \"threshold\")\n",
    "pred_patches_thr_bmo02 = pred_to_imgs(predictions_bmo02, INFERENCE_SHAPE[0], INFERENCE_SHAPE[1], \"threshold\")\n",
    "\n",
    "pred_imgs_bmo01_class01 = pred_patches_bmo01[:,0]; pred_imgs_bmo01_class01 = np.expand_dims(pred_imgs_bmo01_class01, 1)\n",
    "pred_imgs_bmo01_class02 = pred_patches_bmo01[:,1]; pred_imgs_bmo01_class02 = np.expand_dims(pred_imgs_bmo01_class02, 1)\n",
    "\n",
    "pred_thr_bmo01_class01 = pred_patches_thr_bmo01[:,0]; pred_thr_bmo01_class01 = np.expand_dims(pred_thr_bmo01_class01, 1)\n",
    "pred_thr_bmo01_class02 = pred_patches_thr_bmo01[:,1]; pred_thr_bmo01_class02 = np.expand_dims(pred_thr_bmo01_class02, 1)\n",
    "\n",
    "pred_imgs_bmo02_class01 = pred_patches_bmo02[:,0]; pred_imgs_bmo02_class01 = np.expand_dims(pred_imgs_bmo02_class01, 1)\n",
    "pred_imgs_bmo02_class02 = pred_patches_bmo02[:,1]; pred_imgs_bmo02_class02 = np.expand_dims(pred_imgs_bmo02_class02, 1)\n",
    "\n",
    "pred_thr_bmo02_class01 = pred_patches_thr_bmo02[:,0]; pred_thr_bmo02_class01 = np.expand_dims(pred_thr_bmo02_class01, 1)\n",
    "pred_thr_bmo02_class02 = pred_patches_thr_bmo02[:,1]; pred_thr_bmo02_class02 = np.expand_dims(pred_thr_bmo02_class02, 1)\n",
    "\n",
    "\n",
    "if debug_flag == True:\n",
    "    visualize(group_images(pred_imgs_bmo01_class01,N_visual),save_folder+\"bmo01_class01\")#.show()\n",
    "    visualize(group_images(pred_imgs_bmo01_class02,N_visual),save_folder+\"bmo01_class02\")#.show()\n",
    "    visualize(group_images(pred_thr_bmo01_class01,N_visual),save_folder+\"thr_bmo01_class01\")#.show()\n",
    "    visualize(group_images(pred_thr_bmo01_class02,N_visual),save_folder+\"thr_bmo01_class02\")#.show()\n",
    "    \n",
    "    visualize(group_images(pred_imgs_bmo02_class01,N_visual),save_folder+\"bmo02_class01\")#.show()\n",
    "    visualize(group_images(pred_imgs_bmo02_class02,N_visual),save_folder+\"bmo02_class02\")#.show()\n",
    "    visualize(group_images(pred_thr_bmo02_class01,N_visual),save_folder+\"thr_bmo02_class01\")#.show()\n",
    "    visualize(group_images(pred_thr_bmo02_class02,N_visual),save_folder+\"thr_bmo02_class02\")#.show()\n",
    "\n",
    "    for i in range(pred_patches_bmo01.shape[0]):\n",
    "        cv2.imwrite(save_folder+'pred_thr_bmo01_'+str(i)+'_.png', decoding(pred_patches_thr_bmo01[i],pred_patches_bmo01.shape[1]))\n",
    "        cv2.imwrite(save_folder+'pred_thr_bmo02_'+str(i)+'_.png', decoding(pred_patches_thr_bmo02[i],pred_patches_bmo01.shape[1]))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMO \n",
    "Bmo processing scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmo_max_connected_components(bmo_patches, num_img, shape_img, save_folder, debug_flag):\n",
    "    bmo01_thr = (np.transpose(bmo_patches, (0,2,3,1)) * 255).astype(np.uint8)\n",
    "\n",
    "    biggest_label = np.zeros((num_img, shape_img[0], shape_img[1]))\n",
    "    biggest_lists = []\n",
    "    \n",
    "    for idx in range(num_img):\n",
    "        row, col = np.nonzero(bmo01_thr[idx,:,:,0])\n",
    "        num_bmo_label, labeled_bmo_map = cv2.connectedComponents(bmo01_thr[idx,:,:,0])\n",
    "\n",
    "        temp_biggest_label = []\n",
    "\n",
    "        if num_bmo_label != 1:\n",
    "            for label_idx in range(1, num_bmo_label):\n",
    "                temp_row, temp_col = np.where(labeled_bmo_map == label_idx)\n",
    "                temp_biggest_label.append((len(temp_row), label_idx))\n",
    "        else:\n",
    "            temp_biggest_label.append((0,0))\n",
    "\n",
    "        temp_biggest_label = sorted(temp_biggest_label, reverse=True)\n",
    "        biggest_lists.append(temp_biggest_label[0])\n",
    "\n",
    "    for idx in range(num_img):\n",
    "        row, col = np.nonzero(bmo01_thr[idx,:,:,0])\n",
    "        num_bmo_label, labeled_bmo_map = cv2.connectedComponents(bmo01_thr[idx,:,:,0])\n",
    "\n",
    "        if biggest_lists[idx][1] != 0:\n",
    "            biggest_row, biggest_col = np.where(labeled_bmo_map == biggest_lists[idx][1])\n",
    "            biggest_label[idx, biggest_row, biggest_col] = 255\n",
    "    \n",
    "    if debug_flag ==True:\n",
    "        for idx in range(num_img):\n",
    "            cv2.imwrite(save_folder+'connected_comp'+str(idx)+'_.png', biggest_label[idx])\n",
    "    \n",
    "    return biggest_label\n",
    "\n",
    "def bmo_segmentation_reports(pred_bmo01, pred_bmo02, left_gt, right_gt,save_folder):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    from sklearn.metrics import jaccard_similarity_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    left_mean_acc_lists = []\n",
    "    right_mean_acc_lists = []\n",
    "    \n",
    "    for idx in range(np.shape(pred_bmo01)[0]):\n",
    "        pred01_row, pred01_col = np.where(pred_bmo01[idx]  == 255.0)\n",
    "        pred02_row, pred02_col =  np.where(pred_bmo02[idx]  == 255.0)\n",
    "\n",
    "        if np.mean(pred01_col) > np.mean(pred02_col):\n",
    "            left_pred = pred_bmo02[idx]\n",
    "            right_pred = pred_bmo01[idx]\n",
    "        else:\n",
    "            left_pred = pred_bmo01[idx]\n",
    "            right_pred = pred_bmo02[idx]\n",
    "            \n",
    "        left_pred = (left_pred>200)\n",
    "        right_pred = (right_pred >200)\n",
    "        \n",
    "        left_each_gt = (left_gt[idx,:,:,0] > 200)\n",
    "        right_each_gt = (right_gt[idx,:,:,0] > 200)\n",
    "        print(np.shape(left_each_gt))\n",
    "        print('left pred, gt max : {} {}'.format(np.max(left_pred), np.max(left_each_gt)))\n",
    "\n",
    "        flat_left_pred = left_pred.flatten()\n",
    "        flat_right_pred = right_pred.flatten()\n",
    "\n",
    "        flat_left_gt = left_each_gt.flatten()\n",
    "        flat_right_gt = right_each_gt.flatten()\n",
    "\n",
    "        l_table = segmentation_reports(confusion_matrix(flat_left_pred, flat_left_gt), 'left', idx)\n",
    "        r_table = segmentation_reports(confusion_matrix(flat_right_pred, flat_right_gt), 'right', idx)\n",
    "        \n",
    "        \n",
    "        left_intersection = np.sum((flat_left_pred * flat_left_gt))\n",
    "        left_dice = ((2* left_intersection)+1) / ((np.sum(flat_left_pred) + np.sum(flat_left_gt)) +1)\n",
    "        right_intersection = np.sum((flat_right_pred * flat_right_gt))\n",
    "        right_dice = ((2* right_intersection)+1) / ((np.sum(flat_right_pred) + np.sum(flat_right_gt)) +1)\n",
    "        l_table[\"Dice\"] = left_dice\n",
    "        r_table[\"Dice\"] = right_dice\n",
    "        \n",
    "        left_mean_acc_lists.append(l_table[\"Accuracy\"])\n",
    "        right_mean_acc_lists.append(r_table[\"Accuracy\"])\n",
    "        \n",
    "        lr_table = pd.concat([l_table, r_table], ignore_index=True)\n",
    "        \n",
    "        if idx == 0:\n",
    "            prev_lr_table = lr_table\n",
    "        else:\n",
    "            lr_table = pd.concat([lr_table, prev_lr_table], ignore_index=True)\n",
    "            prev_lr_table = lr_table\n",
    "        \n",
    "        debug_left_img = np.zeros((64,64,3), dtype=np.uint8)\n",
    "        debug_right_img = np.zeros((64,64,3), dtype=np.uint8)\n",
    "        \n",
    "        debug_l_pred_row, debug_l_pred_col = np.where(left_pred  == True)\n",
    "        debug_r_pred_row, debug_r_pred_col = np.where(right_pred  == True)\n",
    "        debug_l_gt_row, debug_l_gt_col = np.where(left_each_gt  == True)\n",
    "        debug_r_gt_row, debug_r_gt_col = np.where(right_each_gt  == True)\n",
    "        \n",
    "        debug_left_img[debug_l_pred_row, debug_l_pred_col,:] = (255,0,0)\n",
    "        debug_left_img[debug_l_gt_row, debug_l_gt_col,:] = (0,0,255)\n",
    "        debug_right_img[debug_r_pred_row, debug_r_pred_col,:] = (255,0,0)\n",
    "        debug_right_img[debug_r_gt_row, debug_r_gt_col,:] = (0,0,255)\n",
    "                \n",
    "        cv2.imwrite(save_folder+'left_diff_'+str(idx)+'.png',debug_left_img)\n",
    "        cv2.imwrite(save_folder+'right_diff_'+str(idx)+'.png',debug_right_img)\n",
    "        \n",
    "    print('mean left acc : ',np.mean(left_mean_acc_lists))\n",
    "    print('mean right acc : ', np.mean(right_mean_acc_lists))\n",
    "    #print(lr_table)\n",
    "    return lr_table\n",
    "    \n",
    "def segmentation_reports(confusion_matrix,left_right,index):\n",
    "    seg_reports_table = pd.DataFrame(columns=['Class','Specificity','Sensitivity','Precision', 'Recall', 'Accuracy','F1 Score', 'IoU'])\n",
    "\n",
    "    tp, fp = confusion_matrix[0]\n",
    "    fn, tn = confusion_matrix[1]\n",
    "    SP = tn / (tn+fp) #specificity\n",
    "    SE = tp / (tp+fn)#sensitivity\n",
    "    PR = tp / (tp+fp) #precision\n",
    "    RE = tp / (tp + fn) #Recall\n",
    "    ACC = (tp + tn) / (tp+fp+fn+tn) #accuracy\n",
    "    F1 = 2 *( (RE * PR) / (RE + PR)) #f1 score\n",
    "    IoU = tp / (tp + fp + fn)\n",
    "    Dice = 2*tp / (2*tp+fp+fn)\n",
    "    \n",
    "    seg_reports_table.loc[0,'Class'] = left_right+'_BMO_'+str(index)\n",
    "    seg_reports_table.loc[0,'Specificity'] = SP; seg_reports_table.loc[0,'Sensitivity'] = SE\n",
    "    seg_reports_table.loc[0,'Precision'] = PR; seg_reports_table.loc[0,'Recall'] = RE\n",
    "    seg_reports_table.loc[0,'Accuracy'] = ACC; seg_reports_table.loc[0,'F1 Score'] = F1\n",
    "    seg_reports_table.loc[0,'IoU'] = IoU;\n",
    "    \n",
    "    return seg_reports_table\n",
    "    \n",
    "    \n",
    "\n",
    "def get_bmo_center_points(processed_bmo, num_img, shape_img, save_folder, debug_flag):\n",
    "    bmo_center_points = np.zeros((num_img, shape_img[0], shape_img[1]))\n",
    "    center_points_lists = [] \n",
    "    \n",
    "    for idx in range(num_img):\n",
    "        bmo_row, bmo_col = np.nonzero(processed_bmo[idx])\n",
    "        if len(bmo_row) !=0 :\n",
    "            mean_row = int(np.mean(bmo_row)); mean_col = int(np.mean(bmo_col))\n",
    "            center_points_lists.append((mean_row, mean_col))\n",
    "            bmo_center_points[idx, mean_row, mean_col] = 255\n",
    "        else:\n",
    "            center_points_lists.append((0, 0))\n",
    "            \n",
    "    \n",
    "    if debug_flag == True:\n",
    "        copy_img = np.zeros((num_img,shape_img[0], shape_img[1], 3))\n",
    "        for idx in range(num_img):\n",
    "            bmo_row, bmo_col = np.nonzero(processed_bmo[idx])\n",
    "            if len(bmo_row) !=0 :\n",
    "                mean_row = int(np.mean(bmo_row)); mean_col = int(np.mean(bmo_col))\n",
    "                tempRC = tuple([mean_col, mean_row])\n",
    "                cv2.circle(copy_img[idx],tempRC, 5,(0,255,0))\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        for idx in range(num_img):\n",
    "            cv2.imwrite(save_folder+'center_points'+str(idx)+'_.png', copy_img[idx])\n",
    "        \n",
    "    return bmo_center_points, center_points_lists\n",
    "\n",
    "def bmo_reconstruction_oct(ori_imgs,num_img ,center_bmo01, center_bmo02, bmo01_init_points, bmo02_init_points, save_folder, debug_flag):\n",
    "    recon_imgs = ori_imgs.copy()\n",
    "    recon_bmo01_center_points_lists = []\n",
    "    recon_bmo02_center_points_lists = []\n",
    "    \n",
    "    for idx in range(num_img):\n",
    "        recon_bmo01_center_row = bmo01_init_points[idx][0] +  center_bmo01[idx][0] \n",
    "        recon_bmo01_center_col = bmo01_init_points[idx][1] +  center_bmo01[idx][1] \n",
    "        recon_bmo01_center_points_lists.append((recon_bmo01_center_row, recon_bmo01_center_col)) \n",
    "        \n",
    "        recon_bmo02_center_row = bmo02_init_points[idx][0] +  center_bmo02[idx][0] \n",
    "        recon_bmo02_center_col = bmo02_init_points[idx][1] +  center_bmo02[idx][1]  \n",
    "        recon_bmo02_center_points_lists.append((recon_bmo02_center_row, recon_bmo02_center_col)) \n",
    "        \n",
    "        if debug_flag == True:\n",
    "            temp_bmo01_center = tuple([recon_bmo01_center_col, recon_bmo01_center_row])\n",
    "            temp_bmo02_center = tuple([recon_bmo02_center_col, recon_bmo02_center_row])\n",
    "        \n",
    "            cv2.circle(recon_imgs[idx],temp_bmo01_center, 3,(0,0,255))\n",
    "            cv2.circle(recon_imgs[idx],temp_bmo02_center, 3,(0,0,255))\n",
    "            \n",
    "            cv2.imwrite(save_folder+'recon_img_'+str(idx)+'_.png', recon_imgs[idx])\n",
    "        \n",
    "    return recon_bmo01_center_points_lists, recon_bmo02_center_points_lists\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist the folder in this path : ./pipe_result/final_paper_debug//processed_bmo/\n",
      "already exist the folder in this path : ./pipe_result/final_paper_debug//center_point/\n",
      "already exist the folder in this path : ./pipe_result/final_paper_debug//bmo_recon/\n",
      "already exist the folder in this path : ./pipe_result/final_paper_debug//debug_pred_gt/\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "(64, 64)\n",
      "left pred, gt max : True True\n",
      "mean left acc :  0.97802734375\n",
      "mean right acc :  0.977587890625\n",
      "           Class Specificity Sensitivity Precision    Recall  Accuracy  \\\n",
      "0    left_BMO_19           0    0.976647  0.993002  0.976647  0.969971   \n",
      "1   right_BMO_19           0    0.967822   0.98588  0.967822   0.95459   \n",
      "2    left_BMO_18        0.16    0.980103  0.994764  0.980103  0.975098   \n",
      "3   right_BMO_18           0    0.982843  0.996026  0.982843  0.979004   \n",
      "4    left_BMO_17           0    0.984002  0.991813  0.984002  0.976074   \n",
      "5   right_BMO_17           0    0.980864  0.995022  0.980864  0.976074   \n",
      "6    left_BMO_16    0.368421    0.985283  0.997022  0.985283  0.982422   \n",
      "7   right_BMO_16    0.928571    0.986726  0.999502  0.986726  0.986328   \n",
      "8    left_BMO_15    0.818182    0.981836  0.999001  0.981836  0.980957   \n",
      "9   right_BMO_15        0.16    0.979858  0.994763  0.979858  0.974854   \n",
      "10   left_BMO_14    0.565217    0.983796  0.997511  0.983796  0.981445   \n",
      "11  right_BMO_14    0.694444    0.974877  0.997229  0.974877  0.972412   \n",
      "12   left_BMO_13    0.404255    0.982959  0.993014  0.982959  0.976318   \n",
      "13  right_BMO_13        0.25    0.977608  0.993995  0.977608  0.971924   \n",
      "14   left_BMO_12     0.96875    0.990157  0.999752  0.990157   0.98999   \n",
      "15  right_BMO_12    0.615385    0.988415  0.996273  0.988415  0.984863   \n",
      "16   left_BMO_11    0.878788    0.983264     0.999  0.983264  0.982422   \n",
      "17  right_BMO_11     0.95122    0.994575  0.999504  0.994575  0.994141   \n",
      "18   left_BMO_10    0.139535    0.978781  0.990759  0.978781  0.969971   \n",
      "19  right_BMO_10    0.740741    0.985992  0.998258  0.985992  0.984375   \n",
      "20    left_BMO_9   0.0571429    0.974391  0.991729  0.974391  0.966553   \n",
      "21   right_BMO_9     0.45283     0.98046  0.992737   0.98046  0.973633   \n",
      "22    left_BMO_8           0    0.988922  0.991607  0.988922  0.980713   \n",
      "23   right_BMO_8           0    0.982006  0.990306  0.982006  0.972656   \n",
      "24    left_BMO_7       0.375    0.981373  0.997509  0.981373  0.979004   \n",
      "25   right_BMO_7    0.470968    0.988074  0.979376  0.988074  0.968506   \n",
      "26    left_BMO_6           0    0.988418  0.990615  0.988418  0.979248   \n",
      "27   right_BMO_6    0.508197    0.988352  0.992534  0.988352  0.981201   \n",
      "28    left_BMO_5        0.56    0.983835  0.991727  0.983835  0.976074   \n",
      "29   right_BMO_5     0.41573    0.988021  0.987036  0.988021  0.975586   \n",
      "30    left_BMO_4    0.736842    0.988611  0.996257  0.988611  0.985107   \n",
      "31   right_BMO_4     0.49505     0.99975  0.987392   0.99975  0.987305   \n",
      "32    left_BMO_3       0.625     0.98723  0.997766   0.98723  0.985107   \n",
      "33   right_BMO_3    0.390244    0.978792  0.993741  0.978792    0.9729   \n",
      "34    left_BMO_2           0    0.984755  0.992811  0.984755  0.977783   \n",
      "35   right_BMO_2   0.0769231    0.982196   0.98806  0.982196  0.970703   \n",
      "36    left_BMO_1   0.0810811    0.984693  0.974665  0.984693  0.960205   \n",
      "37   right_BMO_1           0     0.99237  0.991882   0.99237  0.984375   \n",
      "38    left_BMO_0    0.552239    0.993299   0.99256  0.993299  0.986084   \n",
      "39   right_BMO_0           0    0.994829  0.991411  0.994829  0.986328   \n",
      "\n",
      "    F1 Score       IoU      Dice  \n",
      "0   0.984756  0.969971  0.008065  \n",
      "1   0.976767   0.95459  0.005348  \n",
      "2   0.987379  0.975073  0.081081  \n",
      "3   0.989391  0.979004  0.011494  \n",
      "4   0.987892  0.976074  0.010101  \n",
      "5   0.987892  0.976074  0.010101  \n",
      "6   0.991118  0.982392  0.172414  \n",
      "7   0.993073  0.986241  0.486239  \n",
      "8   0.990344  0.980873  0.321739  \n",
      "9   0.987254  0.974829  0.080357  \n",
      "10  0.990606  0.981386  0.262136  \n",
      "11  0.985926  0.972243  0.310976  \n",
      "12  0.987961  0.976208  0.286765  \n",
      "13  0.985734  0.971869  0.128788  \n",
      "14  0.994931  0.989914  0.605769  \n",
      "15  0.992329  0.984774  0.441441  \n",
      "16  0.991069  0.982297  0.450382  \n",
      "17  0.997033  0.994084  0.766990  \n",
      "18  0.984734  0.969927  0.095588  \n",
      "19  0.992087  0.984298  0.390476  \n",
      "20  0.982983  0.966536  0.035211  \n",
      "21   0.98656  0.973477  0.312102  \n",
      "22  0.990263  0.980713  0.012500  \n",
      "23  0.986139  0.972656  0.008850  \n",
      "24  0.989375  0.978973  0.131313  \n",
      "25  0.983706  0.967934  0.532609  \n",
      "26  0.989515  0.979248  0.011628  \n",
      "27  0.990438  0.981058  0.450000  \n",
      "28  0.987765  0.975826  0.464481  \n",
      "29  0.987528  0.975363  0.428571  \n",
      "30   0.99242  0.984953  0.582192  \n",
      "31  0.993532  0.987148  0.660131  \n",
      "32   0.99247  0.985053  0.336957  \n",
      "33  0.986209  0.972794  0.229167  \n",
      "34  0.988767  0.977783  0.010870  \n",
      "35  0.985119  0.970674  0.069767  \n",
      "36  0.979653  0.960117  0.104396  \n",
      "37  0.992126  0.984375  0.015385  \n",
      "38  0.992929  0.985957  0.568182  \n",
      "39  0.993117  0.986328  0.017544  \n"
     ]
    }
   ],
   "source": [
    "# hyperparam\n",
    "save_folder = './pipe_result/'+str(name_experiment)+'/processed_bmo/'\n",
    "save_folder2 = './pipe_result/'+str(name_experiment)+'/center_point/'\n",
    "save_folder3 = './pipe_result/'+str(name_experiment)+'/bmo_recon/'\n",
    "save_folder4 = './pipe_result/'+str(name_experiment)+'/debug_pred_gt/'\n",
    "\n",
    "\n",
    "dir_checker(save_folder)\n",
    "dir_checker(save_folder2)\n",
    "dir_checker(save_folder3)\n",
    "dir_checker(save_folder4)\n",
    "\n",
    "# processing\n",
    "processed_bmo01 = bmo_max_connected_components(pred_thr_bmo01_class01, NUM_YOLO_RESULT,\n",
    "                                                INFERENCE_SHAPE, save_folder, debug_flag)\n",
    "processed_bmo02 = bmo_max_connected_components(pred_thr_bmo02_class01, NUM_YOLO_RESULT,\n",
    "                                                INFERENCE_SHAPE, save_folder, debug_flag)\n",
    "\n",
    "\n",
    "if VALID_TEST=='valid':\n",
    "    LR_SEG_REPORTS= bmo_segmentation_reports(processed_bmo01, processed_bmo02, left_bmoGT_patch, right_bmoGT_patch,save_folder4)\n",
    "    print(LR_SEG_REPORTS)\n",
    "center_bmo01_img, center_bmo01_points = get_bmo_center_points(processed_bmo01, NUM_YOLO_RESULT, INFERENCE_SHAPE, \n",
    "                                     save_folder2, debug_flag)\n",
    "center_bmo02_img, center_bmo02_points = get_bmo_center_points(processed_bmo02, NUM_YOLO_RESULT, INFERENCE_SHAPE, \n",
    "                                     save_folder2, debug_flag)\n",
    "\n",
    "recon_bmo01_center,recon_bmo02_center= bmo_reconstruction_oct(ORI_IMGS,NUM_YOLO_RESULT,\n",
    "                                                               center_bmo01_points, center_bmo02_points, \n",
    "                                                               BMO01_INIT_POINTS, BMO02_INIT_POINTS, \n",
    "                                                               save_folder3, debug_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 330)\n",
      "179 330\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  0,  0],\n",
       "        [26, 26, 26],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [44, 44, 44],\n",
       "        [ 4,  4,  4],\n",
       "        ...,\n",
       "        [ 3,  3,  3],\n",
       "        [ 4,  4,  4],\n",
       "        [ 8,  8,  8]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [47, 47, 47],\n",
       "        [14, 14, 14],\n",
       "        ...,\n",
       "        [ 1,  1,  1],\n",
       "        [ 6,  6,  6],\n",
       "        [10, 10, 10]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]],\n",
       "\n",
       "       [[ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        ...,\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  0]]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(recon_bmo01_center[0])\n",
    "print(recon_bmo01_center[0][0], recon_bmo01_center[0][1])\n",
    "temp_coord= np.where(np.all(RESULT_IMGS[0] == (0,0,255), axis=-1))\n",
    "print(temp_coord)\n",
    "\n",
    "temp = RESULT_IMGS.copy()\n",
    "cv2.line(temp[0], (recon_bmo01_center[0][1], recon_bmo01_center[0][0]), (recon_bmo02_center[0][1], recon_bmo02_center[0][0]), (255,255,0), 2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_groundTruth_extract_bmo_centerPoints(groundTruth_img_path,num_imgs,shape_imgs):\n",
    "    img_h, img_w = shape_imgs[0], shape_imgs[1]\n",
    "    groundTruth_imgs = np.zeros((num_imgs, img_h, img_w,3),dtype=np.uint8)    \n",
    "    idx =0 \n",
    "    left_center_points_lists = [] \n",
    "    right_center_points_lists = [] \n",
    "    print('gt shape : ',np.shape(groundTruth_imgs))\n",
    "      \n",
    "    for count, filename in enumerate(sorted(os.listdir(groundTruth_img_path)), start=0):\n",
    "        if filename.startswith(\".ipynb\") == False:\n",
    "            temp_img = np.zeros((img_h, img_w,1),dtype=np.uint8)    \n",
    "            \n",
    "            temp = cv2.imread(groundTruth_img_path + filename)\n",
    "            groundTruth_imgs[idx] = temp.astype(np.uint8)\n",
    "            \n",
    "            row,col = np.where(np.all(temp == (0,0,255), axis = -1))\n",
    "            temp_img[row,col] = 255\n",
    "            \n",
    "            num_bmo_label, labeled_bmo_map = cv2.connectedComponents(temp_img)\n",
    "            bmo01_row, bmo01_col = np.where(labeled_bmo_map == 1)\n",
    "            bmo02_row, bmo02_col = np.where(labeled_bmo_map == 2)\n",
    "            \n",
    "            mean_bmo01_col = np.mean(bmo01_col)\n",
    "            mean_bmo02_col = np.mean(bmo02_col)\n",
    "            \n",
    "            if mean_bmo01_col > mean_bmo02_col:\n",
    "                # bmo01 -> right / bmo02 -> left\n",
    "                \n",
    "                left_mean_row = int(np.mean(bmo02_row)); left_mean_col = int(np.mean(bmo02_col))\n",
    "                right_mean_row = int(np.mean(bmo01_row)); right_mean_col = int(np.mean(bmo01_col))\n",
    "                \n",
    "                left_center_points_lists.append((left_mean_row, left_mean_col))\n",
    "                right_center_points_lists.append((right_mean_row, right_mean_col))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                left_mean_row = int(np.mean(bmo01_row)); left_mean_col = int(np.mean(bmo01_col))\n",
    "                right_mean_row = int(np.mean(bmo02_row)); right_mean_col = int(np.mean(bmo02_col))\n",
    "                \n",
    "                left_center_points_lists.append((left_mean_row, left_mean_col))\n",
    "                right_center_points_lists.append((right_mean_row, right_mean_col))\n",
    "            \n",
    "            idx = idx+1\n",
    "            \n",
    "    return groundTruth_imgs, left_center_points_lists, right_center_points_lists\n",
    "\n",
    "def calc_dist_gt_pred_center(left_ground_center, right_ground_center, bmo01_pred_center, bmo02_pred_center,\n",
    "                             num_img,ori_img ,save_folder, debug_flag):\n",
    "    \n",
    "    _x_convert = 12.5000\n",
    "    _y_convert = 3.9216\n",
    "    \n",
    "    left_l1_diff = np.zeros(num_img, dtype=np.float32)\n",
    "    right_l1_diff = np.zeros(num_img, dtype=np.float32)\n",
    "    \n",
    "    left_l2_diff = np.zeros(num_img, dtype=np.float32) # euclidian\n",
    "    right_l2_diff = np.zeros(num_img, dtype=np.float32)\n",
    "    \n",
    "    grd_l2_dist = np.zeros(num_img, dtype=np.float32)\n",
    "    pred_l2_dist = np.zeros(num_img, dtype=np.float32)\n",
    "    \n",
    "    ym_left_l1_diff = np.zeros(num_img, dtype=np.float32)\n",
    "    ym_right_l1_diff = np.zeros(num_img, dtype=np.float32)\n",
    "    \n",
    "    ym_left_l2_diff = np.zeros(num_img, dtype=np.float32) # euclidian\n",
    "    ym_right_l2_diff = np.zeros(num_img, dtype=np.float32)\n",
    "    \n",
    "    ym_grd_l2_dist = np.zeros(num_img, dtype=np.float32)\n",
    "    ym_pred_l2_dist = np.zeros(num_img, dtype=np.float32)\n",
    "    \n",
    "    for idx in range(num_img):\n",
    "        if bmo01_pred_center[idx][1] > bmo02_pred_center[idx][1]:\n",
    "            left_pred_row = bmo02_pred_center[idx][0]; left_pred_col = bmo02_pred_center[idx][1]\n",
    "            right_pred_row = bmo01_pred_center[idx][0]; right_pred_col = bmo01_pred_center[idx][1]\n",
    "        else:\n",
    "            left_pred_row = bmo01_pred_center[idx][0]; left_pred_col = bmo01_pred_center[idx][1]\n",
    "            right_pred_row = bmo02_pred_center[idx][0]; right_pred_col = bmo02_pred_center[idx][1]\n",
    "            \n",
    "        left_ground_row = left_ground_center[idx][0]; left_ground_col = left_ground_center[idx][1] \n",
    "        right_ground_row = right_ground_center[idx][0]; right_ground_col = right_ground_center[idx][1]\n",
    "        \n",
    "        # 0 = left, 1 = right\n",
    "        left_gt = np.array((left_ground_row, left_ground_col))\n",
    "        right_gt = np.array((right_ground_row, right_ground_col))\n",
    "        left_pred = np.array((left_pred_row, left_pred_col))\n",
    "        right_pred = np.array((right_pred_row, right_pred_col))\n",
    "        \n",
    "        left_l1_diff[idx] = abs(left_ground_row -left_pred_row) + abs(left_ground_col - left_pred_col)\n",
    "        right_l1_diff[idx] = abs(right_ground_row - right_pred_row) + abs(right_ground_col - right_pred_col)\n",
    "        \n",
    "        left_l2_diff[idx] = np.linalg.norm(left_gt - left_pred)\n",
    "        right_l2_diff[idx] = np.linalg.norm(right_gt - right_pred)\n",
    "        grd_l2_dist[idx] = np.linalg.norm(right_gt- left_gt)\n",
    "        pred_l2_dist[idx] = np.linalg.norm(right_pred - left_pred)\n",
    "        \n",
    "        \n",
    "        # ym distance\n",
    "        ym_left_l1_diff[idx] = abs(left_ground_row -left_pred_row) * _y_convert + abs(left_ground_col - left_pred_col) * _x_convert\n",
    "        ym_right_l1_diff[idx] = abs(right_ground_row - right_pred_row) * _y_convert + abs(right_ground_col - right_pred_col) * _x_convert\n",
    "        \n",
    "        ym_left_l2_diff[idx] = np.sqrt(np.square((left_gt[0] - left_pred[0]) * _y_convert) + np.square((left_gt[1] - left_pred[1]) * _x_convert) )\n",
    "        ym_right_l2_diff[idx] = np.sqrt(np.square((right_gt[0] - right_pred[0]) * _y_convert) + np.square((right_gt[1] - right_pred[1]) * _x_convert) )\n",
    "        \n",
    "        ym_grd_l2_dist[idx] = np.sqrt(np.square((left_gt[0] - right_gt[0]) * _y_convert) + np.square((left_gt[1] - right_gt[1]) * _x_convert) )\n",
    "        ym_pred_l2_dist[idx] = np.sqrt(np.square((left_pred[0] - right_pred[0]) * _y_convert) + np.square((left_pred[1] - right_pred[1]) * _x_convert) )\n",
    "        \n",
    "        #left_l2_diff[idx] = ((((left_ground_row -left_pred_row) **2 ) * _y_convert) + (((left_ground_col - left_pred_col) **2)*_x_convert))**1/2\n",
    "        #right_l2_diff[idx] = ((((right_ground_row -right_pred_row) **2 ) *_y_convert) + (((right_ground_col - right_pred_col) **2 )*_x_convert))**1/2\n",
    "        \n",
    "        if debug_flag == True:\n",
    "            debug_ori_img = ori_img[idx].copy()\n",
    "            debug_left_gt_center = tuple([left_ground_col, left_ground_row])\n",
    "            debug_right_gt_center = tuple([right_ground_col, right_ground_row])\n",
    "            debug_left_pred_center = tuple([left_pred_col, left_pred_row])\n",
    "            debug_right_pred_center = tuple([right_pred_col, right_pred_row])\n",
    "            \n",
    "        \n",
    "            cv2.circle(debug_ori_img,debug_left_gt_center, 3,(255,0,0))\n",
    "            cv2.circle(debug_ori_img,debug_right_gt_center, 3,(255,0,0))\n",
    "            print('save circle')\n",
    "            cv2.imwrite(save_folder+'ground_truth_'+str(idx)+'_.png', debug_ori_img)\n",
    "            \n",
    "            cv2.circle(debug_ori_img,debug_left_pred_center, 3,(0,0,255))\n",
    "            cv2.circle(debug_ori_img,debug_right_pred_center, 3,(0,0,255))\n",
    "            \n",
    "            cv2.imwrite(save_folder+'diff_center_'+str(idx)+'_.png', debug_ori_img)\n",
    "            \n",
    "    \n",
    "    print('left l1 mean dist : {} right l1 mean dist : {}'.format(np.mean(left_l1_diff), np.mean(right_l1_diff)))\n",
    "    print('left l1 var dist : {} right l1 var dist : {}\\n\\n'.format(np.std(left_l1_diff), np.std(right_l1_diff)))\n",
    "    \n",
    "    \n",
    "    print('left l2 mean dist : {} right l2 mean dist : {}'.format(np.mean(left_l2_diff), np.mean(right_l2_diff)))\n",
    "    print('left l2 var dist : {} right l2 var dist : {}\\n\\n'.format(np.std(left_l2_diff), np.std(right_l2_diff)))\n",
    "    \n",
    "    print('[ym] left l1 mean dist : {} right l1 mean dist : {}'.format(np.mean(ym_left_l1_diff), np.mean(ym_right_l1_diff)))\n",
    "    print('[ym] left l1 var dist : {} right l1 var dist : {}\\n\\n'.format(np.std(ym_left_l1_diff), np.std(ym_right_l1_diff)))\n",
    "    \n",
    "    \n",
    "    print('[ym] left l2 mean dist : {} right l2 mean dist : {}'.format(np.mean(ym_left_l2_diff), np.mean(ym_right_l2_diff)))\n",
    "    print('[ym] left l2 var dist : {} right l2 var dist : {}\\n\\n'.format(np.std(ym_left_l2_diff), np.std(ym_right_l2_diff)))\n",
    "    \n",
    "    l1_table = pd.DataFrame(columns=['CLASS','Mean_l1_distance','Std_l1_distance', 'Mean_ym_l1_distance', 'Std_ym_l1_distance'])\n",
    "    l1_table.loc[0,'CLASS' ] = 'LEFT_BMO'\n",
    "    l1_table.loc[0,'Mean_l1_distance' ] = np.mean(left_l1_diff); l1_table.loc[0,'Std_l1_distance' ] = np.std(left_l1_diff)\n",
    "    l1_table.loc[0,'Mean_ym_l1_distance' ] = np.mean(ym_left_l1_diff); l1_table.loc[0,'Std_ym_l1_distance' ] = np.std(ym_left_l1_diff)\n",
    "    \n",
    "    l1_table.loc[1,'CLASS' ] = 'RIGHT_BMO' \n",
    "    l1_table.loc[1,'Mean_l1_distance' ] = np.mean(right_l1_diff); l1_table.loc[1,'Std_l1_distance' ] = np.std(right_l1_diff)\n",
    "    l1_table.loc[1,'Mean_ym_l1_distance' ] = np.mean(ym_right_l1_diff); l1_table.loc[1,'Std_ym_l1_distance' ] = np.std(ym_right_l1_diff)\n",
    "    \n",
    "    \n",
    "    l2_table = pd.DataFrame(columns=['CLASS','Mean_l2_distance','Std_l2_distance', 'Mean_ym_l2_distance', 'Std_ym_l2_distance'])\n",
    "    l2_table.loc[0,'CLASS' ] = 'LEFT_BMO'\n",
    "    l2_table.loc[0,'Mean_l2_distance' ] = np.mean(left_l2_diff); l2_table.loc[0,'Std_l2_distance' ] = np.std(left_l2_diff)\n",
    "    l2_table.loc[0,'Mean_ym_l2_distance' ] = np.mean(ym_left_l2_diff); l2_table.loc[0,'Std_ym_l2_distance' ] = np.std(ym_left_l2_diff)\n",
    "    \n",
    "    l2_table.loc[1,'CLASS' ] = 'RIGHT_BMO' \n",
    "    l2_table.loc[1,'Mean_l2_distance' ] = np.mean(right_l2_diff); l2_table.loc[1,'Std_l2_distance' ] = np.std(right_l2_diff)\n",
    "    l2_table.loc[1,'Mean_ym_l2_distance' ] = np.mean(ym_right_l2_diff); l2_table.loc[1,'Std_ym_l2_distance' ] = np.std(ym_right_l2_diff)\n",
    "    \n",
    "    bmo_l2_diff = np.concatenate((left_l2_diff, right_l2_diff), axis = 0)\n",
    "    bmo_ym_l2_diff = np.concatenate((ym_left_l2_diff, ym_right_l2_diff), axis = 0)\n",
    "\n",
    "    \n",
    "    l2_table.loc[2,'CLASS' ] = 'BMO'\n",
    "    l2_table.loc[2,'Mean_l2_distance' ] = np.mean(bmo_l2_diff)\n",
    "    l2_table.loc[2,'Std_l2_distance' ] = np.std(bmo_l2_diff)\n",
    "    l2_table.loc[2,'Mean_ym_l2_distance' ] = np.mean(bmo_ym_l2_diff)\n",
    "    l2_table.loc[2,'Std_ym_l2_distance' ] = np.std(bmo_ym_l2_diff)\n",
    "    \n",
    "    \n",
    "    \n",
    "    bmo_l2_table = pd.DataFrame(columns=['CLASS','Mean_bmo_l2_distance', 'Mean_ym_bmo_l2_distance'])\n",
    "    bmo_l2_table.loc[0,'CLASS' ] = 'GROUND_TRUTH'\n",
    "    bmo_l2_table.loc[0,'Mean_bmo_l2_distance' ] = np.mean(grd_l2_dist); bmo_l2_table.loc[0,'Mean_ym_bmo_l2_distance' ] = np.mean(ym_grd_l2_dist)\n",
    "    \n",
    "    bmo_l2_table.loc[1,'CLASS' ] = 'PREDICTION'\n",
    "    bmo_l2_table.loc[1,'Mean_bmo_l2_distance' ] = np.mean(pred_l2_dist); bmo_l2_table.loc[0,'Mean_ym_bmo_l2_distance' ] = np.mean(ym_pred_l2_dist)\n",
    "    \n",
    "    return l1_table, l2_table, bmo_l2_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist the folder in this path : ./pipe_result/final_paper_debug//bmo_final_diff/\n",
      "gt shape :  (20, 500, 760, 3)\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "save circle\n",
      "left l1 mean dist : 6.699999809265137 right l1 mean dist : 3.3499999046325684\n",
      "left l1 var dist : 7.149126052856445 right l1 var dist : 4.952524662017822\n",
      "\n",
      "\n",
      "left l2 mean dist : 5.045083045959473 right l2 mean dist : 2.6194605827331543\n",
      "left l2 var dist : 5.417300701141357 right l2 var dist : 3.659019947052002\n",
      "\n",
      "\n",
      "[ym] left l1 mean dist : 49.865325927734375 right l1 mean dist : 28.578481674194336\n",
      "[ym] left l1 var dist : 47.05536651611328 right l1 var dist : 34.001163482666016\n",
      "\n",
      "\n",
      "[ym] left l2 mean dist : 38.786231994628906 right l2 mean dist : 24.13015365600586\n",
      "[ym] left l2 var dist : 34.303958892822266 right l2 var dist : 25.11441993713379\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyperparam\n",
    "save_folder = './pipe_result/'+str(name_experiment)+'/bmo_final_diff/'\n",
    "dir_checker(save_folder)\n",
    "\n",
    "# processing\n",
    "GROUND_TRUTH_IMG, LEFT_GROUND_CENTER,RIGHT_GROUND_CENTER = load_groundTruth_extract_bmo_centerPoints(GROUND_TRUTH_PATH, NUM_YOLO_RESULT, SHAPE_YOLO_RESULT)\n",
    "\n",
    "l1_table, l2_table, bmo_l2_table = calc_dist_gt_pred_center(LEFT_GROUND_CENTER,RIGHT_GROUND_CENTER, recon_bmo01_center,recon_bmo02_center,NUM_YOLO_RESULT,ORI_IMGS, save_folder, debug_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,\n",
    "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = './pipe_result/'+str(name_experiment)+'/'\n",
    "\n",
    "\n",
    "l1_table\n",
    "fig,ax = render_mpl_table(l1_table, header_columns=0, col_width=5.0)\n",
    "fig.savefig(save_folder + 'bmo_l1_table.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_table\n",
    "\n",
    "fig,ax = render_mpl_table(l2_table, header_columns=0, col_width=5.0)\n",
    "fig.savefig(save_folder + 'bmo_l2_table.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmo_l2_table\n",
    "\n",
    "fig,ax = render_mpl_table(bmo_l2_table, header_columns=0, col_width=5.0)\n",
    "fig.savefig(save_folder + 'each_left_right_bmo_l2_table.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_SEG_REPORTS\n",
    "fig,ax = render_mpl_table(LR_SEG_REPORTS, header_columns=0, col_width=5.0)\n",
    "fig.savefig(save_folder + 'bmo_seg_reports.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_seg_table = pd.DataFrame(columns=['Class','Accuracy(%)','F1 Score(%)', 'Dice(%)'])\n",
    "mean_seg_table.loc[0,\"Class\"] = \"BMO\"\n",
    "mean_seg_table.loc[0,\"Accuracy(%)\"] = np.mean(LR_SEG_REPORTS[\"Accuracy\"])\n",
    "mean_seg_table.loc[0,\"F1 Score(%)\"] = np.mean(LR_SEG_REPORTS[\"F1 Score\"])\n",
    "mean_seg_table.loc[0,\"Dice(%)\"] = np.mean(LR_SEG_REPORTS[\"Dice\"])\n",
    "\n",
    "fig,ax = render_mpl_table(mean_seg_table, header_columns=0, col_width=5.0)\n",
    "fig.savefig(save_folder + 'final_mean_bmo_table.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LC processing  \n",
    "이미지 한장한장 적용을 해줘야 할 것 같다. (혹은 list나 numpy.append 이용....)\n",
    "1. overlap-tile prediction\n",
    "overlap-tile 전략을 사용함에 있어서.   \n",
    "    - **Number of images (each row, col)**   \n",
    "        (image size - patch size) // (stride +1) 이는 stride 갯수만큼 이미지를 나누기 떄문  \n",
    "    - **Total number of images**  \n",
    "        (image height - patch height) // (stride +1) * (image width - patch width) // (stride +1)  \n",
    "    - **Overlap-tile condition**  \n",
    "        \n",
    "        \n",
    "2. reconstruct patch\n",
    "3. get centerline\n",
    "4. reconstruction to oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_border_overlap(data, patch_h, patch_w,stride_h, stride_w):\n",
    "    \n",
    "    img_h = data.shape[0]\n",
    "    img_w = data.shape[1]\n",
    "    \n",
    "    leftover_h = (img_h - patch_h) % stride_h\n",
    "    leftover_w = (img_w - patch_w) % stride_w\n",
    "    \n",
    "    if(leftover_h != 0):\n",
    "        print(\"\\nthe side H is not compatible with the selected stride of \" +str(stride_h))\n",
    "        print(\"img_h \" +str(img_h) + \", patch_h \" +str(patch_h) + \", stride_h \" +str(stride_h))\n",
    "        print(\"(img_h - patch_h) MOD stride_h: \" +str(leftover_h))\n",
    "        print(\"So the H dim will be padded with additional \" +str(stride_h - leftover_h) + \" pixels\")\n",
    "        \n",
    "        temp_full_imgs = np.zeros((img_h+(stride_h-leftover_h),img_w))\n",
    "        temp_full_imgs[0:img_h,0:img_w] = data\n",
    "        data = temp_full_imgs\n",
    "        \n",
    "    if(leftover_w != 0):\n",
    "        print(\"\\nthe side H is not compatible with the selected stride of \" +str(stride_w))\n",
    "        print(\"img_h \" +str(img_w) + \", patch_h \" +str(patch_w) + \", stride_h \" +str(stride_w))\n",
    "        print(\"(img_h - patch_h) MOD stride_h: \" +str(leftover_w))\n",
    "        print(\"So the H dim will be padded with additional \" +str(stride_w - leftover_w) + \" pixels\")\n",
    "        \n",
    "        temp_full_imgs = np.zeros((data.shape[0],img_w+(stride_w - leftover_w)))\n",
    "        temp_full_imgs[0:data.shape[0],0:img_w] = data\n",
    "        data = temp_full_imgs\n",
    "    print (\"after paint border lc img shape : \" +str(data.shape))\n",
    "    new_h = np.shape(data)[0]; new_w = np.shape(data)[1]\n",
    "    return data, new_h, new_w\n",
    "\n",
    "def lc_overlap_tile_prediction(ori_imgs, deep_model,bbox_coord,stride,num_img, shape_inference, save_folder, debug_flag):\n",
    "    lc_img = ori_imgs[bbox_coord[1] : bbox_coord[3], bbox_coord[0]:bbox_coord[2],1]\n",
    "    img_h = np.shape(lc_img)[0]; img_w = np.shape(lc_img)[1]\n",
    "    patch_h = shape_inference[0]; patch_w = shape_inference[1]\n",
    "    stride_h = stride; stride_w = stride\n",
    "    \n",
    "    if debug_flag ==True:\n",
    "        cv2.imwrite(save_folder+'lc_img.png', lc_img)\n",
    "    \n",
    "    \n",
    "    print('before paint border lc img shape : {}'.format(np.shape(lc_img)))\n",
    "    lc_img,new_h, new_w = padding_border_overlap(lc_img, patch_h, patch_w, stride_h, stride_w)\n",
    "    print('new h : {} new w : {}'.format(new_h, new_w))\n",
    "    \n",
    "    img_h = new_h; img_w = new_w\n",
    "    num_patch_img = ((img_h - patch_h)//stride_h +1) * ((img_w - patch_w)//stride_w +1)\n",
    "    lc_patches = np.empty((num_patch_img, patch_h, patch_w))\n",
    "    cnt =0 \n",
    "    \n",
    "    for h in range((img_h - patch_h)//stride_h +1):\n",
    "        for w in range((img_w - patch_w)//stride_w +1): \n",
    "            lc_patches[cnt] = lc_img[h*stride_h : (h*stride_h)+patch_h, w*stride_w : (w*stride_w)+patch_w ]\n",
    "            cnt = cnt+1\n",
    "    \n",
    "    print('lc patch shape after extract overlap : {}'.format(np.shape(lc_patches)))\n",
    "    \n",
    "    if debug_flag ==True:\n",
    "        for idx in range(num_patch_img):\n",
    "            #print(np.shape(lc_patches[idx]))\n",
    "            cv2.imwrite(save_folder+'lc_patched'+str(idx)+'_.png', lc_patches[idx])\n",
    "          \n",
    "    lc_patches = np.expand_dims(lc_patches,-1)\n",
    "    lc_patches = np.transpose(lc_patches, (0,3,1,2))\n",
    "    lc_patches = lc_patches / 255.0\n",
    "    lc_pred = deep_model.predict(lc_patches, batch_size=64, verbose=2)\n",
    "    \n",
    "    print('shape lc patches : {}'.format(np.shape(lc_pred)))\n",
    "    \n",
    "    lc_pred_thr = pred_to_imgs(lc_pred, shape_inference[0], shape_inference[1], \"threshold\")\n",
    "    lc_pred = pred_to_imgs(lc_pred, shape_inference[0], shape_inference[1], \"original\")\n",
    "    \n",
    "    \n",
    "    pred_lc_class01 = lc_pred[:,0]; pred_lc_class01 = np.expand_dims(pred_lc_class01, 1)\n",
    "    pred_lc_class02 = lc_pred[:,1]; pred_lc_class02 = np.expand_dims(pred_lc_class02, 1)\n",
    "    \n",
    "    pred_lc_thr_class01 = lc_pred_thr[:,0]; pred_lc_thr_class01 = np.expand_dims(pred_lc_thr_class01, 1)\n",
    "    pred_lc_thr_class02 = lc_pred_thr[:,1]; pred_lc_thr_class02 = np.expand_dims(pred_lc_thr_class02, 1)\n",
    "\n",
    "    print('shape lc patches class : {}'.format(np.shape(pred_lc_class01)))\n",
    "    \n",
    "    if debug_flag == True:\n",
    "        temp_pred_lc_class01 = pred_lc_class01.copy()\n",
    "        temp_pred_lc_class02 = pred_lc_class02.copy()\n",
    "        \n",
    "        temp_pred_lc_class01 = np.transpose(temp_pred_lc_class01, (0,2,3,1))\n",
    "        temp_pred_lc_class02 = np.transpose(temp_pred_lc_class02, (0,2,3,1))\n",
    "        for idx in range(np.shape(pred_lc_class01)[0]):\n",
    "            cv2.imwrite(save_folder + 'pred_lc_patches_class01_' + str(idx)+ '_.png',temp_pred_lc_class01[idx] * 255)\n",
    "            cv2.imwrite(save_folder + 'pred_lc_patches_class02_' + str(idx)+ '_.png',temp_pred_lc_class02[idx]* 255)\n",
    "        \n",
    "    return pred_lc_class01, pred_lc_class02,pred_lc_thr_class01,pred_lc_thr_class02, new_h, new_w\n",
    "        \n",
    "    \n",
    "\n",
    "def lc_reconstruction_avg(patch_lc_pred, shape_inference, new_h, new_w,stride_gap,thr_mode, save_folder , debug_flag ):\n",
    "    lc_pred = patch_lc_pred\n",
    "    img_h = new_h; img_w = new_w\n",
    "    patch_h = shape_inference[0]; patch_w = shape_inference[1]\n",
    "    stride_h = stride_gap; stride_w = stride_gap\n",
    "    \n",
    "    full_prob = np.zeros((lc_pred.shape[1],img_h,img_w))  #itialize to zero mega array with sum of Probabilities\n",
    "    full_sum = np.zeros((lc_pred.shape[1],img_h,img_w))\n",
    "\n",
    "    k =0 \n",
    "    for h in range((img_h-patch_h)//stride_h+1):\n",
    "        for w in range((img_w-patch_w)//stride_w+1):\n",
    "            full_prob[:,h*stride_h:(h*stride_h)+patch_h,w*stride_w:(w*stride_w)+patch_w]+=lc_pred[k]\n",
    "            full_sum[:,h*stride_h:(h*stride_h)+patch_h,w*stride_w:(w*stride_w)+patch_w]+=1\n",
    "            k+=1\n",
    "    \n",
    "    print(np.min(full_sum))\n",
    "    assert(k==lc_pred.shape[0])\n",
    "    assert(np.min(full_sum)>=1.0)\n",
    "    \n",
    "    \n",
    "    final_avg = full_prob/full_sum\n",
    "    print (final_avg.shape)\n",
    "    print(np.max(final_avg))\n",
    "    assert(np.max(final_avg)<=1.0) #max value for a pixel is 1.0\n",
    "    assert(np.min(final_avg)>=0.0) #min value for a pixel is 0.0\n",
    "    \n",
    "    if debug_flag ==True:\n",
    "        temp_final_avg = np.transpose(final_avg,(1,2,0))\n",
    "        if thr_mode == 'threshold':\n",
    "            cv2.imwrite(save_folder+'reconst_thr_lc.png', temp_final_avg*255)\n",
    "        elif thr_mode == 'original':\n",
    "            cv2.imwrite(save_folder+'reconst_lc.png', temp_final_avg*255)\n",
    "\n",
    "    return final_avg\n",
    "\n",
    "def pred_reconstruction_oct(ori_img, lc_img, bbox, diff_h, diff_w, save_folder, debug_flag):\n",
    "    lc_img = lc_img > 0.40\n",
    "    row, col = np.nonzero(lc_img[0,:,:])\n",
    "    \n",
    "    add_row = bbox[1]; add_col = bbox[0]\n",
    "    row = row + add_row\n",
    "    col = col + add_col \n",
    "    \n",
    "    result_recon_ori = ori_img.copy()\n",
    "    result_recon_ori[row, col] = (0,255,0)\n",
    "    \n",
    "    cv2.imwrite(save_folder+'reconstruct_img.png',result_recon_ori)\n",
    "    return result_recon_ori\n",
    "    \n",
    "def fillHole(im_in):\n",
    "    im_floodfill = im_in.copy()\n",
    "\n",
    "    # Mask used to flood filling.\n",
    "    # Notice the size needs to be 2 pixels than the image.\n",
    "    h, w = im_in.shape[:2]\n",
    "    mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "    # Floodfill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    "\n",
    "    # Invert floodfilled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "\n",
    "    # Combine the two images to get the foreground.\n",
    "    im_out = im_in | im_floodfill_inv\n",
    "\n",
    "    return im_out\n",
    "\n",
    "\n",
    "def post_proc_recon_img(recon_img,shape_img, connect_thr_val,img_idx,save_folder, debug_flag):\n",
    "    temp_recon_img = np.zeros((shape_img[0], shape_img[1],1),dtype=np.uint8)\n",
    "    pred_row, pred_col = np.where(np.all(recon_img == (0,255,0), axis= -1))\n",
    "    temp_recon_img[pred_row, pred_col,0] = 255\n",
    "    \n",
    "    post_proc_label = np.zeros((np.shape(temp_recon_img)))\n",
    "\n",
    "    #show_on_jupyter(temp_recon_img[:,:,0],'gray')\n",
    "    temp = temp_recon_img[:,:,0]\n",
    "    #temp = fillHole(temp_recon_img[:,:,0])\n",
    "    if debug_flag == True:\n",
    "        show_on_jupyter(temp,'gray')\n",
    "    \n",
    "    num_lc_label, labeled_lc_map = cv2.connectedComponents(temp)\n",
    "    \n",
    "    biggest_lists = []\n",
    "    temp_biggest_label = []\n",
    "\n",
    "    if num_lc_label != 1:\n",
    "        for label_idx in range(1, num_lc_label):\n",
    "            temp_row, temp_col = np.where(labeled_lc_map == label_idx)\n",
    "            temp_biggest_label.append((len(temp_row), label_idx))\n",
    "    else:\n",
    "        temp_biggest_label.append((0,0))\n",
    "\n",
    "    temp_biggest_label = sorted(temp_biggest_label, reverse=True)\n",
    "    #print('labeled label idx : ',temp_biggest_label)\n",
    "    \n",
    "    num_lc_label, labeled_lc_map = cv2.connectedComponents(temp)\n",
    "    \n",
    "    for idx in range(num_lc_label-1):\n",
    "        #print('idx of temp biggest : ',temp_biggest_label[idx])\n",
    "        #print('temp biggest [idx][0] : {} [idx][1] : {}'.format(temp_biggest_label[idx][0], temp_biggest_label[idx][1]))\n",
    "        if temp_biggest_label[idx][0] > connect_thr_val:\n",
    "            post_row, post_col = np.where(labeled_lc_map == temp_biggest_label[idx][1])\n",
    "            post_proc_label[post_row, post_col,0] = 255\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    if debug_flag == True:\n",
    "        cv2.imwrite(save_folder+'post_proc_lc'+ str(img_idx)+'.png', post_proc_label)\n",
    "        show_on_jupyter(post_proc_label[:,:,0].astype(np.uint8), 'gray')\n",
    "\n",
    "    return post_proc_label\n",
    "    \n",
    "\n",
    "    \n",
    "def diff_spline_fitting_reconNori_img(ori_label,recon_img,shape_img,spline_order, ori_img, debug_flag):\n",
    "    '''\n",
    "    [TO-DO]\n",
    "        - visualization spline fitting result (ori <-> recon)\n",
    "        - Blend-altman plot\n",
    "    '''\n",
    "    \n",
    "    from scipy.interpolate import interp1d\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.optimize import curve_fit\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    _x_convert = 12.5000\n",
    "    _y_convert = 3.9216\n",
    "    \n",
    "    temp_img = np.zeros((shape_img[0], shape_img[1], 3))\n",
    "    label_row, label_col = np.where(np.all(ori_label == (255,0,0),axis=-1))\n",
    "    \n",
    "    #temp_recon = np.zeros((shape_img[0], shape_img[1], 3), dtype=np.float32)\n",
    "    \n",
    "    pred_row, pred_col = np.nonzero(recon_img[:,:,0])\n",
    "    \n",
    "    temp_img[label_row, label_col ,: ] = (255,0,0)\n",
    "    temp_img[pred_row, pred_col , : ] = (0,255,0)\n",
    "    temp_img = temp_img.astype(np.uint8)\n",
    "    \n",
    "    if debug_flag == True:\n",
    "        show_on_jupyter(temp_img)\n",
    "    temp_ori = ori_img.copy()\n",
    "    temp_ori[label_row, label_col,:]= (255,0,0)\n",
    "    temp_ori[pred_row, pred_col , : ] = (0,255,0)\n",
    "    if debug_flag == True:\n",
    "        show_on_jupyter(temp_ori)\n",
    "\n",
    "    #print('label col shape : {} pred col shape: {}: '.format(label_col.shape, pred_col.shape))\n",
    "    flat_label_col = label_col.reshape(-1,1)\n",
    "    flat_label_row = label_row.reshape(-1,1)\n",
    "    \n",
    "    flat_pred_col = pred_col.reshape(-1,1)\n",
    "    flat_pred_row = pred_row.reshape(-1,1)\n",
    "    \n",
    "    new_label_x = np.linspace(np.min(label_col), np.max(label_col),int(np.max(label_col) -np.min(label_col)+1))\n",
    "    new_pred_x = np.linspace(np.min(pred_col), np.max(pred_col), int(np.max(pred_col) - np.min(pred_col)+1))\n",
    "    \n",
    "    #print('flat label col shape : {}'.format(flat_label_col.shape))\n",
    "\n",
    "    '''\n",
    "    numpy polyfit version\n",
    "    \n",
    "    label_regression_coef = np.polyfit(label_col, label_row ,spline_order)\n",
    "    pred_regression_coef = np.polyfit(pred_col , pred_row,spline_order)\n",
    "    print('polynomal coef : ', label_regression_coef)\n",
    "    \n",
    "    label_poly = np.poly1d(label_regression_coef)\n",
    "    pred_poly = np.poly1d(pred_regression_coef)\n",
    "    \n",
    "    \n",
    "    new_label_y = label_poly(new_label_x)\n",
    "    new_pred_y = pred_poly(new_pred_x)\n",
    "    \n",
    "    print('nmpy label pred : {} \\n\\n shape : {} '.format(new_label_y,new_label_y.shape))\n",
    "    '''\n",
    "    \n",
    "    #### sklearn poly fit experiment, (For apply the regularization term)\n",
    "    label_polyreg = make_pipeline(\n",
    "        PolynomialFeatures(degree=spline_order, include_bias=False),\n",
    "        Ridge(alpha=0.01,solver='cholesky',normalize=True)\n",
    "        )\n",
    "    label_polyreg.fit(flat_label_col, flat_label_row)\n",
    "    \n",
    "    pred_polyreg = make_pipeline(\n",
    "        PolynomialFeatures(degree=spline_order, include_bias=False),\n",
    "        Ridge(alpha=0.01,solver='cholesky',normalize=True)\n",
    "        )\n",
    "    pred_polyreg.fit(flat_pred_col, flat_pred_row)\n",
    "    #print('new label shape : {} new pred shape : {}'.format(new_label_x.shape, new_pred_x.shape))\n",
    "    new_label_y = label_polyreg.predict(new_label_x.reshape(-1,1))\n",
    "    new_pred_y = pred_polyreg.predict(new_pred_x.reshape(-1,1))\n",
    "    new_label_y = new_label_y[:,0]\n",
    "    new_pred_y = new_pred_y[:,0]\n",
    "    #print('new label shape : {} new pred shape : {}'.format(new_label_y, new_pred_y))\n",
    "    ########    ########    ########    ########    ########    ########\n",
    "    \n",
    "    h, w = np.shape(ori_img)[0], np.shape(ori_img)[1]\n",
    "\n",
    "    new_int_label_x = new_label_x.astype(np.uint16)\n",
    "    new_int_label_y = np.around(new_label_y).astype(np.uint16)\n",
    "    #print('int label : {}'.format(new_int_label_y))\n",
    "    \n",
    "    new_int_pred_x = new_pred_x.astype(np.uint16)\n",
    "    new_int_pred_y = np.around(new_pred_y).astype(np.uint16)\n",
    "    \n",
    "    temp_poly = ori_img.copy()\n",
    "    temp_mask_poly = np.zeros((shape_img[0], shape_img[1], 3), dtype=np.uint16)\n",
    "    temp_poly[new_int_pred_y, new_int_pred_x] = (0,255,0)\n",
    "    temp_mask_poly[new_int_pred_y, new_int_pred_x] = (0,255,0)\n",
    "    \n",
    "    \n",
    "    temp_label_poly = np.zeros((shape_img[0], shape_img[1], 3), dtype=np.uint16)\n",
    "    temp_label_poly[new_int_label_y, new_int_label_x] = (0,255,0)\n",
    " \n",
    "    \n",
    "    if len(new_label_x) > len(new_pred_x): # new pred x에 맞춰 진행 (작은쪽))\n",
    "        min_idx = np.where(np.min(np.floor(new_pred_x)) == np.floor(new_label_x))\n",
    "        if min_idx[0].size == 0:\n",
    "            min_idx = np.where(np.floor(new_pred_x) == np.min(np.floor(new_label_x)))\n",
    "            \n",
    "        max_idx = np.where(np.max(np.floor(new_pred_x)) == np.floor(new_label_x))\n",
    "        if max_idx[0].size == 0:\n",
    "            max_idx = np.where(np.floor(new_pred_x) == np.max(np.floor(new_label_x)))\n",
    "        #print('min idx : {} max idx : {}'.format(min_idx, max_idx))\n",
    "        #print('min idx : {} max idx : {}'.format(min_idx[0][0], max_idx[0][0]))\n",
    "        \n",
    "        mean_diff = np.zeros(int(max_idx[0][0]) - int(min_idx[0][0]) + 1,dtype=np.float32)\n",
    "        mean_ym_diff = np.zeros(int(max_idx[0][0]) - int(min_idx[0][0]) + 1,dtype=np.float32)\n",
    "        \n",
    "        pred_idx = 0\n",
    "        for label_idx in range(min_idx[0][0] , max_idx[0][0]):\n",
    "            mean_diff[pred_idx] = np.abs(new_label_y[label_idx] - new_pred_y[pred_idx])\n",
    "            mean_ym_diff[pred_idx] = np.abs(new_label_y[label_idx] - new_pred_y[pred_idx]) * _y_convert\n",
    "            #print(' label x : {} '.format(new_label_x[label_idx]))\n",
    "            #print(' pred x : {} '.format(new_pred_x[pred_idx]))\n",
    "            pred_idx = pred_idx +1\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        min_idx = np.where(np.min(np.floor(new_label_x)) == np.floor(new_pred_x))\n",
    "        if min_idx[0].size == 0:\n",
    "            min_idx = np.where(np.floor(new_label_x) == np.min(np.floor(new_pred_x)))\n",
    "        max_idx = np.where(np.max(np.floor(new_label_x)) == np.floor(new_pred_x))\n",
    "        if max_idx[0].size ==0:\n",
    "            max_idx = np.where(np.floor(new_label_x) == np.max(np.floor(new_pred_x)))\n",
    "        #print('min idx : {} max idx : {}'.format(min_idx, max_idx))\n",
    "        #print('min idx : {} max idx : {}'.format(min_idx[0][0], max_idx[0][0]))\n",
    "        mean_diff = np.zeros(int(max_idx[0][0]) - int(min_idx[0][0]) + 1,dtype=np.float32)\n",
    "        mean_ym_diff = np.zeros(int(max_idx[0][0]) - int(min_idx[0][0]) + 1,dtype=np.float32)\n",
    "        \n",
    "        \n",
    "        label_idx = 0\n",
    "        for pred_idx in range(min_idx[0][0] , max_idx[0][0]):\n",
    "            mean_diff[label_idx] = np.abs(new_label_y[label_idx] - new_pred_y[pred_idx])\n",
    "            mean_ym_diff[label_idx] = np.abs(new_label_y[label_idx] - new_pred_y[pred_idx]) * _y_convert\n",
    "            #print(' label x : {} '.format(new_label_x[label_idx]))\n",
    "            #print(' pred x : {} '.format(new_pred_x[pred_idx]))\n",
    "            label_idx = label_idx+1\n",
    "    \n",
    "    #plt.plot(label_col, label_row, \"o\", new_label_x, new_label_y)\n",
    "    #plt.plot(pred_col, pred_row, \"g\", new_pred_x, new_pred_y)\n",
    "    \n",
    "    if debug_flag == True:\n",
    "        #plt.plot(new_label_x, new_label_y, \"r\")\n",
    "        plt.plot(new_pred_x, new_pred_y ,\"g\")\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    return np.mean(mean_diff),np.mean(mean_ym_diff), temp_poly, temp_mask_poly,temp_label_poly, label_polyreg, pred_polyreg\n",
    "    \n",
    "    \n",
    "def prediction_reports(label_img, pred_img,shape_img,ori_img,save_folder):\n",
    "    \n",
    "    reports_label_img = np.zeros((shape_img[0], shape_img[1]))\n",
    "    reports_pred_img = np.zeros((shape_img[0], shape_img[1]))\n",
    "    temp_ori_img = ori_img.copy()\n",
    "    \n",
    "    \n",
    "    label_row, label_col = np.where(np.all(label_img == (255,0,0),axis=-1))\n",
    "    pred_row, pred_col = np.nonzero(pred_img[:,:,0])\n",
    "    cv2.imwrite(save_folder + 'raw_img.png', temp_ori_img)\n",
    "    temp_ori_img[pred_row, pred_col] = (0,0,255)\n",
    "    cv2.imwrite(save_folder + 'raw_pred_img.png', temp_ori_img)\n",
    "    temp_ori_img[label_row, label_col] = (255,0,0)\n",
    "    \n",
    "    #print('row : {} col : {}'.format(label_row, label_col))\n",
    "    concat_label_pred_row = np.concatenate((label_row, pred_row),axis = 0)\n",
    "    concat_label_pred_col = np.concatenate((label_col, pred_col),axis = 0)\n",
    "\n",
    "    max_concat_row = np.max(concat_label_pred_row)\n",
    "    min_concat_row = np.min(concat_label_pred_row)\n",
    "    max_concat_col = np.max(concat_label_pred_col)\n",
    "    min_concat_col = np.min(concat_label_pred_col)\n",
    "    \n",
    "    norm_label_row = np.array((label_row - min_concat_row) / (max_concat_row - min_concat_row),dtype=np.float32 )\n",
    "    norm_pred_row = np.array((pred_row - min_concat_row) / (max_concat_row - min_concat_row), dtype=np.float32)\n",
    "    norm_label_col = np.array((label_row - min_concat_col) / (max_concat_col - min_concat_col),dtype=np.float32 )\n",
    "    norm_pred_col = np.array((pred_row - min_concat_col) / (max_concat_col - min_concat_col), dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    norm_label_idx = zip(norm_label_row, norm_label_col)\n",
    "    norm_pred_idx = zip(norm_pred_row, norm_pred_col)\n",
    "    \n",
    "    label_idx = zip(label_row, label_col)\n",
    "    cv2.imwrite(save_folder + 'ground_img.png', temp_ori_img)\n",
    "    pred_idx = zip(pred_row, pred_col)\n",
    "    \n",
    "    label_coord= [z for z in label_idx]\n",
    "    pred_coord = [z for z in pred_idx]\n",
    "    norm_label_coord = [z for z in norm_label_idx]\n",
    "    norm_pred_coord = [z for z in norm_pred_idx]\n",
    "    \n",
    "    \n",
    "    distance_metric_array = get_distance_metric(label_coord, pred_coord, norm_label_coord, norm_pred_coord)\n",
    "    \n",
    "    \n",
    "    reports_label_img[label_row,label_col] = 1\n",
    "    reports_pred_img[pred_row, pred_col] = 1\n",
    "        \n",
    "    overlap_region = cv2.bitwise_and(reports_pred_img,reports_label_img)\n",
    "    temp_row, temp_col = np.nonzero(overlap_region)\n",
    "    \n",
    "\n",
    "    temp_ori_img[temp_row, temp_col] = (0,255,0)\n",
    "    cv2.imwrite(save_folder + 'different_img.png', temp_ori_img)\n",
    "     \n",
    "    overlap_region_cnt = len(temp_row)\n",
    "    \n",
    "    dice_coeff = (2* overlap_region_cnt) / (len(label_row) + len(pred_row))\n",
    "    jaccard_dist = overlap_region_cnt / (len(label_row) + len(pred_row) -overlap_region_cnt )\n",
    "    \n",
    "    \n",
    "    tp_cnt =  overlap_region_cnt\n",
    "    fp_cnt =  (len(label_row) + len(pred_row) - overlap_region_cnt) - len(label_row)\n",
    "    fn_cnt = (len(label_row) + len(pred_row) - overlap_region_cnt) - len(pred_row)\n",
    "    return dice_coeff, jaccard_dist, distance_metric_array\n",
    "    \n",
    "def get_distance_metric(label, pred,norm_label, norm_pred):\n",
    "    _x_convert = 12.5000\n",
    "    _y_convert = 3.9216\n",
    "    \n",
    "    from scipy.spatial.distance import directed_hausdorff\n",
    "    import similaritymeasures\n",
    "    distance_metric_array = np.zeros(7, dtype=np.float32)\n",
    "    \n",
    "    haus_dist = directed_hausdorff(label, pred)[0]\n",
    "    haus_idx = directed_hausdorff(label, pred)[1:]\n",
    "    \n",
    "    print('haus idx : ', haus_idx)\n",
    "    haus_label_coord = label[haus_idx[0]]\n",
    "    haus_pred_coord = pred[haus_idx[1]]\n",
    "    print('haus label coord : {}, haus pred coord : {}'.format(haus_label_coord, haus_pred_coord))\n",
    "    \n",
    "    ym_haus_dist = np.sqrt(np.square((haus_label_coord[0] - haus_pred_coord[0]) * _y_convert) + np.square((haus_label_coord[1] - haus_pred_coord[1]) * _x_convert) )\n",
    "    print(ym_haus_dist)\n",
    "    \n",
    "    frechet_dist = similaritymeasures.frechet_dist(label, pred)\n",
    "    dtw, d = similaritymeasures.dtw(label, pred)\n",
    "    \n",
    "    norm_haus_dist = directed_hausdorff(norm_label, norm_pred)[0]\n",
    "    norm_frechet_dist = similaritymeasures.frechet_dist(norm_label, norm_pred)\n",
    "    norm_dtw, norm_d = similaritymeasures.dtw(norm_label, norm_pred)\n",
    "    \n",
    "    distance_metric_array[0] = haus_dist\n",
    "    distance_metric_array[1] = frechet_dist\n",
    "    distance_metric_array[2] = dtw\n",
    "    distance_metric_array[3] = norm_haus_dist\n",
    "    distance_metric_array[4] = norm_frechet_dist\n",
    "    distance_metric_array[5] = norm_dtw\n",
    "    distance_metric_array[6] = ym_haus_dist\n",
    "    \n",
    "    return distance_metric_array\n",
    "    \n",
    "def test_diff_spline_fitting_reconNori_img(recon_img,shape_img,spline_order, ori_img, debug_flag):\n",
    "    '''\n",
    "    [TO-DO]\n",
    "        - visualization spline fitting result (ori <-> recon)\n",
    "        - Blend-altman plot\n",
    "    '''\n",
    "    \n",
    "    from scipy.interpolate import interp1d\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.optimize import curve_fit\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "    _x_convert = 12.5000\n",
    "    _y_convert = 3.9216\n",
    "    \n",
    "    temp_img = np.zeros((shape_img[0], shape_img[1], 3))\n",
    "    \n",
    "    #temp_recon = np.zeros((shape_img[0], shape_img[1], 3), dtype=np.float32)\n",
    "    \n",
    "    pred_row, pred_col = np.nonzero(recon_img[:,:,0])\n",
    "    temp_img[pred_row, pred_col , : ] = (0,255,0)\n",
    "    temp_img = temp_img.astype(np.uint8)\n",
    "    \n",
    "    if debug_flag == True:\n",
    "        show_on_jupyter(temp_img)\n",
    "    temp_ori = ori_img.copy()\n",
    "    temp_ori[pred_row, pred_col , : ] = (0,255,0)\n",
    "    if debug_flag == True:\n",
    "        show_on_jupyter(temp_ori)\n",
    "\n",
    "    \n",
    "    flat_pred_col = pred_col.reshape(-1,1)\n",
    "    flat_pred_row = pred_row.reshape(-1,1)\n",
    "    \n",
    "    new_pred_x = np.linspace(np.min(pred_col), np.max(pred_col), int(np.max(pred_col) - np.min(pred_col)+1))\n",
    "    \n",
    "    \n",
    "    #### sklearn poly fit experiment, (For apply the regularization term)\n",
    "    \n",
    "    pred_polyreg = make_pipeline(\n",
    "        PolynomialFeatures(degree=spline_order, include_bias=False),\n",
    "        Ridge(alpha=0.005,solver='cholesky',normalize=True)\n",
    "        )\n",
    "   \n",
    "    pred_polyreg.fit(flat_pred_col, flat_pred_row)\n",
    "    \n",
    "    #print('new label shape : {} new pred shape : {}'.format(new_label_x.shape, new_pred_x.shape))\n",
    "    new_pred_y = pred_polyreg.predict(new_pred_x.reshape(-1,1))\n",
    "    new_pred_y = new_pred_y[:,0]\n",
    "    #print('new label shape : {} new pred shape : {}'.format(new_label_y, new_pred_y))\n",
    "    ########    ########    ########    ########    ########    ########\n",
    "    \n",
    "    h, w = np.shape(ori_img)[0], np.shape(ori_img)[1]\n",
    "    \n",
    "    new_int_pred_x = new_pred_x.astype(np.uint16)\n",
    "    new_int_pred_y = np.around(new_pred_y).astype(np.uint16)\n",
    "    \n",
    "    temp_poly = ori_img.copy()\n",
    "    temp_mask_poly = np.zeros((shape_img[0], shape_img[1], 3), dtype=np.uint16)\n",
    "    temp_poly[new_int_pred_y, new_int_pred_x] = (0,255,0)\n",
    "    temp_mask_poly[new_int_pred_y, new_int_pred_x] = (0,255,0)\n",
    "    \n",
    "    \n",
    "    if debug_flag == True:\n",
    "        #plt.plot(new_label_x, new_label_y, \"r\")\n",
    "        plt.plot(new_pred_x, new_pred_y ,\"g\")\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    return temp_poly, temp_mask_poly, pred_polyreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_experiment = 'final_paper_debug_noReg/'\n",
    "dir_checker('./pipe_result/'+name_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam\n",
    "debug_flag = True\n",
    "save_folder = './pipe_result/'+str(name_experiment)+'/lc_processing/'\n",
    "dir_checker(save_folder)\n",
    "stride_gap = 10\n",
    "\n",
    "save_folder2 = './pipe_result/'+str(name_experiment)+'/lc_reconstruction/'\n",
    "dir_checker(save_folder2)\n",
    "\n",
    "spline_order = 30\n",
    "curve_fit_method =  'non_linear'\n",
    "connect_thr_val = 50\n",
    "save_folder3 = './pipe_result/'+str(name_experiment)+'/post_proc/'\n",
    "dir_checker(save_folder3)\n",
    "\n",
    "real_copy_ori_img = RESULT_IMGS.copy()\n",
    "# processing\n",
    "all_mean_diff = []\n",
    "all_mean_ym_diff = []\n",
    "unknown_cnt =0 \n",
    "\n",
    "# prediction reports\n",
    "mean_dice = []; mean_jaccard = []\n",
    "mean_haus = []; mean_frechet = []; mean_dtw = []\n",
    "mean_norm_haus = []; mean_norm_frechet = []; mean_norm_dtw = []\n",
    "mean_ym_haus = []\n",
    "\n",
    "label_coef_lists = []\n",
    "pred_coef_lists = []\n",
    "\n",
    "\n",
    "LC_POLY_GT = np.zeros(((NUM_YOLO_RESULT,500, 760, 3)),dtype=np.uint8)\n",
    "\n",
    "for idx in range(NUM_YOLO_RESULT):\n",
    "#for idx in range(10):\n",
    "    save_folder = './pipe_result/'+str(name_experiment)+'/lc_processing/' + str(idx)+'/'\n",
    "    save_folder2 = './pipe_result/'+str(name_experiment)+'/lc_reconstruction/' +str(idx)+ '/'\n",
    "    dir_checker(save_folder)\n",
    "    dir_checker(save_folder2)\n",
    "    \n",
    "    lc_xmin = int(YOLO_RESULT_TABLE.iloc[idx]['lc_xmin'])\n",
    "    lc_ymin = int(YOLO_RESULT_TABLE.iloc[idx]['lc_ymin'])\n",
    "    lc_xmax = int(YOLO_RESULT_TABLE.iloc[idx]['lc_xmax'])\n",
    "    lc_ymax = int(YOLO_RESULT_TABLE.iloc[idx]['lc_ymax'])\n",
    "    lc_bbox_coord = (lc_xmin,lc_ymin, lc_xmax, lc_ymax)\n",
    "    temp_ori_img = ORI_IMGS[idx]\n",
    "    \n",
    "    # pred_lc_class02 -> lc prediction\n",
    "    pred_lc_class01, pred_lc_class02,pred_lc_thr_class01,pred_lc_thr_class02,new_h, new_w = lc_overlap_tile_prediction(temp_ori_img, model,\n",
    "                                                                lc_bbox_coord,stride_gap, \n",
    "                                                              NUM_YOLO_RESULT,INFERENCE_SHAPE,\n",
    "                                                              save_folder, debug_flag)\n",
    "    \n",
    "    avg_recon_lc = lc_reconstruction_avg(pred_lc_class02, INFERENCE_SHAPE, new_h, new_w,stride_gap,\n",
    "                                        'original',save_folder2, debug_flag)\n",
    "    \n",
    "    avg_recon_thr_lc = lc_reconstruction_avg(pred_lc_thr_class02, INFERENCE_SHAPE, new_h, new_w,stride_gap,\n",
    "                                        'threshold',save_folder2 ,debug_flag)\n",
    "        \n",
    "    prev_h = int(lc_ymax - lc_ymin); prev_w = int(lc_xmax - lc_xmin)\n",
    "    diff_h = new_h - prev_h; diff_w = new_w - prev_w\n",
    "    recon_pred_img = pred_reconstruction_oct(temp_ori_img, avg_recon_lc, lc_bbox_coord, \n",
    "                            diff_h, diff_w, save_folder2, debug_flag)\n",
    "    \n",
    "    post_recon_img = post_proc_recon_img(recon_pred_img, SHAPE_YOLO_RESULT, connect_thr_val,idx, save_folder3, debug_flag)\n",
    "    temp_check_row , temp_check_col = np.nonzero(post_recon_img[:,:,0])\n",
    "    if len(temp_check_row) !=0:\n",
    "        if VALID_TEST == 'valid':\n",
    "            mean_diff,mean_ym_diff, RESULT_IMGS[idx], RESULT_IMGS_MASKS[idx],LC_POLY_GT[idx], temp_label_coef, temp_pred_coef = diff_spline_fitting_reconNori_img(GROUND_TRUTH_IMG[idx], post_recon_img, SHAPE_YOLO_RESULT,spline_order, ORI_IMGS[idx], debug_flag)\n",
    "            print('label coef : ', temp_label_coef)\n",
    "            print('pref coef : ', temp_pred_coef)\n",
    "            label_coef_lists.append(temp_label_coef); pred_coef_lists.append(temp_pred_coef)\n",
    "\n",
    "            all_mean_diff.append(mean_diff)\n",
    "            all_mean_ym_diff.append(mean_ym_diff)\n",
    "            dice_score, jaccard, dist_array = prediction_reports(GROUND_TRUTH_IMG[idx], post_recon_img,SHAPE_YOLO_RESULT,ORI_IMGS[idx],save_folder2)\n",
    "            mean_dice.append(dice_score); mean_jaccard.append(jaccard)\n",
    "            mean_haus.append(dist_array[0]); mean_frechet.append(dist_array[1]); mean_dtw.append(dist_array[2])\n",
    "            mean_norm_haus.append(dist_array[3]); mean_norm_frechet.append(dist_array[4])\n",
    "            mean_norm_dtw.append(dist_array[5])\n",
    "            mean_ym_haus.append(dist_array[6])\n",
    "        elif VALID_TEST == 'test':\n",
    "            RESULT_IMGS[idx], RESULT_IMGS_MASKS[idx],temp_pred_coef = test_diff_spline_fitting_reconNori_img(post_recon_img, SHAPE_YOLO_RESULT,spline_order, ORI_IMGS[idx], debug_flag)\n",
    "            pred_coef_lists.append(temp_pred_coef)\n",
    "    else:\n",
    "        unknown_cnt = unknown_cnt+1\n",
    "        pass\n",
    "    \n",
    "    #spline_fitting_recon_img(avg_recon_thr_lc,5)\n",
    "    #post_proc_recon_img(avg_recon_lc,0.4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_table = pd.DataFrame(columns= ['Mean dice', 'Mean jaccard', 'Mean average y-diff', 'Std average y-diff'])\n",
    "\n",
    "curve_sim_table = pd.DataFrame(columns=['Mean haus dist','Std haus dist', 'Mean frechet dist','Std frechet dist', 'Mean DTW', 'Std DTW'])\n",
    "curve_sim_norm_table = pd.DataFrame(columns=['Mean norm haus dist','Std norm haus dist', 'Mean norm frechet dist','Std norm frechet dist', 'Mean norm DTW','Std norm DTW'])\n",
    "\n",
    "ym_result_table = pd.DataFrame(columns=['Mean ym average y-diff', 'Std ym average y-diff', 'Mean ym haus dist', 'Std ym haus dist'])\n",
    "\n",
    "segmentation_table.loc[0,'Mean dice'] = np.mean(mean_dice) ; segmentation_table.loc[0,'Mean jaccard'] = np.mean(mean_jaccard)\n",
    "segmentation_table.loc[0,'Mean average y-diff'] = np.mean(all_mean_diff); segmentation_table.loc[0,'Std average y-diff'] = np.std(all_mean_diff)\n",
    "\n",
    "curve_sim_table.loc[0, 'Mean hasu dist'] = np.mean(mean_haus); curve_sim_table.loc[0, 'Std hasu dist'] = np.std(mean_haus);\n",
    "curve_sim_table.loc[0, 'Mean frechet dist'] = np.mean(mean_frechet); curve_sim_table.loc[0, 'Std frechet dist'] = np.std(mean_frechet);\n",
    "curve_sim_table.loc[0, 'Mean DTW'] = np.mean(mean_dtw); curve_sim_table.loc[0, 'Std DTW'] = np.std(mean_dtw);\n",
    "\n",
    "curve_sim_norm_table.loc[0, 'Mean norm hasu dist'] = np.mean(mean_norm_haus); curve_sim_table.loc[0, 'Std norm hasu dist'] = np.std(mean_norm_haus);\n",
    "curve_sim_norm_table.loc[0, 'Mean norm frechet dist'] = np.mean(mean_norm_frechet); curve_sim_table.loc[0, 'Std norm frechet dist'] = np.std(mean_norm_frechet);\n",
    "curve_sim_norm_table.loc[0, 'Mean norm DTW'] = np.mean(mean_norm_dtw); curve_sim_table.loc[0, 'Std norm DTW'] = np.std(mean_norm_dtw);\n",
    "\n",
    "\n",
    "#[TODO] mean ym diff -> all mean ym diff\n",
    "ym_result_table.loc[0,'Mean ym average y-diff'] =  np.mean(all_mean_ym_diff); ym_result_table.loc[0,'Std ym average y-diff'] =  np.std(all_mean_ym_diff)\n",
    "ym_result_table.loc[0,'Mean ym haus dist'] =  np.mean(mean_ym_haus); ym_result_table.loc[0,'Std ym haus dist'] =  np.std(mean_ym_haus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = './pipe_result/'+str(name_experiment)\n",
    "\n",
    "fig,ax = render_mpl_table(segmentation_table, header_columns=0, col_width=4.0)\n",
    "fig.savefig(save_folder +'/'+str(spline_order) +'_segmentation_table.png')\n",
    "\n",
    "fig,ax = render_mpl_table(curve_sim_table, header_columns=0, col_width=4.0)\n",
    "fig.savefig(save_folder +'/'+str(spline_order) + '_curve_sim_table.png')\n",
    "\n",
    "fig,ax = render_mpl_table(curve_sim_norm_table, header_columns=0, col_width=4.0)\n",
    "fig.savefig(save_folder +'/'+str(spline_order) + '_norm_curve_sim_table.png')\n",
    "\n",
    "fig,ax = render_mpl_table(ym_result_table, header_columns=0, col_width=4.0)\n",
    "fig.savefig(save_folder +'/'+str(spline_order) + '_ym_result_table.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dice score : ', np.mean(mean_dice))\n",
    "print('jaccard score : ', np.mean(mean_jaccard))\n",
    "print('all mean diff : ',np.mean(all_mean_diff))\n",
    "print('all std diff : ',np.std(all_mean_diff))\n",
    "\n",
    "print('mean hausdorff distance : ', np.mean(mean_haus))\n",
    "print('mean frechet distance  : ', np.mean(mean_frechet))\n",
    "print('mean dynamic time warping  : ',np.mean(mean_dtw))\n",
    "\n",
    "print('mean normalized hausdorff distance : ', np.mean(mean_norm_haus))\n",
    "print('mean normalized frechet distance  : ', np.mean(mean_norm_frechet))\n",
    "print('mean normalized dynamic time warping  : ',np.mean(mean_norm_dtw))\n",
    "\n",
    "print('std hausdorff distance : ', np.std(mean_haus))\n",
    "print('std frechet distance  : ', np.std(mean_frechet))\n",
    "print('std dynamic time warping  : ',np.std(mean_dtw))\n",
    "\n",
    "print('std normalized hausdorff distance : ', np.std(mean_norm_haus))\n",
    "print('std normalized frechet distance  : ', np.std(mean_norm_frechet))\n",
    "print('std normalized dynamic time warping  : ',np.std(mean_norm_dtw))\n",
    "\n",
    "print('mean ym average y-diff : ', np.mean(mean_ym_diff))\n",
    "print('std ym average y-diff : ', np.std(mean_ym_diff))\n",
    "print('mean ym hausdorff distance : ', np.mean(mean_ym_haus))\n",
    "print('std ym hausdorff distance : ', np.std(mean_ym_haus))\n",
    "\n",
    "\n",
    "print('unknown cnt : ', unknown_cnt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _neighbors_conv(image):\n",
    "    import scipy.ndimage as ndi\n",
    "\n",
    "    \"\"\"\n",
    "    Counts the neighbor pixels for each pixel of an image:\n",
    "            x = [\n",
    "                [0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]\n",
    "            ]\n",
    "            _neighbors(x)\n",
    "            [\n",
    "                [0, 3, 0],\n",
    "                [3, 4, 3],\n",
    "                [0, 3, 0]\n",
    "            ]\n",
    "    :type image: numpy.ndarray\n",
    "    :param image: A two-or-three dimensional image\n",
    "    :return: neighbor pixels for each pixel of an image\n",
    "    \"\"\"\n",
    "    image = image.astype(np.int)\n",
    "    k = np.array([[1,1,1],[1,0,1],[1,1,1]])\n",
    "    neighborhood_count = ndi.convolve(image,k, mode='constant', cval=1)\n",
    "    neighborhood_count[~image.astype(np.bool)] = 0\n",
    "    return neighborhood_count\n",
    "\n",
    "def get_slope(first_point, second_point):\n",
    "    (x1, y1) = (first_point[1],first_point[0])\n",
    "    (x2, y2) = (second_point[1],second_point[0])\n",
    "    slope = ((y2-y1)/(x2-x1))\n",
    "    return slope\n",
    "\n",
    "def get_intersection_perpendicular_n_line(line_p1, line_p2, per_above_points):\n",
    "    '''\n",
    "    line : y = ax + b\n",
    "    perpen line : y = (-1/a)x + c\n",
    "    \n",
    "    1. we know the point of above to perpendicular line -> (x_p, y_p)\n",
    "    2. y_p = (-1/a)x_p + c -> can find the 'c'\n",
    "    3. Example) y = x + 3 / y = -x -7 (a,b) -> intersectin\n",
    "       b = a + 3 / b = -a - 7\n",
    "    4. ax + b = -(1/a)x + c\n",
    "       ax + (1/a)x= c - b\n",
    "       (a + 1/a)x = c - b\n",
    "       x = (c - b) / (a + 1/a)\n",
    "    \n",
    "    '''\n",
    "    line_slope = (line_p1[0] - line_p2[0]) / (line_p1[1] - line_p2[1])\n",
    "    line_constant = line_p1[0] - (line_slope * line_p1[1])\n",
    "    \n",
    "    perpen_slope = -1/line_slope\n",
    "    perpen_constant = per_above_points[0] - (perpen_slope * per_above_points[1])\n",
    "    \n",
    "    xi = (perpen_constant - line_constant) / (line_slope + (1/line_slope))\n",
    "    yi = (line_slope * xi) + line_constant\n",
    "    \n",
    "    return np.array((yi, xi), dtype=np.uint16)\n",
    "    \n",
    "    \n",
    "\n",
    "def get_perpendicular_dist(line_1_point, line_2_point, target_points_row, target_points_col):\n",
    "    '''\n",
    "    code from : https://stackoverflow.com/questions/39840030/distance-between-point-and-a-line-from-two-points/39840218\n",
    "    line_1_point : 'point not points!' Max or min point\n",
    "    line_2_point ; Max or min point\n",
    "    \n",
    "    target_points_row :\n",
    "    target_points_col : \n",
    "    \n",
    "    '''\n",
    "    d_arr = np.zeros(len(target_points_row), dtype=np.float32)\n",
    "    # row, col\n",
    "    p1 = np.array((line_1_point[1], line_1_point[0]))\n",
    "    p2 = np.array((line_2_point[1], line_2_point[0]))\n",
    "    print('p1 , p2 : {} {} ', p1, p2)\n",
    "    \n",
    "    '''\n",
    "    [TODO]\n",
    "        curve depth -> check the their depth (+ or -)\n",
    "        \n",
    "    '''\n",
    "    for idx in range(len(target_points_row)):\n",
    "        p3 = np.array((target_points_col[idx], target_points_row[idx]))\n",
    "        #\n",
    "        d = np.linalg.norm(np.cross(p2-p1, p1-p3))/np.linalg.norm(p2-p1)\n",
    "        #print('cross product : ',np.cross(p2-p1, p1-p3))\n",
    "        if np.cross(p2-p1, p1-p3) >= 0:\n",
    "            d = -d\n",
    "        d_arr[idx] = d\n",
    "        #print(d)\n",
    "    \n",
    "    max_d = np.max(d_arr)\n",
    "    max_d_idx = np.where(d_arr == np.max(d_arr))\n",
    "    print('max_d : ',max_d)\n",
    "    print('max d idx : ', max_d_idx)\n",
    "    #print('max coord row : {} col : {} '.format(target_points_row[max_d_idx], target_points_col[max_d_idx]))\n",
    "    max_coord = np.array((target_points_row[max_d_idx], target_points_col[max_d_idx]))\n",
    "    print('max coord ',max_coord)\n",
    "    #return max_d, max_coord\n",
    "    if len(max_coord[0]) ==1:\n",
    "        print('max coord len == 1 ')\n",
    "        return max_d, max_coord\n",
    "    else:\n",
    "        print('max coord len > 1 ')\n",
    "        print('max coord[0][0] [0][1] ',target_points_row[max_d_idx][0],target_points_col[max_d_idx][0])\n",
    "        return max_d, (target_points_row[max_d_idx][0],target_points_col[max_d_idx][0])\n",
    "    \n",
    "#### draw \n",
    "\n",
    "\n",
    "def createLineIterator(P1, P2, img, flag = False):\n",
    "    \"\"\"\n",
    "    Produces and array that consists of the coordinates and intensities of each pixel in a line between two points\n",
    "\n",
    "    Parameters:\n",
    "        -P1: a numpy array that consists of the coordinate of the first point (x,y)\n",
    "        -P2: a numpy array that consists of the coordinate of the second point (x,y)\n",
    "        -img: the image being processed\n",
    "\n",
    "    Returns:\n",
    "        -it: a numpy array that consists of the coordinates and intensities of each pixel in the radii (shape: [numPixels, 3], row = [x,y,intensity])     \n",
    "    \"\"\"\n",
    "    #define local variables for readability\n",
    "    imageH = img.shape[0]\n",
    "    imageW = img.shape[1]\n",
    "    P1X = P1[0]\n",
    "    P1Y = P1[1]\n",
    "    P2X = P2[0]\n",
    "    P2Y = P2[1]\n",
    "\n",
    "    #difference and absolute difference between points\n",
    "    #used to calculate slope and relative location between points\n",
    "    dX = P2X - P1X\n",
    "    dY = P2Y - P1Y\n",
    "    dXa = np.abs(dX)\n",
    "    dYa = np.abs(dY)\n",
    "\n",
    "    #predefine numpy array for output based on distance between points\n",
    "    itbuffer = np.empty(shape=(np.maximum(dYa,dXa),3),dtype=np.float32)\n",
    "    itbuffer.fill(np.nan)\n",
    "\n",
    "    #Obtain coordinates along the line using a form of Bresenham's algorithm\n",
    "    negY = P1Y > P2Y\n",
    "    negX = P1X > P2X\n",
    "    if P1X == P2X: #vertical line segment\n",
    "        itbuffer[:,0] = P1X\n",
    "        if negY:\n",
    "            itbuffer[:,1] = np.arange(P1Y - 1,P1Y - dYa - 1,-1)\n",
    "        else:\n",
    "            itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)              \n",
    "    elif P1Y == P2Y: #horizontal line segment\n",
    "        itbuffer[:,1] = P1Y\n",
    "        if negX:\n",
    "            itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\n",
    "        else:\n",
    "            itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\n",
    "    else: #diagonal line segment\n",
    "        steepSlope = dYa > dXa\n",
    "        if steepSlope:\n",
    "            slope = dX.astype(np.float32)/dY.astype(np.float32)\n",
    "            #print('slope : ' , slope)\n",
    "            if negY:\n",
    "                itbuffer[:,1] = np.arange(P1Y-1,P1Y-dYa-1,-1)\n",
    "            else:\n",
    "                itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)\n",
    "            #print(itbuffer)\n",
    "            itbuffer[:,0] = (slope*(itbuffer[:,1]-P1Y)).astype(np.int) + P1X\n",
    "        else:\n",
    "            slope = dY.astype(np.float32)/dX.astype(np.float32)\n",
    "            #print('slope : ' , slope)\n",
    "            if negX:\n",
    "                itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\n",
    "            else:\n",
    "                itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\n",
    "            #print(itbuffer)\n",
    "            itbuffer[:,1] = (slope*(itbuffer[:,0]-P1X)).astype(np.int) + P1Y\n",
    "\n",
    "   #Remove points outside of image\n",
    "    colX = itbuffer[:,0]\n",
    "    colY = itbuffer[:,1]\n",
    "    #print('colY : ',colY)\n",
    "    #print('max colY :', max(colY))\n",
    "    if flag == 'max':\n",
    "        max_idx = np.where(colY == int(max(colY)))\n",
    "        #print('max : ',max_idx[0][0])\n",
    "        max_idx = max_idx[0][0]\n",
    "        #print('colX : ',colX)\n",
    "        #print('colY : ',colY)\n",
    "        return itbuffer, (colX[max_idx], colY[max_idx])\n",
    "    elif flag == 'min':\n",
    "        min_idx = np.where(colY == int(min(colY)))\n",
    "        #print('max : ',max_idx[0][0])\n",
    "        min_idx = min_idx[0][0]\n",
    "        #print('colX : ',colX)\n",
    "        #print('colY : ',colY)\n",
    "        return itbuffer, (colX[min_idx], colY[min_idx])\n",
    "    #print(itbuffer)\n",
    "    \n",
    "    #itbuffer = itbuffer[(colX >= 0) & (colY >=0) & (colX<imageW) & (colY<imageH)]\n",
    "    #print(itbuffer)\n",
    "    \n",
    "    #Get intensities from img ndarray\n",
    "    #itbuffer[:,2] = img[itbuffer[:,1].astype(np.uint16),itbuffer[:,0].astype(np.uint16)]\n",
    "\n",
    "    return itbuffer\n",
    "\n",
    "\n",
    "def getDashLine(line, dash_constant = 3, delete_connect_val = 1):\n",
    "    delete_idx = []\n",
    "    for idx in range(len(line)):\n",
    "        if idx % dash_constant ==0:\n",
    "            delete_idx.append(idx)\n",
    "            for con_idx in range(delete_connect_val-1):\n",
    "                delete_idx.append(idx + con_idx)\n",
    "                \n",
    "    dash_line = np.delete(line, delete_idx, axis =0 )\n",
    "    return dash_line\n",
    "    \n",
    "\n",
    "def getSlopeVal(point1, point2):\n",
    "    '''\n",
    "    point1, point2 = (height, width) = (y, x)\n",
    "    \n",
    "    '''\n",
    "    slope = (point1[0] - point2[0]) / (point1[1] - point2[1])\n",
    "    return slope\n",
    "\n",
    "def getPerpendicularLineList(point, slope, target_y = 500):\n",
    "    '''\n",
    "    - 길이를 정하면 될 듯\n",
    "    point[0] = h(y) , point[1] = w(x)\n",
    "    \n",
    "    '''    \n",
    "    import numpy as np\n",
    "    \n",
    "    if slope != 0 :\n",
    "        perpendicular_slope = -(1/slope)\n",
    "    else:\n",
    "        slope = 1e-12\n",
    "        perpendicular_slope = -(1/slope)\n",
    "    # y = ax+b / y - ax -b =0\n",
    "    a = perpendicular_slope\n",
    "    b = point[0] - (perpendicular_slope * point[1])\n",
    "    #print('a : ',a)\n",
    "    #print('b : ',b)\n",
    "    target_x = (target_y - b)/a\n",
    "    \n",
    "    #print(target_y, target_x)\n",
    "    \n",
    "    return np.asarray((int(target_y), int(target_x))), b\n",
    "    \n",
    "def lineIterToCoord(line_iter_result):\n",
    "    coord_list = []\n",
    "    for i in range(len(line_iter_result)):\n",
    "        h = int(line_iter_result[i][0])\n",
    "        w = int(line_iter_result[i][1])\n",
    "        coord_list.append(np.asarray((h,w)))\n",
    "        \n",
    "    return np.asarray(coord_list)\n",
    "\n",
    "def lcMergeCoord(lc_row, lc_col):\n",
    "    coord_list = []\n",
    "    for i in range(len(lc_row)):\n",
    "        coord_list.append(np.asarray((lc_row[i], lc_col[i])))\n",
    "        \n",
    "    return np.asarray(coord_list)\n",
    "\n",
    "def left_right_lc_neighbors_conv(image,mode):\n",
    "    import scipy.ndimage as ndi\n",
    "\n",
    "    \"\"\"\n",
    "    Counts the neighbor pixels for each pixel of an image:\n",
    "            x = [\n",
    "                [0, 1, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 1, 0]\n",
    "            ]\n",
    "            _neighbors(x)\n",
    "            [\n",
    "                [0, 3, 0],\n",
    "                [3, 4, 3],\n",
    "                [0, 3, 0]\n",
    "            ]\n",
    "    :type image: numpy.ndarray\n",
    "    :param image: A two-or-three dimensional image\n",
    "    :return: neighbor pixels for each pixel of an image\n",
    "    \"\"\"\n",
    "    if mode == 'right':\n",
    "        image = image.astype(np.int)\n",
    "        k = np.array([[1,1,0],[1,0,0],[1,1,0]])\n",
    "        neighborhood_count = ndi.convolve(image,k, mode='constant', cval=1)\n",
    "        neighborhood_count[~image.astype(np.bool)] = 0\n",
    "        return neighborhood_count\n",
    "    elif mode =='left':\n",
    "        image = image.astype(np.int)\n",
    "        k = np.array([[0,1,1],[0,0,1],[0,1,1]])\n",
    "        neighborhood_count = ndi.convolve(image,k, mode='constant', cval=1)\n",
    "        neighborhood_count[~image.astype(np.bool)] = 0\n",
    "        return neighborhood_count\n",
    "\n",
    "def getWidthPoint(img_shape, lc_info, L_perpen_line_info, R_perpen_line_info, debug_mode =True):\n",
    "    '''\n",
    "    img_shape : (num, height, width, ch)\n",
    "    \n",
    "    '''\n",
    "    zero_img = np.zeros((img_shape[1], img_shape[2]), dtype=np.uint16)\n",
    "    zero_3ch_img = np.zeros((img_shape[1], img_shape[2],3), dtype=np.uint16)\n",
    "    \n",
    "    zero_img[lc_info] = True\n",
    "    \n",
    "    mask_neighbors = (_neighbors_conv(zero_img) == 1)\n",
    "    temp_row, temp_col = np.where(mask_neighbors == True)\n",
    "\n",
    "    min_row_idx = np.where(temp_row == np.min(temp_row))\n",
    "    min_col_idx = np.where(temp_col == np.min(temp_col))\n",
    "    max_row_idx = np.where(temp_row == np.max(temp_row))\n",
    "    max_col_idx = np.where(temp_col == np.max(temp_col))\n",
    "\n",
    "    min_end_coord =np.array((temp_row[min_col_idx[0][0]] ,temp_col[min_col_idx[0][0]]))\n",
    "    max_end_coord =np.array((temp_row[max_col_idx[0][0]] ,temp_col[max_col_idx[0][0]]))\n",
    "    zero_img[L_perpen_line_info] = True\n",
    "    left_width_candi_point = left_right_lc_neighbors_conv(zero_img, 'left')\n",
    "    if np.max(left_width_candi_point) <3: #right...\n",
    "        left_width_point = min_end_coord\n",
    "        print('[1] left type : {} left shape : {}'.format(type(left_width_point), np.shape(left_width_point)))\n",
    "\n",
    "    else:\n",
    "        left_width_point = np.where(left_width_candi_point == np.max(left_width_candi_point))\n",
    "        print('[2] left type : {} left shape : {}'.format(type(left_width_point), np.shape(left_width_point)))\n",
    "\n",
    "        if np.shape(left_width_point )[1] >=2:\n",
    "            left_width_point = np.array((left_width_point[0][0], left_width_point[1][0]))\n",
    "            print('[3] left type : {} left shape : {}'.format(type(left_width_point), np.shape(left_width_point)))\n",
    "        else:\n",
    "            left_width_point = np.array((left_width_point[0][0], left_width_point[1][0]))\n",
    "    \n",
    "    zero_img[L_perpen_line_info] = False\n",
    "    zero_img[R_perpen_line_info] = True\n",
    "    right_width_candi_point = left_right_lc_neighbors_conv(zero_img, 'right')\n",
    "    \n",
    "    if np.max(right_width_candi_point) < 3:\n",
    "        right_width_point = max_end_coord\n",
    "    else:\n",
    "        right_width_point = np.where(right_width_candi_point == np.max(right_width_candi_point))\n",
    "        if np.shape(right_width_point)[1]  >=2:\n",
    "            right_width_point = np.array((right_width_point[0][0], right_width_point[1][0]))\n",
    "            #right_width_point = [right_width_point[0][0], right_width_point[1][0]]\n",
    "        else:\n",
    "            right_width_point = np.array((right_width_point[0][0], right_width_point[1][0]))\n",
    "    \n",
    "    if debug_mode ==True:\n",
    "        zero_3ch_img[lc_info[0], lc_info[1],:] = (255,255,0)\n",
    "        zero_3ch_img[L_perpen_line_info[0],L_perpen_line_info[1] ,:] = (255,255,255)\n",
    "        zero_3ch_img[R_perpen_line_info[0], R_perpen_line_info[1],:] = (255,255,255)\n",
    "        \n",
    "        print('left : ',left_width_point)\n",
    "        print('right : ',right_width_point)\n",
    "        cv2.circle(zero_3ch_img ,(left_width_point[1], left_width_point[0]), 3,(0,255,255))\n",
    "        cv2.circle(zero_3ch_img ,(right_width_point[1], right_width_point[0]), 3,(0,255,255))\n",
    "        \n",
    "        show_on_jupyter(zero_3ch_img, fig_size=(15,15))\n",
    "\n",
    "        \n",
    "    return np.asarray(left_width_point), np.asarray(right_width_point)\n",
    "\n",
    "def detectPeakPoint(lc_row, lc_col):\n",
    "    from scipy.signal import find_peaks\n",
    "    lc_col, lc_row = zip(*sorted(zip(lc_col, lc_row)))\n",
    "    peaks, _ = find_peaks(lc_row, distance=3)\n",
    "    print('shape : {}'.format(np.shape(peaks)))\n",
    "    \n",
    "    max_idx =0\n",
    "    prev_row = 0\n",
    "    curr_row = 0 \n",
    "    for idx in range(np.shape(peaks)[0]):\n",
    "        prev_row = curr_row\n",
    "        ext_idx = peaks[idx]\n",
    "        ext_row, ext_col = lc_row[ext_idx], lc_col[ext_idx]\n",
    "        curr_row = ext_row\n",
    "        if curr_row > prev_row:\n",
    "            max_idx = ext_idx\n",
    "            \n",
    "    return lc_row[max_idx], lc_col[max_idx]\n",
    "        \n",
    "def getBmoPerpendicularDist(line_1_point, line_2_point, target_points_row, target_points_col):\n",
    "    '''\n",
    "    code from : https://stackoverflow.com/questions/39840030/distance-between-point-and-a-line-from-two-points/39840218\n",
    "    line_1_point : 'point not points!' Max or min point\n",
    "    line_2_point ; Max or min point\n",
    "    \n",
    "    target_points_row :\n",
    "    target_points_col : \n",
    "    \n",
    "    '''\n",
    "    # row, col\n",
    "    p1 = np.array((line_1_point[1], line_1_point[0]))\n",
    "    p2 = np.array((line_2_point[1], line_2_point[0]))\n",
    "    \n",
    "    '''\n",
    "    [TODO]\n",
    "        curve depth -> check the their depth (+ or -)\n",
    "        \n",
    "    '''\n",
    "    p3 = np.array((target_points_col, target_points_row))\n",
    "        #\n",
    "    d = np.linalg.norm(np.cross(p2-p1, p1-p3))/np.linalg.norm(p2-p1)\n",
    "    return d\n",
    "\n",
    "def drawLineUsingEndPoint(end_points,slope, draw_len = 50):\n",
    "    # y = ax + b\n",
    "    b = -(slope* end_points[0] ) + end_points[1]\n",
    "    \n",
    "    #for i in range(draw_len):\n",
    "        \n",
    "def physical_distance_converter(ref_points, target_points):\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    _x_convert = 12.5000\n",
    "    _y_convert = 3.9216\n",
    "    print('ref points : {} target points : {}'.format(ref_points, target_points))\n",
    "    \n",
    "    dist = np.sqrt(np.square((ref_points[0] - target_points[0]) * _y_convert, dtype = np.float32) + np.square((ref_points[1] - target_points[1]) * _x_convert, dtype= np.float32) ,dtype= np.float32)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This section is optimized for inha hosital data (2020.11)\n",
    "\n",
    "\n",
    "'''\n",
    "save_folder =  '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'\n",
    "dir_checker(save_folder)\n",
    "\n",
    "idx = 15\n",
    "\n",
    "\n",
    "if idx ==  0:\n",
    "    filename = '001005'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 1:\n",
    "    filename = '001006'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 2:\n",
    "    filename = '001007'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 3:\n",
    "    filename = '001008'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 4:\n",
    "    filename = '002005' #\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 5:\n",
    "    filename = '002006'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 6:\n",
    "    filename = '002007'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 7:\n",
    "    filename = '002008'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 8:\n",
    "    filename = '003005'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 9:\n",
    "    filename = '003006'#\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 10:\n",
    "    filename = '003007'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 11:\n",
    "    filename = '003008'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 12:\n",
    "    filename = '004005'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 13:\n",
    "    filename = '004006'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 14:\n",
    "    filename = '004007'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "elif idx == 15:\n",
    "    filename = '004008'\n",
    "    save_folder =   '/home/bono/Desktop/mellab_project/data/set1_inhaHos/'+'quant_result/' + file_num +'/'+filename+'/'\n",
    "    \n",
    "    \n",
    "dir_checker(save_folder)\n",
    "\n",
    "_x_convert = 12.5000\n",
    "_y_convert = 3.9216\n",
    "\n",
    "lc_width_arr = np.zeros(NUM_YOLO_RESULT, dtype=np.float32)\n",
    "no_post_lc_width_arr = np.zeros(NUM_YOLO_RESULT, dtype=np.float32)\n",
    "\n",
    "\n",
    "copy_result_img = RESULT_IMGS.copy()\n",
    "copy_result_mask = RESULT_IMGS_MASKS.copy()\n",
    "\n",
    "PRED_LCD = []\n",
    "PRED_LCCD = []\n",
    "PRED_LCCI = []\n",
    "\n",
    "no_post_PRED_LCD = []\n",
    "no_post_PRED_LCCD = []\n",
    "no_post_PRED_LCCI = []\n",
    "\n",
    "dash_constant = 5\n",
    "\n",
    "\n",
    "## start!!!\n",
    "\n",
    "temp_left = recon_bmo01_center[idx]\n",
    "temp_right = recon_bmo02_center[idx]\n",
    "\n",
    "# change the left & right\n",
    "if recon_bmo01_center[idx][1] > recon_bmo02_center[idx][1]:\n",
    "    recon_bmo01_center[idx] = temp_right\n",
    "    recon_bmo02_center[idx] = temp_left\n",
    "print('recon bmo center type : ', type(recon_bmo01_center))\n",
    "\n",
    "cv2.imwrite(save_folder+filename+'_lc_img.png',copy_result_img[idx])\n",
    "# debugging process\n",
    "RESULT_IMGS[idx, recon_bmo01_center[idx][0], recon_bmo01_center[idx][1]] = (0,0,255)\n",
    "RESULT_IMGS[idx, recon_bmo02_center[idx][0], recon_bmo02_center[idx][1]] = (0,0,255) \n",
    "copy_result_img[idx, recon_bmo01_center[idx][0], recon_bmo01_center[idx][1]] = (0,0,255)\n",
    "copy_result_img[idx, recon_bmo02_center[idx][0], recon_bmo02_center[idx][1]] = (0,0,255) \n",
    "\n",
    "\n",
    "L_bmo_circle_coord = (recon_bmo01_center[idx][1], recon_bmo01_center[idx][0])\n",
    "R_bmo_circle_coord = (recon_bmo02_center[idx][1], recon_bmo02_center[idx][0])\n",
    "\n",
    "cv2.circle(copy_result_img[idx] ,L_bmo_circle_coord, 3,(0,0,255),-1)\n",
    "cv2.circle(copy_result_img[idx] ,R_bmo_circle_coord, 3,(0,0,255),-1)\n",
    "show_on_jupyter(copy_result_img[idx], fig_size= (17,17))\n",
    "cv2.imwrite(save_folder+filename+'_seg.png',copy_result_img[idx])\n",
    "\n",
    "\n",
    "\n",
    "cv2.line(copy_result_img[idx], (recon_bmo01_center[idx][1], recon_bmo01_center[idx][0]), (recon_bmo02_center[idx][1], recon_bmo02_center[idx][0]), (255,255,0), 2 )\n",
    "cv2.imwrite(save_folder+filename+'_bmo_ref.png',copy_result_img[idx])\n",
    "\n",
    "################################################################################################\n",
    "# perpendicular line to bmo terminate points\n",
    "line_coord = createLineIterator(np.asarray(recon_bmo01_center[idx]), np.asarray(recon_bmo02_center[idx]), copy_result_img[idx,:,:,0])\n",
    "\n",
    "slope = getSlopeVal(np.asarray(recon_bmo01_center[idx]), np.asarray(recon_bmo02_center[idx]))\n",
    "print('slope : ' , slope)\n",
    "left_target_point,left_b = getPerpendicularLineList(np.asarray(recon_bmo01_center[idx]), slope,target_y=450)\n",
    "left_per_line_coord, max_left_line_points = createLineIterator(np.asarray(recon_bmo01_center[idx]), left_target_point, copy_result_img[idx,:,:,0], flag = 'min')\n",
    "left_dash_line_coord = getDashLine(left_per_line_coord, dash_constant=dash_constant, delete_connect_val=3)\n",
    "copy_result_img[idx,left_dash_line_coord[:,0].astype(np.uint16), left_dash_line_coord[:,1].astype(np.uint16)] = (255,255,255)\n",
    "#cv2.circle(copy_result_img[idx] ,(recon_bmo01_center[idx][1], recon_bmo01_center[idx][0]), 5,(0,255,255))\n",
    "\n",
    "right_target_point,right_b = getPerpendicularLineList(np.asarray(recon_bmo02_center[idx]), slope,target_y=450)\n",
    "right_per_line_coord, max_right_line_points = createLineIterator(np.asarray(recon_bmo02_center[idx]), right_target_point, copy_result_img[idx,:,:,0], flag ='max')\n",
    "right_dash_line_coord = getDashLine(right_per_line_coord, dash_constant=dash_constant, delete_connect_val=3)\n",
    "copy_result_img[idx,right_dash_line_coord[:,0].astype(np.uint16), right_dash_line_coord[:,1].astype(np.uint16)] = (255,255,255)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "RESULT_IMGS_MASKS[idx, recon_bmo01_center[idx][0], recon_bmo01_center[idx][1]] = (0,0,255)\n",
    "RESULT_IMGS_MASKS[idx, recon_bmo02_center[idx][0], recon_bmo02_center[idx][1]] = (0,0,255)\n",
    "\n",
    "# LC\n",
    "lc_border_row, lc_border_col = np.where(np.all(RESULT_IMGS[idx] == (0,255,0), axis=-1))\n",
    "########################## 잠깐 실험...! (polyfit)\n",
    "print('left line info : {} right line info :{}'.format(max_left_line_points, max_right_line_points))\n",
    "\n",
    "left_interpol_point = 0\n",
    "right_interpol_point = 0\n",
    "if int(max_left_line_points[1]) >  recon_bmo01_center[idx][1]:\n",
    "    left_interpol_point = recon_bmo01_center[idx][1]\n",
    "else:\n",
    "    print('exception! : {}'.format(max_left_line_points[1]))\n",
    "    left_interpol_point = int(max_left_line_points[1])\n",
    "\n",
    "\n",
    "if int(max_right_line_points[1]) < recon_bmo02_center[idx][1]:\n",
    "    right_interpol_point = recon_bmo02_center[idx][1]\n",
    "else:\n",
    "    right_interpol_point = int(max_right_line_points[1])\n",
    "\n",
    "print('right interpol point : ', right_interpol_point)\n",
    "show_on_jupyter(copy_result_img[idx], fig_size=(17,17))\n",
    "cv2.imwrite(save_folder+filename+'_lc_interpol.png',copy_result_img[idx])\n",
    "################################################################################################\n",
    "\n",
    "L_per_info = (left_per_line_coord[:,0].astype(np.uint16), left_per_line_coord[:,1].astype(np.uint16))\n",
    "R_per_info = (right_per_line_coord[:,0].astype(np.uint16), right_per_line_coord[:,1].astype(np.uint16))\n",
    "left, right = getWidthPoint(np.shape(YOLO_IMGS),(lc_border_row,lc_border_col),L_per_info, R_per_info)\n",
    "print('left : {} right : {}'.format(left, right))\n",
    "# 흔적\n",
    "\n",
    "min_end_coord = left\n",
    "max_end_coord = right\n",
    "print('min end coord : {} max end coord {} '.format(min_end_coord,max_end_coord))\n",
    "##################### perpendicular ####################\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "left_end_lc_point = left\n",
    "right_end_lc_point = right\n",
    "print('right end lc point[1] : {} right interpol point : {}'.format(right_end_lc_point[1], right_interpol_point))\n",
    "interpol_lc_left_x_range = np.linspace(left_interpol_point, left_end_lc_point[1],int(left_end_lc_point[1] -left_interpol_point+1))\n",
    "interpol_lc_right_x_range = np.linspace(right_end_lc_point[1], right_interpol_point,int(right_interpol_point-right_end_lc_point[1]+1))\n",
    "print('idx : ',idx)\n",
    "print('left interpolation range : {} \\n right interpolation range : {}'.format(interpol_lc_left_x_range, interpol_lc_right_x_range))\n",
    "\n",
    "#print('reshape : {} pred coef[idx] : {} '.format(interpol_lc_left_x_range.reshape(-1,1), pred_coef_lists[idx]))\n",
    "new_pred_left_lc_y = pred_coef_lists[idx].predict(interpol_lc_left_x_range.reshape(-1,1))\n",
    "new_pred_left_lc_y = np.around(new_pred_left_lc_y[:,0]).astype(np.uint16)\n",
    "\n",
    "new_pred_right_lc_y = pred_coef_lists[idx].predict(interpol_lc_right_x_range.reshape(-1,1))\n",
    "new_pred_right_lc_y = np.around(new_pred_right_lc_y[:,0]).astype(np.uint16)\n",
    "\n",
    "print('pred cocl shape : {} new pred left lc x shape : {}'.format(lc_border_col.shape, new_pred_left_lc_y.shape))\n",
    "\n",
    "new_lc_border_col = np.concatenate((interpol_lc_left_x_range, lc_border_col),axis = 0)\n",
    "new_lc_border_col = np.concatenate((new_lc_border_col, interpol_lc_right_x_range), axis =0)\n",
    "new_lc_border_col = new_lc_border_col.astype(np.uint16)\n",
    "\n",
    "new_lc_border_row = np.concatenate((new_pred_left_lc_y, lc_border_row), axis =0 )\n",
    "new_lc_border_row = np.concatenate((new_lc_border_row, new_pred_right_lc_y), axis =0 )\n",
    "\n",
    "print('concat row shape : {} concat col shape : {}'.format(new_lc_border_row.shape, new_lc_border_col.shape))\n",
    "\n",
    "#new_lc_border_row[new_lc_border_row > 500]\n",
    "#copy_result_img[idx, new_lc_border_row, new_lc_border_col] = (125,125,0)\n",
    "#show_on_jupyter(copy_result_img[idx], fig_size=(15,15))\n",
    "print('concat row : {} concat col: {}'.format(new_lc_border_row, new_lc_border_col))\n",
    "final_lc_left, final_lc_right = getWidthPoint(np.shape(YOLO_IMGS),(new_lc_border_row,new_lc_border_col),L_per_info, R_per_info)\n",
    "\n",
    "# find final lc point's index\n",
    "print('final lc left : {}'.format(final_lc_left))\n",
    "print('row : {} \\n\\n col : {}'.format(new_lc_border_row, new_lc_border_col))\n",
    "# delete, 찾은 값 기준 범위\n",
    "left_col_idx = np.where( new_lc_border_col == final_lc_left[1])\n",
    "left_row_idx = np.where( new_lc_border_row == final_lc_left[0])\n",
    "print('final lc left col idx : {} row idx : {}'.format(left_col_idx, left_row_idx))\n",
    "\n",
    "new_lc_info = np.array((new_lc_border_row, new_lc_border_col))\n",
    "dist_left_row = new_lc_border_row - final_lc_left[0]\n",
    "dist_left_col = new_lc_border_col.astype(np.int16) - final_lc_left[1]\n",
    "dist_left = np.abs(dist_left_row) + np.abs(dist_left_col)\n",
    "left_idx = (np.where(dist_left == np.min(dist_left)))\n",
    "left_idx = left_idx[0][0]\n",
    "\n",
    "dist_right_row = new_lc_border_row - final_lc_right[0]\n",
    "dist_right_col = new_lc_border_col.astype(np.int16) - final_lc_right[1]\n",
    "dist_right = np.abs(dist_right_row) + np.abs(dist_right_col)\n",
    "right_idx = (np.where(dist_right == np.min(dist_right)))\n",
    "right_idx = right_idx[0][-1]\n",
    "\n",
    "#print('left idx : {} right idx : {} temp : {}'.format( left_idx, right_idx, np.shape(new_lc_border_row)[0]))\n",
    "\n",
    "delete_left_lists = np.linspace(0, left_idx,int(left_idx+1), dtype=np.int16)\n",
    "delete_right_lists = np.linspace(right_idx, np.shape(new_lc_border_row)[0],int(np.shape(new_lc_border_row)[0]- right_idx+1), dtype=np.int16)\n",
    "concat_delete = np.concatenate((delete_left_lists, delete_right_lists), axis = 0)\n",
    "print('concat delete : ', concat_delete)\n",
    "print('delete lists : {}, right : {} shape : {}'.format( delete_left_lists, delete_right_lists, np.shape(delete_right_lists)))\n",
    "print(np.shape(new_lc_info))\n",
    "new_final_lc_row = np.delete(new_lc_border_row,  concat_delete)\n",
    "new_final_lc_col = np.delete(new_lc_border_col,  concat_delete)\n",
    "print(new_final_lc_col)\n",
    "\n",
    "\n",
    "copy_result_img[idx, new_final_lc_row, new_final_lc_col] = (125,125,0)\n",
    "print(new_final_lc_col)\n",
    "\n",
    "# new\n",
    "show_on_jupyter(copy_result_img[idx], fig_size=(15,15))\n",
    "\n",
    "cv2.imwrite(save_folder+filename+'_post_seg.png',copy_result_img[idx])\n",
    "\n",
    "\n",
    "#new_temp_right = np.delete(new_lc_info, delete_right_lists)\n",
    "\n",
    "############################################################\n",
    "############################################################\n",
    "############################################################\n",
    "#ym_left_l2_diff[idx] = np.sqrt(np.square((left_gt[0] - left_pred[0]) * _y_convert) + np.square((left_gt[1] - left_pred[1]) * _x_convert) )\n",
    "\n",
    "no_post_lc_width_arr[idx] = np.linalg.norm(max_end_coord -min_end_coord)\n",
    "#lc_width_arr[idx] = np.linalg.norm(final_lc_right -final_lc_left)\n",
    "lc_width_arr[idx] = physical_distance_converter((final_lc_right[0], final_lc_right[1]), (final_lc_left[0], final_lc_left[1]))\n",
    "print('lc width : {}'.format(lc_width_arr[idx]))\n",
    "# convert to physical distance\n",
    "#no_post_lc_width_arr[idx] = np.sqrt(np.square((max_end_coord[0] - min_end_coord[0]) * _y_convert) + np.square((max_end_coord[1] - min_end_coord[1]) * _x_convert) )\n",
    "#lc_width_arr[idx] = np.linalg.norm(final_lc_right -final_lc_left)\n",
    "\n",
    "cv2.line(copy_result_img[idx], (final_lc_left[1], final_lc_left[0]), (final_lc_right[1],final_lc_right[0]), (255,0,255), 2 )\n",
    "cv2.imwrite(save_folder+str(idx)+'_lc_width.png',copy_result_img[idx])\n",
    "#cv2.line(copy_result_img[idx], (min_end_coord[1], min_end_coord[0]), (max_end_coord[1],max_end_coord[0]), (255,0,255), 2 )\n",
    "\n",
    "# get laminar cribrosa curve depth final_lc_left, final_lc_right \n",
    "print('min end coord : {} max end coord : {} max - min : {} '.format(min_end_coord, max_end_coord, (max_end_coord - min_end_coord)))\n",
    "\n",
    "max_lc_d , max_lc_coord = get_perpendicular_dist(final_lc_left, final_lc_right, new_final_lc_row,new_final_lc_col)\n",
    "lc_d_draw_coord = get_intersection_perpendicular_n_line(final_lc_left, final_lc_right, max_lc_coord)\n",
    "no_post_max_lc_d , no_post_max_lc_coord = get_perpendicular_dist(min_end_coord, max_end_coord, lc_border_row, lc_border_col)\n",
    "\n",
    "'''\n",
    "circle_coord = (max_lc_coord[1], max_lc_coord[0])\n",
    "print(circle_coord)\n",
    "cv2.circle(copy_result_img[idx] ,circle_coord, 3,(0,255,255),-1)\n",
    "\n",
    "temp_circle_coord = (lc_d_draw_coord [1], lc_d_draw_coord [0])\n",
    "cv2.circle(copy_result_img[idx] ,temp_circle_coord, 3,(0,255,255),-1)\n",
    "'''\n",
    "cv2.line(copy_result_img[idx], (max_lc_coord[1], max_lc_coord[0]), (lc_d_draw_coord[1], lc_d_draw_coord [0]), (0,255,255), 2 )\n",
    "cv2.imwrite(save_folder+filename+'_LCCD.png',copy_result_img[idx])\n",
    "\n",
    "physical_max_lc_d = physical_distance_converter((max_lc_coord[0], max_lc_coord[1]), (lc_d_draw_coord[0], lc_d_draw_coord [1]))\n",
    "print('physical max d : ', np.shape(physical_max_lc_d))\n",
    "print('physical max d : ', physical_max_lc_d)\n",
    "physical_max_lc_d = physical_max_lc_d\n",
    "\n",
    "left_bmo_coord =np.array((recon_bmo01_center[idx][0] ,recon_bmo01_center[idx][1]))\n",
    "right_bmo_coord =np.array((recon_bmo02_center[idx][0] ,recon_bmo02_center[idx][1]))\n",
    "\n",
    "# get laminar cribrosa depth\n",
    "lc_max_dep_row, lc_max_dep_col = detectPeakPoint(new_final_lc_row, new_final_lc_col)\n",
    "no_post_lc_max_dep_row, no_post_lc_max_dep_col = detectPeakPoint(lc_border_row, lc_border_col)\n",
    "\n",
    "max_bmo_d  = getBmoPerpendicularDist(left_bmo_coord,right_bmo_coord,lc_max_dep_row, lc_max_dep_col)\n",
    "max_bmo_coord = (lc_max_dep_row, lc_max_dep_col)\n",
    "bmo_d_draw_coord = get_intersection_perpendicular_n_line(left_bmo_coord, right_bmo_coord, max_bmo_coord )\n",
    "\n",
    "\n",
    "no_post_max_bmo_d  = getBmoPerpendicularDist(left_bmo_coord,right_bmo_coord,no_post_lc_max_dep_row, no_post_lc_max_dep_col)\n",
    "no_post_max_bmo_coord = (no_post_lc_max_dep_row, no_post_lc_max_dep_col)\n",
    "\n",
    "#circle_coord02 = (max_bmo_coord[1], max_bmo_coord[0])\n",
    "#cv2.circle(copy_result_img[idx] ,circle_coord02, 3,(255,255,255),-1)\n",
    "\n",
    "\n",
    "cv2.line(copy_result_img[idx], (max_bmo_coord[1], max_bmo_coord[0]), (bmo_d_draw_coord[1],bmo_d_draw_coord[0]), (255,255,255), 2 )\n",
    "print('bmo0 {} bmo1 {} bmoD0 {} bmoD1 {}'.format(max_bmo_coord[0], max_bmo_coord[1],bmo_d_draw_coord[0],bmo_d_draw_coord[1]))\n",
    "\n",
    "physical_max_bmo_d = physical_distance_converter(np.array((max_bmo_coord[0], max_bmo_coord[1])),  np.array((bmo_d_draw_coord[0],bmo_d_draw_coord[1])))\n",
    "\n",
    "show_on_jupyter(copy_result_img[idx], fig_size=(15,15))\n",
    "cv2.imwrite(save_folder+filename+'_final.png', copy_result_img[idx])\n",
    "\n",
    "\n",
    "print('physical distance LCD : {} LCCD : {} '.format(physical_max_bmo_d, physical_max_lc_d))\n",
    "\n",
    "print('LCD : {} LCCD : {} LCCI : {} '.format( physical_max_bmo_d,physical_max_lc_d, ((physical_max_lc_d / lc_width_arr[idx])* 100)))\n",
    "PRED_LCD.append(physical_max_bmo_d)\n",
    "PRED_LCCD.append(physical_max_lc_d)\n",
    "PRED_LCCI.append(((physical_max_lc_d / lc_width_arr[idx])* 100))\n",
    "\n",
    "no_post_PRED_LCD.append(no_post_max_bmo_d)\n",
    "no_post_PRED_LCCD.append(no_post_max_lc_d)\n",
    "no_post_PRED_LCCI.append(((no_post_max_lc_d / no_post_lc_width_arr[idx])* 100))\n",
    "    \n",
    "\n",
    "f = open(save_folder+\"result.txt\", 'w')\n",
    "f.write('LCD : ' + str(physical_max_bmo_d) + '\\n' +'LCCD : '+str(physical_max_lc_d[0]) + '\\n' + 'LCCI : ' + str(((physical_max_lc_d[0] / lc_width_arr[idx])* 100)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if VALID_TEST == 'test':\n",
    "    LC_NAME = 'N20'\n",
    "    lc_save_folder = './case_study/'+LC_NAME+'/'\n",
    "    dir_checker(lc_save_folder)\n",
    "    \n",
    "    \n",
    "_x_convert = 12.5000\n",
    "_y_convert = 3.9216\n",
    "\n",
    "lc_width_arr = np.zeros(NUM_YOLO_RESULT, dtype=np.float32)\n",
    "no_post_lc_width_arr = np.zeros(NUM_YOLO_RESULT, dtype=np.float32)\n",
    "\n",
    "\n",
    "copy_result_img = RESULT_IMGS.copy()\n",
    "copy_result_mask = RESULT_IMGS_MASKS.copy()\n",
    "\n",
    "PRED_LCD = []\n",
    "PRED_LCCD = []\n",
    "PRED_LCCI = []\n",
    "\n",
    "no_post_PRED_LCD = []\n",
    "no_post_PRED_LCCD = []\n",
    "no_post_PRED_LCCI = []\n",
    "\n",
    "dash_constant = 5\n",
    "\n",
    "# result image precessing\n",
    "#for idx in range(NUM_YOLO_RESULT):\n",
    "for idx in range(NUM_YOLO_RESULT):\n",
    "    idx = 6\n",
    "    temp_left = recon_bmo01_center[idx]\n",
    "    temp_right = recon_bmo02_center[idx]\n",
    "    \n",
    "    # change the left & right\n",
    "    if recon_bmo01_center[idx][1] > recon_bmo02_center[idx][1]:\n",
    "        recon_bmo01_center[idx] = temp_right\n",
    "        recon_bmo02_center[idx] = temp_left\n",
    "    print('recon bmo center type : ', type(recon_bmo01_center))\n",
    "    \n",
    "    cv2.imwrite(save_folder+str(idx)+'_lc_img.png',copy_result_img[idx])\n",
    "    # debugging process\n",
    "    RESULT_IMGS[idx, recon_bmo01_center[idx][0], recon_bmo01_center[idx][1]] = (0,0,255)\n",
    "    RESULT_IMGS[idx, recon_bmo02_center[idx][0], recon_bmo02_center[idx][1]] = (0,0,255) \n",
    "    copy_result_img[idx, recon_bmo01_center[idx][0], recon_bmo01_center[idx][1]] = (0,0,255)\n",
    "    copy_result_img[idx, recon_bmo02_center[idx][0], recon_bmo02_center[idx][1]] = (0,0,255) \n",
    "    \n",
    "    \n",
    "    L_bmo_circle_coord = (recon_bmo01_center[idx][1], recon_bmo01_center[idx][0])\n",
    "    R_bmo_circle_coord = (recon_bmo02_center[idx][1], recon_bmo02_center[idx][0])\n",
    "    \n",
    "    cv2.circle(copy_result_img[idx] ,L_bmo_circle_coord, 3,(0,0,255),-1)\n",
    "    cv2.circle(copy_result_img[idx] ,R_bmo_circle_coord, 3,(0,0,255),-1)\n",
    "    show_on_jupyter(copy_result_img[idx], fig_size= (17,17))\n",
    "    cv2.imwrite(save_folder+str(idx)+'_seg.png',copy_result_img[idx])\n",
    "    if VALID_TEST == 'test':\n",
    "        cv2.imwrite(lc_save_folder+LC_NAME+'_'+str(idx)+'_seg.png', copy_result_img[idx])\n",
    "        \n",
    "    \n",
    "    cv2.line(copy_result_img[idx], (recon_bmo01_center[idx][1], recon_bmo01_center[idx][0]), (recon_bmo02_center[idx][1], recon_bmo02_center[idx][0]), (255,255,0), 2 )\n",
    "    cv2.imwrite(save_folder+str(idx)+'_bmo_ref.png',copy_result_img[idx])\n",
    "    ################################################################################################\n",
    "    # perpendicular line to bmo terminate points\n",
    "    line_coord = createLineIterator(np.asarray(recon_bmo01_center[idx]), np.asarray(recon_bmo02_center[idx]), copy_result_img[idx,:,:,0])\n",
    "\n",
    "    slope = getSlopeVal(np.asarray(recon_bmo01_center[idx]), np.asarray(recon_bmo02_center[idx]))\n",
    "    print('slope : ' , slope)\n",
    "    left_target_point,left_b = getPerpendicularLineList(np.asarray(recon_bmo01_center[idx]), slope,target_y=450)\n",
    "    left_per_line_coord, max_left_line_points = createLineIterator(np.asarray(recon_bmo01_center[idx]), left_target_point, copy_result_img[idx,:,:,0], flag = 'min')\n",
    "    left_dash_line_coord = getDashLine(left_per_line_coord, dash_constant=dash_constant, delete_connect_val=3)\n",
    "    copy_result_img[idx,left_dash_line_coord[:,0].astype(np.uint16), left_dash_line_coord[:,1].astype(np.uint16)] = (255,255,255)\n",
    "    #cv2.circle(copy_result_img[idx] ,(recon_bmo01_center[idx][1], recon_bmo01_center[idx][0]), 5,(0,255,255))\n",
    "    \n",
    "    right_target_point,right_b = getPerpendicularLineList(np.asarray(recon_bmo02_center[idx]), slope,target_y=450)\n",
    "    right_per_line_coord, max_right_line_points = createLineIterator(np.asarray(recon_bmo02_center[idx]), right_target_point, copy_result_img[idx,:,:,0], flag ='max')\n",
    "    right_dash_line_coord = getDashLine(right_per_line_coord, dash_constant=dash_constant, delete_connect_val=3)\n",
    "    copy_result_img[idx,right_dash_line_coord[:,0].astype(np.uint16), right_dash_line_coord[:,1].astype(np.uint16)] = (255,255,255)\n",
    "    \n",
    "    ################################################################################################\n",
    "    \n",
    "    RESULT_IMGS_MASKS[idx, recon_bmo01_center[idx][0], recon_bmo01_center[idx][1]] = (0,0,255)\n",
    "    RESULT_IMGS_MASKS[idx, recon_bmo02_center[idx][0], recon_bmo02_center[idx][1]] = (0,0,255)\n",
    "    \n",
    "    # LC\n",
    "    lc_border_row, lc_border_col = np.where(np.all(RESULT_IMGS[idx] == (0,255,0), axis=-1))\n",
    "    ########################## 잠깐 실험...! (polyfit)\n",
    "    print('left line info : {} right line info :{}'.format(max_left_line_points, max_right_line_points))\n",
    "    \n",
    "    left_interpol_point = 0\n",
    "    right_interpol_point = 0\n",
    "    if int(max_left_line_points[1]) >  recon_bmo01_center[idx][1]:\n",
    "        left_interpol_point = recon_bmo01_center[idx][1]\n",
    "    else:\n",
    "        print('exception! : {}'.format(max_left_line_points[1]))\n",
    "        left_interpol_point = int(max_left_line_points[1])\n",
    "        \n",
    "        \n",
    "    if int(max_right_line_points[1]) < recon_bmo02_center[idx][1]:\n",
    "        right_interpol_point = recon_bmo02_center[idx][1]\n",
    "    else:\n",
    "        right_interpol_point = int(max_right_line_points[1])\n",
    "        \n",
    "    print('right interpol point : ', right_interpol_point)\n",
    "    show_on_jupyter(copy_result_img[idx], fig_size=(17,17))\n",
    "    cv2.imwrite(save_folder+str(idx)+'_lc_interpol.png',copy_result_img[idx])\n",
    "    ################################################################################################\n",
    "    \n",
    "    L_per_info = (left_per_line_coord[:,0].astype(np.uint16), left_per_line_coord[:,1].astype(np.uint16))\n",
    "    R_per_info = (right_per_line_coord[:,0].astype(np.uint16), right_per_line_coord[:,1].astype(np.uint16))\n",
    "    left, right = getWidthPoint(np.shape(YOLO_IMGS),(lc_border_row,lc_border_col),L_per_info, R_per_info)\n",
    "    print('left : {} right : {}'.format(left, right))\n",
    "    # 흔적\n",
    "    \n",
    "    min_end_coord = left\n",
    "    max_end_coord = right\n",
    "    print('min end coord : {} max end coord {} '.format(min_end_coord,max_end_coord))\n",
    "    ##################### perpendicular ####################\n",
    "    ############################################################\n",
    "    ############################################################\n",
    "    \n",
    "    left_end_lc_point = left\n",
    "    right_end_lc_point = right\n",
    "    print('right end lc point[1] : {} right interpol point : {}'.format(right_end_lc_point[1], right_interpol_point))\n",
    "    interpol_lc_left_x_range = np.linspace(left_interpol_point, left_end_lc_point[1],int(left_end_lc_point[1] -left_interpol_point+1))\n",
    "    interpol_lc_right_x_range = np.linspace(right_end_lc_point[1], right_interpol_point,int(right_interpol_point-right_end_lc_point[1]+1))\n",
    "    print('idx : ',idx)\n",
    "    print('left interpolation range : {} \\n right interpolation range : {}'.format(interpol_lc_left_x_range, interpol_lc_right_x_range))\n",
    "    \n",
    "    #print('reshape : {} pred coef[idx] : {} '.format(interpol_lc_left_x_range.reshape(-1,1), pred_coef_lists[idx]))\n",
    "    new_pred_left_lc_y = pred_coef_lists[idx].predict(interpol_lc_left_x_range.reshape(-1,1))\n",
    "    new_pred_left_lc_y = np.around(new_pred_left_lc_y[:,0]).astype(np.uint16)\n",
    "    \n",
    "    new_pred_right_lc_y = pred_coef_lists[idx].predict(interpol_lc_right_x_range.reshape(-1,1))\n",
    "    new_pred_right_lc_y = np.around(new_pred_right_lc_y[:,0]).astype(np.uint16)\n",
    "    \n",
    "    print('pred cocl shape : {} new pred left lc x shape : {}'.format(lc_border_col.shape, new_pred_left_lc_y.shape))\n",
    "    \n",
    "    new_lc_border_col = np.concatenate((interpol_lc_left_x_range, lc_border_col),axis = 0)\n",
    "    new_lc_border_col = np.concatenate((new_lc_border_col, interpol_lc_right_x_range), axis =0)\n",
    "    new_lc_border_col = new_lc_border_col.astype(np.uint16)\n",
    "    \n",
    "    new_lc_border_row = np.concatenate((new_pred_left_lc_y, lc_border_row), axis =0 )\n",
    "    new_lc_border_row = np.concatenate((new_lc_border_row, new_pred_right_lc_y), axis =0 )\n",
    "\n",
    "    print('concat row shape : {} concat col shape : {}'.format(new_lc_border_row.shape, new_lc_border_col.shape))\n",
    "    \n",
    "    #new_lc_border_row[new_lc_border_row > 500]\n",
    "    #copy_result_img[idx, new_lc_border_row, new_lc_border_col] = (125,125,0)\n",
    "    #show_on_jupyter(copy_result_img[idx], fig_size=(15,15))\n",
    "    print('concat row : {} concat col: {}'.format(new_lc_border_row, new_lc_border_col))\n",
    "    final_lc_left, final_lc_right = getWidthPoint(np.shape(YOLO_IMGS),(new_lc_border_row,new_lc_border_col),L_per_info, R_per_info)\n",
    "\n",
    "    # find final lc point's index\n",
    "    print('final lc left : {}'.format(final_lc_left))\n",
    "    print('row : {} \\n\\n col : {}'.format(new_lc_border_row, new_lc_border_col))\n",
    "    # delete, 찾은 값 기준 범위\n",
    "    left_col_idx = np.where( new_lc_border_col == final_lc_left[1])\n",
    "    left_row_idx = np.where( new_lc_border_row == final_lc_left[0])\n",
    "    print('final lc left col idx : {} row idx : {}'.format(left_col_idx, left_row_idx))\n",
    "    \n",
    "    new_lc_info = np.array((new_lc_border_row, new_lc_border_col))\n",
    "    dist_left_row = new_lc_border_row - final_lc_left[0]\n",
    "    dist_left_col = new_lc_border_col.astype(np.int16) - final_lc_left[1]\n",
    "    dist_left = np.abs(dist_left_row) + np.abs(dist_left_col)\n",
    "    left_idx = (np.where(dist_left == np.min(dist_left)))\n",
    "    left_idx = left_idx[0][0]\n",
    "    \n",
    "    dist_right_row = new_lc_border_row - final_lc_right[0]\n",
    "    dist_right_col = new_lc_border_col.astype(np.int16) - final_lc_right[1]\n",
    "    dist_right = np.abs(dist_right_row) + np.abs(dist_right_col)\n",
    "    right_idx = (np.where(dist_right == np.min(dist_right)))\n",
    "    right_idx = right_idx[0][-1]\n",
    "    \n",
    "    #print('left idx : {} right idx : {} temp : {}'.format( left_idx, right_idx, np.shape(new_lc_border_row)[0]))\n",
    "    \n",
    "    delete_left_lists = np.linspace(0, left_idx,int(left_idx+1), dtype=np.int16)\n",
    "    delete_right_lists = np.linspace(right_idx, np.shape(new_lc_border_row)[0],int(np.shape(new_lc_border_row)[0]- right_idx+1), dtype=np.int16)\n",
    "    concat_delete = np.concatenate((delete_left_lists, delete_right_lists), axis = 0)\n",
    "    print('concat delete : ', concat_delete)\n",
    "    print('delete lists : {}, right : {} shape : {}'.format( delete_left_lists, delete_right_lists, np.shape(delete_right_lists)))\n",
    "    print(np.shape(new_lc_info))\n",
    "    new_final_lc_row = np.delete(new_lc_border_row,  concat_delete)\n",
    "    new_final_lc_col = np.delete(new_lc_border_col,  concat_delete)\n",
    "    print(new_final_lc_col)\n",
    "    \n",
    "    \n",
    "    copy_result_img[idx, new_final_lc_row, new_final_lc_col] = (125,125,0)\n",
    "    print(new_final_lc_col)\n",
    "    \n",
    "    # new\n",
    "    show_on_jupyter(copy_result_img[idx], fig_size=(15,15))\n",
    "    \n",
    "    cv2.imwrite(save_folder+str(idx)+'_post_seg.png',copy_result_img[idx])\n",
    "    if VALID_TEST == 'test':\n",
    "        cv2.imwrite(lc_save_folder+LC_NAME+'_'+str(idx)+'_post_seg.png', copy_result_img[idx])\n",
    "    \n",
    "    #new_temp_right = np.delete(new_lc_info, delete_right_lists)\n",
    "    \n",
    "    ############################################################\n",
    "    ############################################################\n",
    "    ############################################################\n",
    "    #ym_left_l2_diff[idx] = np.sqrt(np.square((left_gt[0] - left_pred[0]) * _y_convert) + np.square((left_gt[1] - left_pred[1]) * _x_convert) )\n",
    "\n",
    "    no_post_lc_width_arr[idx] = np.linalg.norm(max_end_coord -min_end_coord)\n",
    "    #lc_width_arr[idx] = np.linalg.norm(final_lc_right -final_lc_left)\n",
    "    lc_width_arr[idx] = physical_distance_converter((final_lc_right[0], final_lc_right[1]), (final_lc_left[0], final_lc_left[1]))\n",
    "    print('lc width : {}'.format(lc_width_arr[idx]))\n",
    "    # convert to physical distance\n",
    "    #no_post_lc_width_arr[idx] = np.sqrt(np.square((max_end_coord[0] - min_end_coord[0]) * _y_convert) + np.square((max_end_coord[1] - min_end_coord[1]) * _x_convert) )\n",
    "    #lc_width_arr[idx] = np.linalg.norm(final_lc_right -final_lc_left)\n",
    "    \n",
    "    cv2.line(copy_result_img[idx], (final_lc_left[1], final_lc_left[0]), (final_lc_right[1],final_lc_right[0]), (255,0,255), 2 )\n",
    "    cv2.imwrite(save_folder+str(idx)+'_lc_width.png',copy_result_img[idx])\n",
    "    #cv2.line(copy_result_img[idx], (min_end_coord[1], min_end_coord[0]), (max_end_coord[1],max_end_coord[0]), (255,0,255), 2 )\n",
    "    \n",
    "    # get laminar cribrosa curve depth final_lc_left, final_lc_right \n",
    "    print('min end coord : {} max end coord : {} max - min : {} '.format(min_end_coord, max_end_coord, (max_end_coord - min_end_coord)))\n",
    "    \n",
    "    max_lc_d , max_lc_coord = get_perpendicular_dist(final_lc_left, final_lc_right, new_final_lc_row,new_final_lc_col)\n",
    "    lc_d_draw_coord = get_intersection_perpendicular_n_line(final_lc_left, final_lc_right, max_lc_coord)\n",
    "    no_post_max_lc_d , no_post_max_lc_coord = get_perpendicular_dist(min_end_coord, max_end_coord, lc_border_row, lc_border_col)\n",
    "    \n",
    "    '''\n",
    "    circle_coord = (max_lc_coord[1], max_lc_coord[0])\n",
    "    print(circle_coord)\n",
    "    cv2.circle(copy_result_img[idx] ,circle_coord, 3,(0,255,255),-1)\n",
    "    \n",
    "    temp_circle_coord = (lc_d_draw_coord [1], lc_d_draw_coord [0])\n",
    "    cv2.circle(copy_result_img[idx] ,temp_circle_coord, 3,(0,255,255),-1)\n",
    "    '''\n",
    "    cv2.line(copy_result_img[idx], (max_lc_coord[1], max_lc_coord[0]), (lc_d_draw_coord[1], lc_d_draw_coord [0]), (0,255,255), 2 )\n",
    "    cv2.imwrite(save_folder+str(idx)+'_LCCD.png',copy_result_img[idx])\n",
    "    physical_max_lc_d = physical_distance_converter((max_lc_coord[0], max_lc_coord[1]), (lc_d_draw_coord[0], lc_d_draw_coord [1]))\n",
    "    print('physical max d : ', np.shape(physical_max_lc_d))\n",
    "    print('physical max d : ', physical_max_lc_d)\n",
    "    physical_max_lc_d = physical_max_lc_d\n",
    "\n",
    "    left_bmo_coord =np.array((recon_bmo01_center[idx][0] ,recon_bmo01_center[idx][1]))\n",
    "    right_bmo_coord =np.array((recon_bmo02_center[idx][0] ,recon_bmo02_center[idx][1]))\n",
    "    \n",
    "    # get laminar cribrosa depth\n",
    "    lc_max_dep_row, lc_max_dep_col = detectPeakPoint(new_final_lc_row, new_final_lc_col)\n",
    "    no_post_lc_max_dep_row, no_post_lc_max_dep_col = detectPeakPoint(lc_border_row, lc_border_col)\n",
    "    \n",
    "    max_bmo_d  = getBmoPerpendicularDist(left_bmo_coord,right_bmo_coord,lc_max_dep_row, lc_max_dep_col)\n",
    "    max_bmo_coord = (lc_max_dep_row, lc_max_dep_col)\n",
    "    bmo_d_draw_coord = get_intersection_perpendicular_n_line(left_bmo_coord, right_bmo_coord, max_bmo_coord )\n",
    "\n",
    "    \n",
    "    no_post_max_bmo_d  = getBmoPerpendicularDist(left_bmo_coord,right_bmo_coord,no_post_lc_max_dep_row, no_post_lc_max_dep_col)\n",
    "    no_post_max_bmo_coord = (no_post_lc_max_dep_row, no_post_lc_max_dep_col)\n",
    "    \n",
    "    #circle_coord02 = (max_bmo_coord[1], max_bmo_coord[0])\n",
    "    #cv2.circle(copy_result_img[idx] ,circle_coord02, 3,(255,255,255),-1)\n",
    "    \n",
    "    \n",
    "    cv2.line(copy_result_img[idx], (max_bmo_coord[1], max_bmo_coord[0]), (bmo_d_draw_coord[1],bmo_d_draw_coord[0]), (255,255,255), 2 )\n",
    "    print('bmo0 {} bmo1 {} bmoD0 {} bmoD1 {}'.format(max_bmo_coord[0], max_bmo_coord[1],bmo_d_draw_coord[0],bmo_d_draw_coord[1]))\n",
    "\n",
    "    physical_max_bmo_d = physical_distance_converter(np.array((max_bmo_coord[0], max_bmo_coord[1])),  np.array((bmo_d_draw_coord[0],bmo_d_draw_coord[1])))\n",
    "    \n",
    "    show_on_jupyter(copy_result_img[idx], fig_size=(15,15))\n",
    "    cv2.imwrite(save_folder+str(idx)+'_final.png', copy_result_img[idx])\n",
    "    if VALID_TEST == 'test':\n",
    "        cv2.imwrite(lc_save_folder+LC_NAME+'_'+str(idx)+'_final.png', copy_result_img[idx])\n",
    "        \n",
    "    print('physical distance LCD : {} LCCD : {} '.format(physical_max_bmo_d, physical_max_lc_d))\n",
    "    \n",
    "    print('LCD : {} LCCD : {} LCCI : {} '.format( physical_max_bmo_d,physical_max_lc_d, ((physical_max_lc_d / lc_width_arr[idx])* 100)))\n",
    "    PRED_LCD.append(physical_max_bmo_d)\n",
    "    PRED_LCCD.append(physical_max_lc_d)\n",
    "    PRED_LCCI.append(((physical_max_lc_d / lc_width_arr[idx])* 100))\n",
    "    \n",
    "    no_post_PRED_LCD.append(no_post_max_bmo_d)\n",
    "    no_post_PRED_LCCD.append(no_post_max_lc_d)\n",
    "    no_post_PRED_LCCI.append(((no_post_max_lc_d / no_post_lc_width_arr[idx])* 100))\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LC_PARAM_TABLE = pd.DataFrame(columns= ['LCD', 'LCCD', 'LCCI'])\n",
    "AVG_LC_PARAM_TABLE = pd.DataFrame(columns= ['AVG_LCD', 'AVG_LCCD', 'AVG_LCCI'])\n",
    "\n",
    "\n",
    "#8,7,6,5,4\n",
    "\n",
    "\n",
    "for idx in range(NUM_YOLO_RESULT):\n",
    "    LC_PARAM_TABLE.loc[idx,\"LCD\"] = PRED_LCD[idx]\n",
    "    LC_PARAM_TABLE.loc[idx,\"LCCD\"] = PRED_LCCD[idx]\n",
    "    LC_PARAM_TABLE.loc[idx,\"LCCI\"] = PRED_LCCI[idx]\n",
    "\n",
    "fig,ax = render_mpl_table(LC_PARAM_TABLE, header_columns=0, col_width=5.0)\n",
    "fig.savefig(lc_save_folder +LC_NAME+ '_LC_PARAM_TABLE.png')\n",
    "\n",
    "AVG_LC_PARAM_TABLE.loc[idx,\"AVG_LCD\"] = np.average(PRED_LCD)\n",
    "AVG_LC_PARAM_TABLE.loc[idx,\"AVG_LCCD\"] = np.average(PRED_LCCD)\n",
    "AVG_LC_PARAM_TABLE.loc[idx,\"AVG_LCCI\"] = np.average(PRED_LCCI)\n",
    "fig,ax = render_mpl_table(AVG_LC_PARAM_TABLE, header_columns=0, col_width=5.0)\n",
    "fig.savefig(lc_save_folder +LC_NAME+ '_AVG_LC_PARAM_TABLE.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clinical parameters\n",
    "- 최종적인 목표는 ground <-> pred blend-altman plot\n",
    "- 위에서 pred는 (pixel-wise) 구한 상태\n",
    "- gt를 구해야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakdetect(y_axis, x_axis = None, lookahead = 500, delta = 0):\n",
    "    \"\"\"\n",
    "    Converted from/based on a MATLAB script at http://billauer.co.il/peakdet.html\n",
    "    \n",
    "    Algorithm for detecting local maximas and minmias in a signal.\n",
    "    Discovers peaks by searching for values which are surrounded by lower\n",
    "    or larger values for maximas and minimas respectively\n",
    "    \n",
    "    keyword arguments:\n",
    "    y_axis -- A list containg the signal over which to find peaks\n",
    "    x_axis -- A x-axis whose values correspond to the 'y_axis' list and is used\n",
    "        in the return to specify the postion of the peaks. If omitted the index\n",
    "        of the y_axis is used. (default: None)\n",
    "    lookahead -- (optional) distance to look ahead from a peak candidate to\n",
    "        determine if it is the actual peak (default: 500) \n",
    "        '(sample / period) / f' where '4 >= f >= 1.25' might be a good value\n",
    "    delta -- (optional) this specifies a minimum difference between a peak and\n",
    "        the following points, before a peak may be considered a peak. Useful\n",
    "        to hinder the algorithm from picking up false peaks towards to end of\n",
    "        the signal. To work well delta should be set to 'delta >= RMSnoise * 5'.\n",
    "        (default: 0)\n",
    "            Delta function causes a 20% decrease in speed, when omitted\n",
    "            Correctly used it can double the speed of the algorithm\n",
    "    \n",
    "    return -- two lists [maxtab, mintab] containing the positive and negative\n",
    "        peaks respectively. Each cell of the lists contains a tupple of:\n",
    "        (position, peak_value) \n",
    "        to get the average peak value do 'np.mean(maxtab, 0)[1]' on the results\n",
    "    \"\"\"\n",
    "    maxtab = []\n",
    "    mintab = []\n",
    "    dump = []   #Used to pop the first hit which always if false\n",
    "       \n",
    "    length = len(y_axis)\n",
    "    if x_axis is None:\n",
    "        x_axis = range(length)\n",
    "    \n",
    "    #perform some checks\n",
    "    if length != len(x_axis):\n",
    "        raise ValueError(\"Input vectors y_axis and x_axis must have same length\")\n",
    "    if lookahead < 1:\n",
    "        raise ValueError(\"Lookahead must be above '1' in value\")\n",
    "    if not (np.isscalar(delta) and delta >= 0):\n",
    "        raise ValueError(\"delta must be a positive number\")\n",
    "    \n",
    "    #needs to be a numpy array\n",
    "    y_axis = np.asarray(y_axis)\n",
    "    \n",
    "    #maxima and minima candidates are temporarily stored in\n",
    "    #mx and mn respectively\n",
    "    mn, mx = np.Inf, -np.Inf\n",
    "    \n",
    "    #Only detect peak if there is 'lookahead' amount of points after it\n",
    "    for index, (x, y) in enumerate(zip(x_axis[:-lookahead], y_axis[:-lookahead])):\n",
    "        if y > mx:\n",
    "            mx = y\n",
    "            mxpos = x\n",
    "        if y < mn:\n",
    "            mn = y\n",
    "            mnpos = x\n",
    "        \n",
    "        ####look for max####\n",
    "        if y < mx-delta and mx != np.Inf:\n",
    "            #Maxima peak candidate found\n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].max() < mx:\n",
    "                maxtab.append((mxpos, mx))\n",
    "                dump.append(True)\n",
    "                #set algorithm to only find minima now\n",
    "                mx = np.Inf\n",
    "                mn = np.Inf\n",
    "        \n",
    "        ####look for min####\n",
    "        if y > mn+delta and mn != -np.Inf:\n",
    "            #Minima peak candidate found \n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].min() > mn:\n",
    "                mintab.append((mnpos, mn))\n",
    "                dump.append(False)\n",
    "                #set algorithm to only find maxima now\n",
    "                mn = -np.Inf\n",
    "                mx = -np.Inf\n",
    "    \n",
    "    \n",
    "    #Remove the false hit on the first value of the y_axis\n",
    "    try:\n",
    "        if dump[0]:\n",
    "            maxtab.pop(0)\n",
    "            #print \"pop max\"\n",
    "        else:\n",
    "            mintab.pop(0)\n",
    "            #print \"pop min\"\n",
    "        del dump\n",
    "    except IndexError:\n",
    "        #no peaks were found, should the function return empty lists?\n",
    "        pass\n",
    "    \n",
    "    return maxtab, mintab\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import medial_axis, skeletonize\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import find_peaks_cwt\n",
    "\n",
    "gt_lc_width_arr = np.zeros(NUM_YOLO_RESULT, dtype=np.float32)\n",
    "\n",
    "copy_gt_img = GROUND_TRUTH_IMG.copy()\n",
    "copy_ori_img = real_copy_ori_img.copy()\n",
    "\n",
    "GT_LCD = []\n",
    "GT_LCCD = []\n",
    "GT_LCCI = []\n",
    "\n",
    "avg_rmse_lists = []\n",
    "mean_peak = []\n",
    "\n",
    "for idx in range(NUM_YOLO_RESULT):\n",
    "    \n",
    "    left_bmo_center = np.asarray((LEFT_GROUND_CENTER[idx][0], LEFT_GROUND_CENTER[idx][1]))\n",
    "    right_bmo_center = np.asarray((RIGHT_GROUND_CENTER[idx][0], RIGHT_GROUND_CENTER[idx][1]))\n",
    "    print('bmo center type : {} shape : {}'.format(type(left_bmo_center), np.shape(left_bmo_center)))\n",
    "    \n",
    "    \n",
    "    copy_ori_img[idx,left_bmo_center[0], left_bmo_center[1]] = (0,0,255)\n",
    "    copy_ori_img[idx, right_bmo_center[0], right_bmo_center[1]] = (0,0,255) \n",
    "    show_on_jupyter(copy_gt_img[idx])\n",
    "    \n",
    "    \n",
    "    cv2.line(copy_ori_img[idx], (left_bmo_center[1], left_bmo_center[0]), (right_bmo_center[1], right_bmo_center[0]), (255,255,0), 2 )\n",
    "\n",
    "    # LC\n",
    "    lc_border_row, lc_border_col = np.where(np.all(GROUND_TRUTH_IMG[idx] == (255,0,0), axis=-1))\n",
    "    gray_mask = np.zeros((SHAPE_YOLO_RESULT[0], SHAPE_YOLO_RESULT[1]))\n",
    "    gray_mask[lc_border_row, lc_border_col] = True\n",
    "    gray_mask = skeletonize(gray_mask)\n",
    "    skeleton_row, skeleton_col = np.nonzero(gray_mask)\n",
    "    copy_ori_img[idx, skeleton_row, skeleton_col, :] = (0,255,0)\n",
    "    \n",
    "    #show_on_jupyter(gray_mask*255,'gray')\n",
    "\n",
    "    ################################################################################################\n",
    "    # perpendicular line to bmo terminate points\n",
    "    line_coord = createLineIterator(np.asarray(left_bmo_center), np.asarray(right_bmo_center), copy_ori_img[idx,:,:,0])\n",
    "\n",
    "    dash_constant = 5\n",
    "    slope = getSlopeVal(np.asarray(left_bmo_center), np.asarray(right_bmo_center))\n",
    "    left_target_point,left_b = getPerpendicularLineList(np.asarray(left_bmo_center), slope,target_y=450)\n",
    "    \n",
    "    left_per_line_coord = createLineIterator(np.asarray(left_bmo_center), left_target_point, copy_ori_img[idx,:,:,0])\n",
    "    left_dash_line_coord = getDashLine(left_per_line_coord, dash_constant=dash_constant, delete_connect_val=3)\n",
    "    copy_ori_img[idx,left_dash_line_coord[:,0].astype(np.uint16), left_dash_line_coord[:,1].astype(np.uint16)] = (255,255,255)\n",
    "    #cv2.circle(copy_result_img[idx] ,(recon_bmo01_center[idx][1], recon_bmo01_center[idx][0]), 5,(0,255,255))\n",
    "\n",
    "    right_target_point,right_b = getPerpendicularLineList(np.asarray(right_bmo_center), slope,target_y=450)\n",
    "    right_per_line_coord = createLineIterator(np.asarray(right_bmo_center), right_target_point, copy_ori_img[idx,:,:,0])\n",
    "    right_dash_line_coord = getDashLine(right_per_line_coord, dash_constant=dash_constant, delete_connect_val=3)\n",
    "    copy_ori_img[idx,right_dash_line_coord[:,0].astype(np.uint16), right_dash_line_coord[:,1].astype(np.uint16)] = (255,255,255)\n",
    "    \n",
    "    ################################################################################################\n",
    "    \n",
    "    \n",
    "\n",
    "    #min_col_idx = np.where(skeleton_col==np.min(skeleton_col))\n",
    "    #max_col_idx = np.where(skeleton_col == np.max(skeleton_col))\n",
    "    \n",
    "    lc_border_row, lc_border_col = np.where(np.all(copy_ori_img[idx] == (0,255,0), axis=-1))\n",
    "    show_on_jupyter(copy_ori_img[idx])\n",
    "    \n",
    "    L_per_info = (left_per_line_coord[:,0].astype(np.uint16), left_per_line_coord[:,1].astype(np.uint16))\n",
    "    R_per_info = (right_per_line_coord[:,0].astype(np.uint16), right_per_line_coord[:,1].astype(np.uint16))\n",
    "    left, right = getWidthPoint(np.shape(YOLO_IMGS),(lc_border_row,lc_border_col),L_per_info, R_per_info)\n",
    "    \n",
    "    \n",
    "    #min_end_coord =np.array((skeleton_row[min_col_idx[0][0]] ,skeleton_col[min_col_idx[0][0]]))\n",
    "    #max_end_coord =np.array((skeleton_row[max_col_idx[0][0]] ,skeleton_col[max_col_idx[0][0]]))\n",
    "    min_end_coord = left\n",
    "    max_end_coord = right\n",
    "    gt_lc_width_arr[idx] = np.linalg.norm(max_end_coord - min_end_coord)\n",
    "    \n",
    "    \n",
    "    cv2.line(copy_ori_img[idx], (min_end_coord[1], min_end_coord[0]), (max_end_coord[1],max_end_coord[0]), (255,0,255), 2 )\n",
    "\n",
    "    max_lc_d , max_lc_coord = get_perpendicular_dist(min_end_coord, max_end_coord,skeleton_row, skeleton_col)\n",
    "    circle_coord = (max_lc_coord[1], max_lc_coord[0])\n",
    "    print(circle_coord)\n",
    "    print('circle : ', circle_coord[0], circle_coord[1])\n",
    "    cv2.circle(copy_ori_img[idx] ,circle_coord, 3,(0,255,255))\n",
    "    \n",
    "    \n",
    "    left_bmo_coord =np.array((left_bmo_center[0] ,left_bmo_center[1]))\n",
    "    right_bmo_coord =np.array((right_bmo_center[0] ,right_bmo_center[1]))\n",
    "    \n",
    "    \n",
    "    lc_max_dep_row, lc_max_dep_col = detectPeakPoint(skeleton_row, skeleton_col)\n",
    "    max_bmo_d  = getBmoPerpendicularDist(left_bmo_coord,right_bmo_coord,lc_max_dep_row, lc_max_dep_col)\n",
    "    max_bmo_coord = (lc_max_dep_row, lc_max_dep_col)\n",
    "    circle_coord02 = (max_bmo_coord[1], max_bmo_coord[0])\n",
    "    \n",
    "    #max_bmo_d , max_bmo_coord = get_perpendicular_dist(left_bmo_coord,right_bmo_coord,lc_border_row, lc_border_col)\n",
    "    #circle_coord02 = (max_bmo_coord[1], max_bmo_coord[0])\n",
    "    \n",
    "    cv2.circle(copy_ori_img[idx] ,circle_coord02, 3,(255,255,255))\n",
    "    show_on_jupyter(copy_ori_img[idx], fig_size=(13,13))\n",
    "    \n",
    "    print('LCD : {} LCCD : {} LCCI : {} '.format( max_bmo_d,max_lc_d, ((max_lc_d / gt_lc_width_arr[idx])* 100)))\n",
    "    GT_LCD.append(max_bmo_d)\n",
    "    GT_LCCD.append(max_lc_d)\n",
    "    GT_LCCI.append(((max_lc_d / gt_lc_width_arr[idx])* 100))\n",
    "print('aveage rmse : ', np.mean(np.array(avg_rmse_lists)))\n",
    "print('mean peak : ',np.mean(np.array(mean_peak)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.divide(PRED_LCD,GT_LCD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(np.divide(PRED_LCD,GT_LCD)))\n",
    "print(np.average(np.divide(PRED_LCCD,GT_LCCD)))\n",
    "print(np.average(np.divide(PRED_LCCI,GT_LCCI)))\n",
    "print(np.average(np.divide(lc_width_arr, gt_lc_width_arr)))\n",
    "\n",
    "\n",
    "print(np.average(np.divide(no_post_PRED_LCD,GT_LCD)))\n",
    "print(np.average(np.divide(no_post_PRED_LCCD,GT_LCCD)))\n",
    "print(np.average(np.divide(no_post_PRED_LCCI,GT_LCCI)))\n",
    "print(np.average(np.divide(no_post_lc_width_arr, gt_lc_width_arr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def bland_altman_plot(data1, data2, *args, **kwargs):\n",
    "    data1     = np.asarray(data1)\n",
    "    data2     = np.asarray(data2)\n",
    "    mean      = np.mean([data1, data2], axis=0)\n",
    "    diff      = data1 - data2                   # Difference between data1 and data2\n",
    "    md        = np.mean(diff)                   # Mean of the difference\n",
    "    sd        = np.std(diff, axis=0)            # Standard deviation of the difference\n",
    "\n",
    "    plt.scatter(mean, diff, *args, **kwargs)\n",
    "    plt.axhline(md,           color='gray', linestyle='--')\n",
    "    plt.axhline(md + 1.96*sd, color='gray', linestyle='--')\n",
    "    plt.axhline(md - 1.96*sd, color='gray', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import random\n",
    "\n",
    "bland_altman_plot(np.array(GT_LCD),np.array(PRED_LCD))\n",
    "plt.title('Bland-Altman Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bland_altman_plot(np.array(GT_LCCD),np.array(PRED_LCCD))\n",
    "plt.title('Bland-Altman Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bland_altman_plot(np.array(GT_LCCI),np.array(PRED_LCCI))\n",
    "plt.title('Bland-Altman Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "save_folder = './pipe_result/'+str(name_experiment)+'/'\n",
    "print(save_folder)\n",
    "f, ax = plt.subplots(1, figsize = (8,5))\n",
    "sm.graphics.mean_diff_plot(np.array(GT_LCD), np.array(PRED_LCD), ax = ax)\n",
    "plt.savefig(save_folder+str(spline_order) + '_LCD_bland_altman.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize = (8,5))\n",
    "sm.graphics.mean_diff_plot(np.array(GT_LCCD), np.array(PRED_LCCD), ax = ax)\n",
    "plt.savefig(save_folder +str(spline_order)+ 'LCCD_bland_altman.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize = (8,5))\n",
    "sm.graphics.mean_diff_plot(np.array(GT_LCCI), np.array(PRED_LCCI), ax = ax)\n",
    "plt.savefig(save_folder +str(spline_order)+ '_LCCI_bland_altman.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width blend altman plot\n",
    "\n",
    "f, ax = plt.subplots(1, figsize = (8,5))\n",
    "sm.graphics.mean_diff_plot(np.array(gt_lc_width_arr), np.array(lc_width_arr), ax = ax)\n",
    "plt.savefig(save_folder +str(spline_order)+ '_width_bland_altman.png')\n",
    "plt.show()\n",
    "\n",
    "Glaucoma_OCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width blend altman plot\n",
    "\n",
    "f, ax = plt.subplots(1, figsize = (8,5))\n",
    "sm.graphics.mean_diff_plot(np.array(gt_lc_width_arr), np.array(no_post_lc_width_arr), ax = ax)\n",
    "plt.savefig(save_folder +str(spline_order)+ '_no_post_width_bland_altman.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_width_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_lc_width_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_post_lc_width_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "LCCD_PEARSON = scipy.stats.pearsonr(GT_LCCD, PRED_LCCD)\n",
    "LCD_PEARSON = scipy.stats.pearsonr(GT_LCD, PRED_LCD)\n",
    "LCCI_PEARSON = scipy.stats.pearsonr(GT_LCCI, PRED_LCCI)\n",
    "\n",
    "print(LCCD_PEARSON)\n",
    "print(LCD_PEARSON)\n",
    "print(LCCI_PEARSON)\n",
    "\n",
    "print(LCD_PEARSON[0]**2)\n",
    "print(LCCI_PEARSON[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "column_A= GT_LCCD\n",
    "column_B= PRED_LCCD\n",
    "df = pd.DataFrame({'A': column_A, 'B': column_B})\n",
    "\n",
    "reg = stats.linregress(df.A, df.B)\n",
    "\n",
    "plt.plot(df.A, df.B, 'bo', label='Data')\n",
    "plt.plot(df.A, reg.intercept + reg.slope * df.A, 'k-', label='Linear Regression')\n",
    "plt.xlabel('Ground-truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.text(0.000001, 0.45,'R-squared : {} \\np-value < 0.01'.format(round(LCCD_PEARSON[0]**2,4)), transform=ax.transAxes)\n",
    "plt.legend()\n",
    "plt.savefig(save_folder+str(spline_order)+'_LCCD_correlation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_A= GT_LCD\n",
    "column_B= PRED_LCD\n",
    "df = pd.DataFrame({'A': column_A, 'B': column_B})\n",
    "\n",
    "reg = stats.linregress(df.A, df.B)\n",
    "\n",
    "plt.plot(df.A, df.B, 'bo', label='Data')\n",
    "plt.plot(df.A, reg.intercept + reg.slope * df.A, 'k-', label='Linear Regression')\n",
    "plt.xlabel('Ground-truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.text(0.000001, 0.45,'R-squared : {} \\np-value < 0.01'.format(round(LCD_PEARSON[0]**2,4)), transform=ax.transAxes)\n",
    "plt.legend()\n",
    "plt.savefig(save_folder+str(spline_order)+'_LCD_correlation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_A= GT_LCCI\n",
    "column_B= PRED_LCCI\n",
    "df = pd.DataFrame({'A': column_A, 'B': column_B})\n",
    "\n",
    "reg = stats.linregress(df.A, df.B)\n",
    "\n",
    "plt.plot(df.A, df.B, 'bo', label='Data')\n",
    "plt.plot(df.A, reg.intercept + reg.slope * df.A, 'k-', label='Linear Regression')\n",
    "plt.xlabel('Ground-truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.text(0.000001, 0.45,'R-squared : {} \\np-value < 0.01'.format(round(LCCI_PEARSON[0]**2,4)), transform=ax.transAxes)\n",
    "plt.legend()\n",
    "plt.savefig(save_folder+str(spline_order)+'_LCCI_correlation.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_table = pd.DataFrame(columns=['Class','Correlation factor (R)','P-value'])\n",
    "clinical_table.loc[0,'Class' ] = 'LCCD'\n",
    "clinical_table.loc[0,'Correlation factor (R)' ] = LCCD_PEARSON[0]\n",
    "clinical_table.loc[0,'P-value' ] = LCCD_PEARSON[1]\n",
    "\n",
    "clinical_table.loc[1,'Class' ] = 'LCD'\n",
    "clinical_table.loc[1,'Correlation factor (R)' ] = LCD_PEARSON[0]\n",
    "clinical_table.loc[1,'P-value' ] = LCD_PEARSON[1]\n",
    "\n",
    "clinical_table.loc[2,'Class' ] = 'LCCI'\n",
    "clinical_table.loc[2,'Correlation factor (R)' ] = LCCI_PEARSON[0]\n",
    "clinical_table.loc[2,'P-value' ] = LCCI_PEARSON[1]\n",
    "\n",
    "clinical_table.to_excel(save_folder +str(spline_order)+ \"_clinical_table.xlsx\")  \n",
    "clinical_table.to_csv(save_folder +str(spline_order)+ \"_clinical_table.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [4,5,6,7,8]\n",
    "normal_lcd = [405.72, 411.32, 376.99, 392.13, 403.07]\n",
    "glaucoma_lcd = [635.73,566.47,598.38,674.24,672.96]\n",
    "\n",
    "normal_lccd = [23.53,43.14,52.49,33.77,47.06]\n",
    "glaucoma_lccd = [178.44,111.39,124.23,127.83,194.51]\n",
    "\n",
    "normal_lcci = [1.39,4.48,3.13,2.11,3.49]\n",
    "glaucoma_lcci = [7.74,4.90,7.41,5.40,9.12]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x,normal_lcd,color='r',zorder=2)\n",
    "plt.plot(x,normal_lcd,color='r',zorder=1, label= 'Normal')\n",
    "\n",
    "plt.scatter(x,glaucoma_lcd,color='b',zorder=2)\n",
    "plt.plot(x,glaucoma_lcd,color='b',zorder=1, label = 'Glaucoma')\n",
    "\n",
    "plt.xlabel(\"Plane number\", fontsize = 25)\n",
    "plt.ylabel(\"LCD (µm)\", fontsize = 25)\n",
    "plt.xticks(fontsize = 18)\n",
    "plt.yticks(fontsize = 18)\n",
    "\n",
    "plt.ylim(200, 800)\n",
    "plt.legend(fontsize='x-large')\n",
    "\n",
    "plt.savefig('./case_study/lcd_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
