{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bono/.pyenv/versions/3.5.5/envs/gpuTest/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bono/.pyenv/versions/3.5.5/envs/gpuTest/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bono/.pyenv/versions/3.5.5/envs/gpuTest/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bono/.pyenv/versions/3.5.5/envs/gpuTest/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bono/.pyenv/versions/3.5.5/envs/gpuTest/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bono/.pyenv/versions/3.5.5/envs/gpuTest/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import configparser\n",
    "import shutil\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model as plotn\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import models\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './lib_keras/')\n",
    "from help_functions import *\n",
    "\n",
    "from lib_keras.model_lib import *\n",
    "#function to obtain data for training/testing (validation)\n",
    "from temp_extract_patches import temp_get_data_training\n",
    "\n",
    "print(K.tensorflow_backend._get_available_gpus())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom U-net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " path data : ./data/hdf5_data/inha_oct/\n",
      " save_folder : result\n",
      " name_experiment : 01_2class_borderSegTest\n",
      " num_epoches : 50\n",
      " batch_size : 8\n",
      "\n",
      "OrderedDict([((0, 0, 0), 0), ((255, 0, 0), 1), ((0, 0, 255), 2)])\n",
      "3\n",
      "./result/01_2class_borderSegTest/\n"
     ]
    }
   ],
   "source": [
    "config = configparser.RawConfigParser()\n",
    "config.read('configuration.txt')\n",
    "#patch to the datasets\n",
    "path_data = config.get('data paths', 'path_local')\n",
    "#Experiment name\n",
    "save_folder = config.get('experiment name','result_save_path')\n",
    "name_experiment = config.get('experiment name', 'name')\n",
    "\n",
    "#training settings\n",
    "num_epochs = int(config.get('training settings', 'num_epochs'))\n",
    "batch_size = int(config.get('training settings', 'batch_size'))\n",
    "\n",
    "print(' path data : {}\\n save_folder : {}\\n name_experiment : {}\\n num_epoches : {}\\n batch_size : {}\\n'.format(path_data, save_folder,\\\n",
    "                                                                                                               name_experiment,\\\n",
    "                                                                                                               num_epochs,batch_size))\n",
    "'''\n",
    "5 class\n",
    "class01 (255,0,0), Red , RNFL\n",
    "class02 (0,255,0), Green, other layers\n",
    "class03 (0,0,255), Blue, RPE\n",
    "class04 (255,255,0), Yellow, LC\n",
    "\n",
    "'''\n",
    "mapping = OrderedDict()\n",
    "mapping[(0,0,0)] = 0\n",
    "mapping[(255,0,0)] = 1\n",
    "mapping[(0,0,255)] = 2\n",
    "\n",
    "\n",
    "print(mapping)\n",
    "print(len(mapping))\n",
    "print('./'+save_folder+'/'+name_experiment+'/')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist the folder in this path : ./result/01_2class_borderSegTest/\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('./'+save_folder+'/'+name_experiment+'/') == False:\n",
    "    os.mkdir('./'+save_folder+'/'+name_experiment+'/')\n",
    "else:\n",
    "    print('already exist the folder in this path : {}'.format('./'+save_folder+'/'+name_experiment+'/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./result/01_2class_borderSegTest/configuration.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data + config.get('data paths', 'train_groundTruth')\n",
    "\n",
    "# copy configuration\n",
    "\n",
    "shutil.copyfile('./configuration.txt', './'+save_folder+'/'+name_experiment+'/configuration.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract patch for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train path : ./data/hdf5_data/inha_oct/inha_oct_train.hdf5\n",
      " train label path : ./data/hdf5_data/inha_oct/inha_oct_groundTruth_train.hdf5\n",
      " patch height : 64 patch width : 64\n",
      " num subimgs : 100000 \t inside FOV : False \t save path : result/01_2class_borderSegTest\n"
     ]
    }
   ],
   "source": [
    "print(' train path : {}\\n train label path : {}\\n patch height : {} patch width : {}\\n\\\n",
    " num subimgs : {} \\t inside FOV : {} \\t save path : {}'.format(path_data + config.get('data paths', 'train_imgs_original'),\\\n",
    "                                                       path_data + config.get('data paths', 'train_groundTruth'),\\\n",
    "                                                       int(config.get('data attributes', 'patch_height')),\\\n",
    "                                                       int(config.get('data attributes', 'patch_width')),\\\n",
    "                                                       int(config.get('training settings', 'num_subimgs')),\\\n",
    "                                                       config.getboolean('training settings', 'inside_FOV'),\\\n",
    "                                                       save_folder+'/'+name_experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist the folder in this path : result/01_2class_borderSegTest\n",
      "number of subimages :  100000\n",
      "[DEBUG] shape of train_imgs_original :  (35, 3, 500, 760)\n",
      "[DEBUG] shape of train_imgs_label :  (35, 3, 500, 760)\n",
      "[group images func] prev data shape  : (35, 3, 500, 760)\n",
      "[group images func] after data shape :  (35, 500, 760, 3)\n",
      "[group images func] first total image :  (500, 3800, 3)\n",
      "[group images func] final total image :  (4000, 3800, 3)\n",
      "data shape :  (4000, 3800, 3)\n",
      "<PIL.Image.Image image mode=RGB size=3800x4000 at 0x7FB2217A65F8>\n",
      "file name :  ./result/01_2class_borderSegTest/imgs_train\n",
      "[group images func] prev data shape  : (35, 3, 500, 760)\n",
      "[group images func] after data shape :  (35, 500, 760, 3)\n",
      "[group images func] first total image :  (500, 3800, 3)\n",
      "[group images func] final total image :  (4000, 3800, 3)\n",
      "data shape :  (4000, 3800, 3)\n",
      "<PIL.Image.Image image mode=RGB size=3800x4000 at 0x7FB2217A65F8>\n",
      "file name :  ./result/01_2class_borderSegTest/imgs_labels\n",
      "[DEBUG] normalize shape :  (35, 1, 500, 760)\n",
      "[DEBUG] i normalize shape :  (1, 500, 760)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./lib_keras/pre_processing.py:238: RuntimeWarning: invalid value encountered in true_divide\n",
      "  imgs_normalized[i] = ((imgs_normalized[i] - np.min(imgs_normalized[i])) / (np.max(imgs_normalized[i])-np.min(imgs_normalized[i])))*255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[group images func] prev data shape  : (35, 1, 500, 760)\n",
      "[group images func] after data shape :  (35, 500, 760, 1)\n",
      "[group images func] first total image :  (500, 3800, 1)\n",
      "[group images func] final total image :  (4000, 3800, 1)\n",
      "data shape :  (4000, 3800, 1)\n",
      "<PIL.Image.Image image mode=L size=3800x4000 at 0x7FB2217A6E80>\n",
      "file name :  ./result/01_2class_borderSegTest/preprocessed\n",
      "\n",
      "\n",
      "[get_data_training] preprocessed image shape :  (35, 1, 500, 760)\n",
      "\n",
      "[get_data_training] preprocessed mask shape :  (35, 3, 500, 760)\n",
      "mask maximum val :  255.0\n",
      "[get_data_training] preprocessed2 image shape :  (35, 1, 500, 760)\n",
      "\n",
      "\n",
      "[padding] pad h size : 12\t pad w size : 8\n",
      "\n",
      "\n",
      "[padding] imgs shape : (35, 500, 760, 1)\t labels shape : (35, 500, 760, 3)\n",
      "\n",
      "\n",
      "[padding] pad imgs shape : (35, 512, 768, 1)\t pad labels shape : (35, 512, 768, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract patches:   0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[final pad] imgs shape : (35, 512, 768, 1)\t labels shape : (35, 512, 768, 3)\n",
      "\n",
      "\n",
      "[final transpose] imgs shape : (35, 1, 512, 768)\t labels shape : (35, 3, 512, 768)\n",
      "\n",
      "\n",
      "[get_data_training] train images/masks shape : (35, 1, 512, 768)\n",
      "[get_data_training] train images range (min-max) [0.0 , 1.0] \n",
      "[get_data_training] train masks are within 0-1\n",
      "\n",
      "\n",
      "\n",
      "[extract random] num of class :  3\n",
      "[extract random] full image shape : (35, 1, 512, 768)\n",
      "[extract random] full masks shape : (35, 3, 512, 768)\n",
      "[extract random] patches shape : (100000, 1, 64, 64)\n",
      "[extract random] patches masks shape : (100000, 3, 64, 64)\n",
      "[extract random] patches per full image : 2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract patches: 100%|██████████| 35/35 [02:19<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[After patch] mask shape :  (100000, 3, 64, 64)\n",
      "[Augmentation function] patches shape :  (100000, 1, 64, 64)\n",
      "[Augmentation function] augmentation patches shape :  (100000, 64, 64, 1)\n",
      "[Augmentation function] augmentation patches masks shape :  (100000, 64, 64, 3)\n",
      "\n",
      "\n",
      "[get_data_training] train PATCHES images/masks shape : (100000, 1, 64, 64)\n",
      "[get_data_training] train PATCHES images range (min-max): 0.0 - 1.0\n",
      "[get_data_training] patches_imgs_train : (100000, 1, 64, 64)\n",
      "[group images func] prev data shape  : (50, 1, 64, 64)\n",
      "[group images func] after data shape :  (50, 64, 64, 1)\n",
      "[group images func] first total image :  (64, 320, 1)\n",
      "[group images func] final total image :  (704, 320, 1)\n",
      "data shape :  (704, 320, 1)\n",
      "<PIL.Image.Image image mode=L size=320x704 at 0x7FB22172A6A0>\n",
      "file name :  ./result/01_2class_borderSegTest/train_patch_img\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "patches_imgs_train, patches_masks_train, class_freq_tabel = temp_get_data_training(\n",
    "    train_imgs_original = path_data + config.get('data paths', 'train_imgs_original'),\n",
    "    train_groudTruth = path_data + config.get('data paths', 'train_groundTruth'),  #masks\n",
    "    patch_height = int(config.get('data attributes', 'patch_height')),\n",
    "    patch_width = int(config.get('data attributes', 'patch_width')),\n",
    "    num_subimgs = int(config.get('training settings', 'num_subimgs')),\n",
    "    label_mapping = mapping,\n",
    "    inside_FOV = config.getboolean('training settings', 'inside_FOV'), #select the patches only inside the FOV  (default == True)\n",
    "    save_path = save_folder+'/'+name_experiment\n",
    ")\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "      <th>frequency_0</th>\n",
       "      <th>frequency_1</th>\n",
       "      <th>frequency_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11686830</td>\n",
       "      <td>7104</td>\n",
       "      <td>8338</td>\n",
       "      <td>0.99868</td>\n",
       "      <td>0.000607062</td>\n",
       "      <td>0.000712511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11682017</td>\n",
       "      <td>6808</td>\n",
       "      <td>13447</td>\n",
       "      <td>0.998269</td>\n",
       "      <td>0.000581767</td>\n",
       "      <td>0.00114909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11688266</td>\n",
       "      <td>3898</td>\n",
       "      <td>10108</td>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.000333098</td>\n",
       "      <td>0.000863764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11686630</td>\n",
       "      <td>5208</td>\n",
       "      <td>10434</td>\n",
       "      <td>0.998663</td>\n",
       "      <td>0.000445042</td>\n",
       "      <td>0.000891622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11687919</td>\n",
       "      <td>5457</td>\n",
       "      <td>8896</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>0.00046632</td>\n",
       "      <td>0.000760194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11681874</td>\n",
       "      <td>6869</td>\n",
       "      <td>13529</td>\n",
       "      <td>0.998257</td>\n",
       "      <td>0.00058698</td>\n",
       "      <td>0.0011561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11702272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11684340</td>\n",
       "      <td>6140</td>\n",
       "      <td>11792</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0.000524684</td>\n",
       "      <td>0.00100767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11690179</td>\n",
       "      <td>4115</td>\n",
       "      <td>7978</td>\n",
       "      <td>0.998967</td>\n",
       "      <td>0.000351641</td>\n",
       "      <td>0.000681748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11688236</td>\n",
       "      <td>5582</td>\n",
       "      <td>8454</td>\n",
       "      <td>0.998801</td>\n",
       "      <td>0.000477001</td>\n",
       "      <td>0.000722424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11684258</td>\n",
       "      <td>5539</td>\n",
       "      <td>12475</td>\n",
       "      <td>0.998461</td>\n",
       "      <td>0.000473327</td>\n",
       "      <td>0.00106603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11689660</td>\n",
       "      <td>3949</td>\n",
       "      <td>8663</td>\n",
       "      <td>0.998922</td>\n",
       "      <td>0.000337456</td>\n",
       "      <td>0.000740284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11685536</td>\n",
       "      <td>3441</td>\n",
       "      <td>13295</td>\n",
       "      <td>0.99857</td>\n",
       "      <td>0.000294045</td>\n",
       "      <td>0.0011361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11680944</td>\n",
       "      <td>5838</td>\n",
       "      <td>15490</td>\n",
       "      <td>0.998177</td>\n",
       "      <td>0.000498877</td>\n",
       "      <td>0.00132367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11680844</td>\n",
       "      <td>3260</td>\n",
       "      <td>18168</td>\n",
       "      <td>0.998169</td>\n",
       "      <td>0.000278578</td>\n",
       "      <td>0.00155252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11687355</td>\n",
       "      <td>3418</td>\n",
       "      <td>11499</td>\n",
       "      <td>0.998725</td>\n",
       "      <td>0.00029208</td>\n",
       "      <td>0.00098263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11687570</td>\n",
       "      <td>5572</td>\n",
       "      <td>9130</td>\n",
       "      <td>0.998744</td>\n",
       "      <td>0.000476147</td>\n",
       "      <td>0.00078019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11683059</td>\n",
       "      <td>4611</td>\n",
       "      <td>14602</td>\n",
       "      <td>0.998358</td>\n",
       "      <td>0.000394026</td>\n",
       "      <td>0.00124779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11687712</td>\n",
       "      <td>3501</td>\n",
       "      <td>11059</td>\n",
       "      <td>0.998756</td>\n",
       "      <td>0.000299173</td>\n",
       "      <td>0.00094503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11684389</td>\n",
       "      <td>4441</td>\n",
       "      <td>13442</td>\n",
       "      <td>0.998472</td>\n",
       "      <td>0.000379499</td>\n",
       "      <td>0.00114867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11679502</td>\n",
       "      <td>5368</td>\n",
       "      <td>17402</td>\n",
       "      <td>0.998054</td>\n",
       "      <td>0.000458714</td>\n",
       "      <td>0.00148706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11685112</td>\n",
       "      <td>7478</td>\n",
       "      <td>9682</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.000639021</td>\n",
       "      <td>0.000827361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11687053</td>\n",
       "      <td>5087</td>\n",
       "      <td>10132</td>\n",
       "      <td>0.998699</td>\n",
       "      <td>0.000434702</td>\n",
       "      <td>0.000865815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11687629</td>\n",
       "      <td>4418</td>\n",
       "      <td>10225</td>\n",
       "      <td>0.998749</td>\n",
       "      <td>0.000377534</td>\n",
       "      <td>0.000873762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11689729</td>\n",
       "      <td>4092</td>\n",
       "      <td>8451</td>\n",
       "      <td>0.998928</td>\n",
       "      <td>0.000349676</td>\n",
       "      <td>0.000722167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11688558</td>\n",
       "      <td>3248</td>\n",
       "      <td>10466</td>\n",
       "      <td>0.998828</td>\n",
       "      <td>0.000277553</td>\n",
       "      <td>0.000894356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11682542</td>\n",
       "      <td>6014</td>\n",
       "      <td>13716</td>\n",
       "      <td>0.998314</td>\n",
       "      <td>0.000513917</td>\n",
       "      <td>0.00117208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11682396</td>\n",
       "      <td>4389</td>\n",
       "      <td>15487</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.000375055</td>\n",
       "      <td>0.00132342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11685228</td>\n",
       "      <td>4929</td>\n",
       "      <td>12115</td>\n",
       "      <td>0.998544</td>\n",
       "      <td>0.0004212</td>\n",
       "      <td>0.00103527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11687100</td>\n",
       "      <td>3402</td>\n",
       "      <td>11770</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.000290713</td>\n",
       "      <td>0.00100579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11677762</td>\n",
       "      <td>9393</td>\n",
       "      <td>15117</td>\n",
       "      <td>0.997906</td>\n",
       "      <td>0.000802665</td>\n",
       "      <td>0.0012918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11679797</td>\n",
       "      <td>6903</td>\n",
       "      <td>15572</td>\n",
       "      <td>0.998079</td>\n",
       "      <td>0.000589885</td>\n",
       "      <td>0.00133068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>11682014</td>\n",
       "      <td>4953</td>\n",
       "      <td>15305</td>\n",
       "      <td>0.998269</td>\n",
       "      <td>0.000423251</td>\n",
       "      <td>0.00130787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>11686083</td>\n",
       "      <td>5328</td>\n",
       "      <td>10861</td>\n",
       "      <td>0.998617</td>\n",
       "      <td>0.000455296</td>\n",
       "      <td>0.00092811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>11683959</td>\n",
       "      <td>4737</td>\n",
       "      <td>13576</td>\n",
       "      <td>0.998435</td>\n",
       "      <td>0.000404793</td>\n",
       "      <td>0.00116012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_0 class_1 class_2 frequency_0  frequency_1  frequency_2\n",
       "0   11686830    7104    8338     0.99868  0.000607062  0.000712511\n",
       "1   11682017    6808   13447    0.998269  0.000581767   0.00114909\n",
       "2   11688266    3898   10108    0.998803  0.000333098  0.000863764\n",
       "3   11686630    5208   10434    0.998663  0.000445042  0.000891622\n",
       "4   11687919    5457    8896    0.998773   0.00046632  0.000760194\n",
       "5   11681874    6869   13529    0.998257   0.00058698    0.0011561\n",
       "6   11702272       0       0           1            0            0\n",
       "7   11684340    6140   11792    0.998468  0.000524684   0.00100767\n",
       "8   11690179    4115    7978    0.998967  0.000351641  0.000681748\n",
       "9   11688236    5582    8454    0.998801  0.000477001  0.000722424\n",
       "10  11684258    5539   12475    0.998461  0.000473327   0.00106603\n",
       "11  11689660    3949    8663    0.998922  0.000337456  0.000740284\n",
       "12  11685536    3441   13295     0.99857  0.000294045    0.0011361\n",
       "13  11680944    5838   15490    0.998177  0.000498877   0.00132367\n",
       "14  11680844    3260   18168    0.998169  0.000278578   0.00155252\n",
       "15  11687355    3418   11499    0.998725   0.00029208   0.00098263\n",
       "16  11687570    5572    9130    0.998744  0.000476147   0.00078019\n",
       "17  11683059    4611   14602    0.998358  0.000394026   0.00124779\n",
       "18  11687712    3501   11059    0.998756  0.000299173   0.00094503\n",
       "19  11684389    4441   13442    0.998472  0.000379499   0.00114867\n",
       "20  11679502    5368   17402    0.998054  0.000458714   0.00148706\n",
       "21  11685112    7478    9682    0.998534  0.000639021  0.000827361\n",
       "22  11687053    5087   10132    0.998699  0.000434702  0.000865815\n",
       "23  11687629    4418   10225    0.998749  0.000377534  0.000873762\n",
       "24  11689729    4092    8451    0.998928  0.000349676  0.000722167\n",
       "25  11688558    3248   10466    0.998828  0.000277553  0.000894356\n",
       "26  11682542    6014   13716    0.998314  0.000513917   0.00117208\n",
       "27  11682396    4389   15487    0.998302  0.000375055   0.00132342\n",
       "28  11685228    4929   12115    0.998544    0.0004212   0.00103527\n",
       "29  11687100    3402   11770    0.998703  0.000290713   0.00100579\n",
       "30  11677762    9393   15117    0.997906  0.000802665    0.0012918\n",
       "31  11679797    6903   15572    0.998079  0.000589885   0.00133068\n",
       "32  11682014    4953   15305    0.998269  0.000423251   0.00130787\n",
       "33  11686083    5328   10861    0.998617  0.000455296   0.00092811\n",
       "34  11683959    4737   13576    0.998435  0.000404793   0.00116012"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_freq_tabel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_class_00</th>\n",
       "      <th>avg_class_01</th>\n",
       "      <th>avg_class_02</th>\n",
       "      <th>avg_freq_00</th>\n",
       "      <th>avg_freq_01</th>\n",
       "      <th>avg_freq_02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.16856e+07</td>\n",
       "      <td>4985.43</td>\n",
       "      <td>11733.6</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>0.000426022</td>\n",
       "      <td>0.00100268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  avg_class_00 avg_class_01 avg_class_02 avg_freq_00  avg_freq_01 avg_freq_02\n",
       "0  1.16856e+07      4985.43      11733.6    0.998571  0.000426022  0.00100268"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "average_class_freq = pd.DataFrame(columns=['avg_class_00', 'avg_class_01', 'avg_class_02', 'avg_freq_00','avg_freq_01','avg_freq_02'])\n",
    "\n",
    "average_class_freq.loc[0,'avg_class_00'] = class_freq_tabel['class_0'].mean()\n",
    "average_class_freq.loc[0,'avg_class_01'] = class_freq_tabel['class_1'].mean()\n",
    "average_class_freq.loc[0,'avg_class_02'] = class_freq_tabel['class_2'].mean()\n",
    "\n",
    "\n",
    "average_class_freq.loc[0,'avg_freq_00'] = class_freq_tabel['frequency_0'].mean()\n",
    "average_class_freq.loc[0,'avg_freq_01'] = class_freq_tabel['frequency_1'].mean()\n",
    "average_class_freq.loc[0,'avg_freq_02'] = class_freq_tabel['frequency_2'].mean()\n",
    "\n",
    "average_class_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_tabel.to_csv('./'+save_folder+'/'+name_experiment+'/'+'all_class_imbalance.csv', encoding='utf-8')\n",
    "average_class_freq.to_csv('./'+save_folder+'/'+name_experiment+'/'+'avg_class_imbalance.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "patches_masks_train_class00 = patches_masks_train[:,0,:,:] \n",
    "patches_masks_train_class00 = np.expand_dims(patches_masks_train_class00,1)\n",
    "patches_masks_train_class01 = patches_masks_train[:,1,:,:] \n",
    "patches_masks_train_class01 = np.expand_dims(patches_masks_train_class01,1)\n",
    "patches_masks_train_class02 = patches_masks_train[:,2,:,:] \n",
    "patches_masks_train_class02 = np.expand_dims(patches_masks_train_class02,1)\n",
    "\n",
    "\n",
    "\n",
    "print(np.shape(patches_masks_train_class00))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[group images func] prev data shape  : (40, 1, 64, 64)\n",
      "[group images func] after data shape :  (40, 64, 64, 1)\n",
      "[group images func] first total image :  (64, 320, 1)\n",
      "[group images func] final total image :  (576, 320, 1)\n",
      "data shape :  (576, 320, 1)\n",
      "<PIL.Image.Image image mode=L size=320x576 at 0x7FB22018C7F0>\n",
      "file name :  ./result/01_2class_borderSegTest/sample_input_imgs\n",
      "[group images func] prev data shape  : (40, 1, 64, 64)\n",
      "[group images func] after data shape :  (40, 64, 64, 1)\n",
      "[group images func] first total image :  (64, 320, 1)\n",
      "[group images func] final total image :  (576, 320, 1)\n",
      "data shape :  (576, 320, 1)\n",
      "<PIL.Image.Image image mode=L size=320x576 at 0x7FB22018C7B8>\n",
      "file name :  ./result/01_2class_borderSegTest/sample_input_masks_claass0\n",
      "[group images func] prev data shape  : (40, 1, 64, 64)\n",
      "[group images func] after data shape :  (40, 64, 64, 1)\n",
      "[group images func] first total image :  (64, 320, 1)\n",
      "[group images func] final total image :  (576, 320, 1)\n",
      "data shape :  (576, 320, 1)\n",
      "<PIL.Image.Image image mode=L size=320x576 at 0x7FB22018C860>\n",
      "file name :  ./result/01_2class_borderSegTest/sample_input_masks_claass1\n",
      "[group images func] prev data shape  : (40, 1, 64, 64)\n",
      "[group images func] after data shape :  (40, 64, 64, 1)\n",
      "[group images func] first total image :  (64, 320, 1)\n",
      "[group images func] final total image :  (576, 320, 1)\n",
      "data shape :  (576, 320, 1)\n",
      "<PIL.Image.Image image mode=L size=320x576 at 0x7FB22018C780>\n",
      "file name :  ./result/01_2class_borderSegTest/sample_input_masks_claass2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAJACAAAAADZE+DrAAACBElEQVR4nO3WoWtVURwH8DPDUBYmvKAo8g7ikBkEi7JoGirDIPgwWYShQVgyyrLBYDAo2A0DwaDRLjyGaBiMHSzOMDZZ2DT4M4hNReZ797zLPp8/4Hy/fLn33JsSAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOxbvWcXmws70FxUY7aOPV271+3WrtFi048iYul87Rot1jk9txHvb9Su0WZjp/qxVrtEu40/j4e1O/yL+IPavVJKixuv+ydG/iv5c6rRnPDau9iem6jdYo9GYsJzLyPuz56pXWOPRuE5PP5g53O8mh1iwtgQz07p13zDTfmbg7uX7h7qvM0r89Uq/K/6t+LJJxFf+90LvVuVCgxA3RUnbl6J7xHx7fGLlI4M9uxmX67frNdQgamPy5ul3J5c7Ry+PJ5zXiiTR3POOc80kz9ANX92eleXY3M7IuLDpwHl17ve6+hufVk8W9ZLuXO9lFLK+pvajdqqrf/XAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAPvJD4Utt/VEozrLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=320x576 at 0x7FB22018C780>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_sample = min(patches_imgs_train.shape[0],40)\n",
    "visualize(group_images(patches_imgs_train[0:N_sample,:,:,:],5),'./'+save_folder+'/'+name_experiment+'/'+\"sample_input_imgs\")#.show()\n",
    "visualize(group_images(patches_masks_train_class00[0:N_sample,:,:,:],5),'./'+save_folder+'/'+name_experiment+'/'+\"sample_input_masks_claass0\")#.show()\n",
    "visualize(group_images(patches_masks_train_class01[0:N_sample,:,:,:],5),'./'+save_folder+'/'+name_experiment+'/'+\"sample_input_masks_claass1\")#.show()\n",
    "visualize(group_images(patches_masks_train_class02[0:N_sample,:,:,:],5),'./'+save_folder+'/'+name_experiment+'/'+\"sample_input_masks_claass2\")#.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape :  (100000, 1, 64, 64)\n",
      "n_ch : 1 patch_h : 64 patch_w : 64\n",
      "input shape :  (None, 1, 64, 64)\n",
      "\n",
      "gating shape : (None, 128, 4, 4), conv4 shape : (None, 64, 8, 8)\n",
      "shape x,g  (None, 64, 8, 8) (None, 128, 4, 4)\n",
      "inter shape :   128\n",
      "stride x : 1 stride y : 1\n",
      "theta_x shape :  (None, 128, 4, 4)\n",
      "upsample_g shape :  (None, 128, 4, 4)\n",
      "\n",
      "attn1 shape : (None, 64, 8, 8) center shape : (None, 128, 4, 4) \n",
      "\n",
      "attn1 shape : (None, 64, 8, 8) up1 shape : (None, 128, 8, 8)\n",
      "shape x,g  (None, 64, 16, 16) (None, 128, 8, 8)\n",
      "inter shape :   64\n",
      "stride x : 1 stride y : 1\n",
      "theta_x shape :  (None, 64, 8, 8)\n",
      "upsample_g shape :  (None, 64, 8, 8)\n",
      "shape x,g  (None, 32, 32, 32) (None, 128, 16, 16)\n",
      "inter shape :   64\n",
      "stride x : 1 stride y : 1\n",
      "theta_x shape :  (None, 64, 16, 16)\n",
      "upsample_g shape :  (None, 64, 16, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 64, 64)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 64, 64)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 64, 64)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 32)   9248        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 16, 16)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 16, 16)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 16, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 16, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 16, 16)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 16, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 16, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 8, 8)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 8, 8)     36928       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 8, 8)     32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 8, 8)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 8, 8)     36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 8, 8)     32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 8, 8)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 64, 4, 4)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 4, 4)    73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 4, 4)    16          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 4, 4)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 4, 4)    147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 4, 4)    16          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 4, 4)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gating01_conv (Conv2D)          (None, 128, 4, 4)    16512       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gating01_bn (BatchNormalization (None, 128, 4, 4)    16          gating01_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gating01_act (Activation)       (None, 128, 4, 4)    0           gating01_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 4, 4)    16512       gating01_act[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "g_upattn01 (Conv2DTranspose)    (None, 128, 4, 4)    147584      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "xlattn01 (Conv2D)               (None, 128, 4, 4)    32896       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 4, 4)    0           g_upattn01[0][0]                 \n",
      "                                                                 xlattn01[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 4, 4)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "psiattn01 (Conv2D)              (None, 1, 4, 4)      129         activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1, 4, 4)      0           psiattn01[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 1, 8, 8)      0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "psi_upattn01 (Lambda)           (None, 64, 8, 8)     0           up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "q_attnattn01 (Multiply)         (None, 64, 8, 8)     0           psi_upattn01[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "q_attn_convattn01 (Conv2D)      (None, 64, 8, 8)     4160        q_attnattn01[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 8, 8)     73792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "q_attn_bnattn01 (BatchNormaliza (None, 64, 8, 8)     32          q_attn_convattn01[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 8, 8)    0           conv2d_transpose_1[0][0]         \n",
      "                                                                 q_attn_bnattn01[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gating02_conv (Conv2D)          (None, 128, 8, 8)    16512       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gating02_bn (BatchNormalization (None, 128, 8, 8)    32          gating02_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gating02_act (Activation)       (None, 128, 8, 8)    0           gating02_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 8, 8)     8256        gating02_act[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "g_upattn02 (Conv2DTranspose)    (None, 64, 8, 8)     36928       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "xlattn02 (Conv2D)               (None, 64, 8, 8)     16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 8, 8)     0           g_upattn02[0][0]                 \n",
      "                                                                 xlattn02[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 8, 8)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "psiattn02 (Conv2D)              (None, 1, 8, 8)      65          activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1, 8, 8)      0           psiattn02[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 1, 16, 16)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "psi_upattn02 (Lambda)           (None, 64, 16, 16)   0           up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "q_attnattn02 (Multiply)         (None, 64, 16, 16)   0           psi_upattn02[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "q_attn_convattn02 (Conv2D)      (None, 64, 16, 16)   4160        q_attnattn02[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 16, 16)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "q_attn_bnattn02 (BatchNormaliza (None, 64, 16, 16)   64          q_attn_convattn02[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 16, 16)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 q_attn_bnattn02[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gating03_conv (Conv2D)          (None, 128, 16, 16)  16512       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gating03_bn (BatchNormalization (None, 128, 16, 16)  64          gating03_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gating03_act (Activation)       (None, 128, 16, 16)  0           gating03_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 16, 16)   8256        gating03_act[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "g_upattn03 (Conv2DTranspose)    (None, 64, 16, 16)   36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "xlattn03 (Conv2D)               (None, 64, 16, 16)   8256        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 16, 16)   0           g_upattn03[0][0]                 \n",
      "                                                                 xlattn03[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 16, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "psiattn03 (Conv2D)              (None, 1, 16, 16)    65          activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1, 16, 16)    0           psiattn03[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 1, 32, 32)    0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "psi_upattn03 (Lambda)           (None, 32, 32, 32)   0           up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "q_attnattn03 (Multiply)         (None, 32, 32, 32)   0           psi_upattn03[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "q_attn_convattn03 (Conv2D)      (None, 32, 32, 32)   1056        q_attnattn03[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 32)   36896       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "q_attn_bnattn03 (BatchNormaliza (None, 32, 32, 32)   128         q_attn_convattn03[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 32, 32)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 q_attn_bnattn03[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 32, 64, 64)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 64)   0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 3, 64, 64)    195         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 3, 4096)      0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 4096, 3)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4096, 3)      0           permute_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 954,486\n",
      "Trainable params: 953,822\n",
      "Non-trainable params: 664\n",
      "__________________________________________________________________________________________________\n",
      "Check: final output of the network:\n",
      "(None, 4096, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41736"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ch = patches_imgs_train.shape[1]\n",
    "patch_height = patches_imgs_train.shape[2]\n",
    "patch_width = patches_imgs_train.shape[3]\n",
    "print('shape : ',patches_imgs_train.shape)\n",
    "print('n_ch : {} patch_h : {} patch_w : {}'.format(n_ch, patch_height, patch_width))\n",
    "#model = naive_attn_unet(n_ch, patch_height, patch_width)  #the U-net model\n",
    "#model = unet_norm(n_ch, patch_height, patch_width,len(mapping))\n",
    "#model = naive_attn_unet(n_ch, patch_height, patch_width,len(mapping))\n",
    "\n",
    "#model = bigger_unet_norm(n_ch, patch_height, patch_width,len(mapping))\n",
    "#model = bigger_naive_attn_unet(n_ch, patch_height, patch_width,len(mapping))\n",
    "model = class3_attn_unet(n_ch, patch_height, patch_width,len(mapping))\n",
    "#model = attn_reg_test(n_ch, patch_height, patch_width,len(mapping))\n",
    "\n",
    "print (\"Check: final output of the network:\")\n",
    "print (model.output_shape)\n",
    "\n",
    "#plot(model, to_file= './'+save_folder+'/'+name_experiment+'/' +name_experiment+ '_model.png')   #check how the model looks like\n",
    "#plot(model, to_file= name_experiment+'/'+name_experiment + '_model.png')   #check how the model looks like\n",
    "\n",
    "json_string = model.to_json()\n",
    "open('./'+save_folder+'/'+name_experiment+'/' +name_experiment+'_architecture.json', 'w').write(json_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training session] mask unet func patch mask shape :q  (100000, 3, 64, 64)\n",
      "[training session] After mask unet func patch mask shape :  (100000, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Keras provides a set of functions called callbacks: \n",
    "you can think of callbacks as events that will be triggered at certain training states. \n",
    "The callback we need for checkpointing is the ModelCheckpoint \n",
    "which provides all the features we need according to the checkpointing strategy we adopted in our example\n",
    "'''\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./'+save_folder+'/'+name_experiment+'/best_weights.h5', verbose=1, monitor='val_loss', mode='auto', save_best_only=True) #save at each epoch if the validation decreased\n",
    "\n",
    "print('[training session] mask unet func patch mask shape :q ',patches_masks_train.shape)\n",
    "patches_masks_train = np.reshape(patches_masks_train, (patches_masks_train.shape[0], len(mapping), patch_height* patch_width))\n",
    "patches_masks_train = np.transpose(patches_masks_train,(0,2,1))\n",
    "#patches_masks_train = masks_Unet(patches_masks_train)  #reduce memory consumption\n",
    "print('[training session] After mask unet func patch mask shape : ',patches_masks_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "80000/80000 [==============================] - 621s 8ms/step - loss: 26.5054 - generalized_dice_coeff: 0.7433 - val_loss: 1.4454 - val_generalized_dice_coeff: 0.8603\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.44544, saving model to ./result/01_2class_borderSegTest/best_weights.h5\n",
      "Epoch 2/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 1.2421 - generalized_dice_coeff: 0.8750 - val_loss: 1.3696 - val_generalized_dice_coeff: 0.8926\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.44544 to 1.36962, saving model to ./result/01_2class_borderSegTest/best_weights.h5\n",
      "Epoch 3/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 1.1822 - generalized_dice_coeff: 0.8804 - val_loss: 1.3540 - val_generalized_dice_coeff: 0.8425\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.36962 to 1.35396, saving model to ./result/01_2class_borderSegTest/best_weights.h5\n",
      "Epoch 4/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 1.1349 - generalized_dice_coeff: 0.8849 - val_loss: 1.5026 - val_generalized_dice_coeff: 0.8159\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.35396\n",
      "Epoch 5/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 1.1212 - generalized_dice_coeff: 0.8870 - val_loss: 1.2531 - val_generalized_dice_coeff: 0.8773\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.35396 to 1.25314, saving model to ./result/01_2class_borderSegTest/best_weights.h5\n",
      "Epoch 6/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 1.1081 - generalized_dice_coeff: 0.8884 - val_loss: 1.2604 - val_generalized_dice_coeff: 0.8771\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.25314\n",
      "Epoch 7/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 1.0949 - generalized_dice_coeff: 0.8905 - val_loss: 1.2503 - val_generalized_dice_coeff: 0.8744\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.25314 to 1.25031, saving model to ./result/01_2class_borderSegTest/best_weights.h5\n",
      "Epoch 8/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 1.0860 - generalized_dice_coeff: 0.8913 - val_loss: 1.2372 - val_generalized_dice_coeff: 0.8953\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.25031 to 1.23719, saving model to ./result/01_2class_borderSegTest/best_weights.h5\n",
      "Epoch 9/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 1.0776 - generalized_dice_coeff: 0.8926 - val_loss: 1.2510 - val_generalized_dice_coeff: 0.9003\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.23719\n",
      "Epoch 10/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 1.0674 - generalized_dice_coeff: 0.8936 - val_loss: 1.2905 - val_generalized_dice_coeff: 0.8658\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.23719\n",
      "Epoch 11/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 1.0581 - generalized_dice_coeff: 0.8941 - val_loss: 1.2608 - val_generalized_dice_coeff: 0.8953\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.23719\n",
      "Epoch 12/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 1.0480 - generalized_dice_coeff: 0.8950 - val_loss: 1.2545 - val_generalized_dice_coeff: 0.8774\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.23719\n",
      "Epoch 13/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 1.0369 - generalized_dice_coeff: 0.8959 - val_loss: 1.2637 - val_generalized_dice_coeff: 0.9036\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.23719\n",
      "Epoch 14/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 1.0281 - generalized_dice_coeff: 0.8974 - val_loss: 1.2560 - val_generalized_dice_coeff: 0.9062\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.23719\n",
      "Epoch 15/50\n",
      "80000/80000 [==============================] - 615s 8ms/step - loss: 1.0155 - generalized_dice_coeff: 0.8982 - val_loss: 1.2876 - val_generalized_dice_coeff: 0.8743\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.23719\n",
      "Epoch 16/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 1.0072 - generalized_dice_coeff: 0.8989 - val_loss: 1.3402 - val_generalized_dice_coeff: 0.8519\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.23719\n",
      "Epoch 17/50\n",
      "80000/80000 [==============================] - 615s 8ms/step - loss: 1.0007 - generalized_dice_coeff: 0.8995 - val_loss: 1.2556 - val_generalized_dice_coeff: 0.9004\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.23719\n",
      "Epoch 18/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 0.9850 - generalized_dice_coeff: 0.9003 - val_loss: 1.2868 - val_generalized_dice_coeff: 0.8805\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.23719\n",
      "Epoch 19/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.9769 - generalized_dice_coeff: 0.9013 - val_loss: 1.3185 - val_generalized_dice_coeff: 0.9079\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.23719\n",
      "Epoch 20/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.9677 - generalized_dice_coeff: 0.9023 - val_loss: 1.3511 - val_generalized_dice_coeff: 0.9221\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.23719\n",
      "Epoch 21/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.9555 - generalized_dice_coeff: 0.9032 - val_loss: 1.3120 - val_generalized_dice_coeff: 0.9119\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.23719\n",
      "Epoch 22/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 0.9468 - generalized_dice_coeff: 0.9044 - val_loss: 1.3141 - val_generalized_dice_coeff: 0.9034\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.23719\n",
      "Epoch 23/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.9324 - generalized_dice_coeff: 0.9052 - val_loss: 1.3596 - val_generalized_dice_coeff: 0.8719\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.23719\n",
      "Epoch 24/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.9190 - generalized_dice_coeff: 0.9069 - val_loss: 1.3382 - val_generalized_dice_coeff: 0.9080\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.23719\n",
      "Epoch 25/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 0.9081 - generalized_dice_coeff: 0.9080 - val_loss: 1.4033 - val_generalized_dice_coeff: 0.9233\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.23719\n",
      "Epoch 26/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.8944 - generalized_dice_coeff: 0.9086 - val_loss: 1.3916 - val_generalized_dice_coeff: 0.9062\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.23719\n",
      "Epoch 27/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 0.8815 - generalized_dice_coeff: 0.9104 - val_loss: 1.4260 - val_generalized_dice_coeff: 0.8788\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.23719\n",
      "Epoch 28/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.8689 - generalized_dice_coeff: 0.9112 - val_loss: 1.4246 - val_generalized_dice_coeff: 0.9213\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.23719\n",
      "Epoch 29/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.8536 - generalized_dice_coeff: 0.9125 - val_loss: 1.4730 - val_generalized_dice_coeff: 0.9240\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.23719\n",
      "Epoch 30/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 0.8332 - generalized_dice_coeff: 0.9141 - val_loss: 1.4817 - val_generalized_dice_coeff: 0.8737\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.23719\n",
      "Epoch 31/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.8193 - generalized_dice_coeff: 0.9150 - val_loss: 1.6441 - val_generalized_dice_coeff: 0.9334\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.23719\n",
      "Epoch 32/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.8076 - generalized_dice_coeff: 0.9166 - val_loss: 1.5579 - val_generalized_dice_coeff: 0.9284\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.23719\n",
      "Epoch 33/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 0.7955 - generalized_dice_coeff: 0.9173 - val_loss: 1.5311 - val_generalized_dice_coeff: 0.9279\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.23719\n",
      "Epoch 34/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.7852 - generalized_dice_coeff: 0.9180 - val_loss: 1.4906 - val_generalized_dice_coeff: 0.8933\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.23719\n",
      "Epoch 35/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.7718 - generalized_dice_coeff: 0.9200 - val_loss: 1.5426 - val_generalized_dice_coeff: 0.9063\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.23719\n",
      "Epoch 36/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 0.7605 - generalized_dice_coeff: 0.9206 - val_loss: 1.5251 - val_generalized_dice_coeff: 0.9153\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.23719\n",
      "Epoch 37/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.7508 - generalized_dice_coeff: 0.9218 - val_loss: 1.6387 - val_generalized_dice_coeff: 0.9364\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.23719\n",
      "Epoch 38/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.7348 - generalized_dice_coeff: 0.9236 - val_loss: 1.5488 - val_generalized_dice_coeff: 0.9075\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.23719\n",
      "Epoch 39/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 0.7266 - generalized_dice_coeff: 0.9247 - val_loss: 1.7729 - val_generalized_dice_coeff: 0.9421\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.23719\n",
      "Epoch 40/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.7173 - generalized_dice_coeff: 0.9257 - val_loss: 1.6163 - val_generalized_dice_coeff: 0.9027\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.23719\n",
      "Epoch 41/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.7061 - generalized_dice_coeff: 0.9267 - val_loss: 1.6845 - val_generalized_dice_coeff: 0.9311\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.23719\n",
      "Epoch 42/50\n",
      "80000/80000 [==============================] - 616s 8ms/step - loss: 0.6976 - generalized_dice_coeff: 0.9281 - val_loss: 1.5959 - val_generalized_dice_coeff: 0.9078\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.23719\n",
      "Epoch 43/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.6854 - generalized_dice_coeff: 0.9292 - val_loss: 1.6602 - val_generalized_dice_coeff: 0.9263\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.23719\n",
      "Epoch 44/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.6746 - generalized_dice_coeff: 0.9302 - val_loss: 1.6684 - val_generalized_dice_coeff: 0.9202\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.23719\n",
      "Epoch 45/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.6693 - generalized_dice_coeff: 0.9312 - val_loss: 1.7332 - val_generalized_dice_coeff: 0.9340\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.23719\n",
      "Epoch 46/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 0.6584 - generalized_dice_coeff: 0.9323 - val_loss: 1.7866 - val_generalized_dice_coeff: 0.9301\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.23719\n",
      "Epoch 47/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.6520 - generalized_dice_coeff: 0.9333 - val_loss: 2.0005 - val_generalized_dice_coeff: 0.8340\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.23719\n",
      "Epoch 48/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 0.6404 - generalized_dice_coeff: 0.9345 - val_loss: 1.7087 - val_generalized_dice_coeff: 0.9090\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.23719\n",
      "Epoch 49/50\n",
      "80000/80000 [==============================] - 618s 8ms/step - loss: 0.6322 - generalized_dice_coeff: 0.9359 - val_loss: 1.8159 - val_generalized_dice_coeff: 0.9390\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.23719\n",
      "Epoch 50/50\n",
      "80000/80000 [==============================] - 617s 8ms/step - loss: 0.6199 - generalized_dice_coeff: 0.9370 - val_loss: 2.0488 - val_generalized_dice_coeff: 0.9412\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.23719\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "[WARNING] ./result/01_2class_borderSegTest/last_weights.h5 already exists - overwrite? [y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIP] Next time specify overwrite=True!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    history = model.fit(patches_imgs_train, patches_masks_train, epochs=num_epochs, batch_size=batch_size, verbose=1, shuffle=True, validation_split=0.2, callbacks=[checkpointer])\n",
    "    model.save_weights('./'+save_folder+'/'+name_experiment +'/last_weights.h5', overwrite=False)\n",
    "except KeyboardInterrupt:\n",
    "    model.save_weights('./'+save_folder+'/'+name_experiment +'/last_weights.h5', overwrite=False)\n",
    "    print('Keyboard Interrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(patches_imgs_train, patches_masks_train, epochs=num_epochs, batch_size=batch_size, verbose=1, shuffle=True, validation_split=0.2, callbacks=[checkpointer])\n",
    "model.save_weights('./'+save_folder+'/'+name_experiment +'/last_weights.h5', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Keras provides a set of functions called callbacks: \n",
    "you can think of callbacks as events that will be triggered at certain training states. \n",
    "The callback we need for checkpointing is the ModelCheckpoint \n",
    "which provides all the features we need according to the checkpointing strategy we adopted in our example\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='./'+save_folder+'/'+name_experiment+'/best_weights.h5', verbose=1, monitor='val_loss', mode='auto', save_best_only=True) #save at each epoch if the validation decreased\n",
    "\n",
    "print('[training session] before mask unet func patch mask shape : ',patches_masks_train.shape)\n",
    "patches_masks_train = masks_Unet(patches_masks_train)  #reduce memory consumption\n",
    "print('[training session] after mask unet func patch mask shape : ',patches_masks_train.shape)\n",
    "\n",
    "#print(len(x_train))\n",
    "history = model.fit_generator(data_gen.flow(patches_imgs_train,patches_masks_train,batch_size=batch_size,subset='training'), \n",
    "                              steps_per_epoch=len(patches_imgs_train)/batch_size,epochs=num_epochs, verbose=1,shuffle=True, callbacks=[checkpointer],\n",
    "                             validation_data = data_gen.flow(patches_imgs_train,patches_masks_train,batch_size=batch_size,subset='validation'),\n",
    "                             validation_steps = 10)\n",
    "model.save_weights('./'+save_folder+'/'+name_experiment +'/last_weights.h5', overwrite=True) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['generalized_dice_coeff', 'val_generalized_dice_coeff', 'val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist the folder in this path : ./result/01_2class_borderSegTest/train_history\n",
      "already exist the folder in this path : ./result/01_2class_borderSegTest/train_history\n",
      "already exist the folder in this path : ./result/01_2class_borderSegTest/train_history\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss= history.history['val_loss']\n",
    "acc = history.history['generalized_dice_coeff']\n",
    "val_acc = history.history['val_generalized_dice_coeff']\n",
    "\n",
    "epochs = range(1,len(acc) +1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label = \"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('./'+save_folder+'/'+name_experiment+\"/training_loss_result.png\")\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label = \"Training generalized_dice_coeff\")\n",
    "plt.plot(epochs, val_acc, 'r', label = \"Validation generalized_dice_coeff\")\n",
    "plt.title(\"Training and Validation dice coef\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig('./'+save_folder+'/'+name_experiment+\"/training_acc_result.png\")\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "file_path = './'+save_folder+'/'+name_experiment + '/' + 'train_history'\n",
    "\n",
    "def save_history_txt_csv(history, file_path, file_name):\n",
    "    if os.path.isdir(file_path) == False:\n",
    "        os.mkdir(file_path)\n",
    "    else:\n",
    "        print('already exist the folder in this path : {}'.format(file_path))\n",
    "    \n",
    "    hist_df = pd.DataFrame(history) \n",
    "\n",
    "    # save to json:  \n",
    "    hist_json_file = file_path + '/' + file_name +'.json' \n",
    "    with open(hist_json_file, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "\n",
    "    # or save to csv: \n",
    "    hist_csv_file = file_path + '/' + file_name + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "\n",
    "save_history_txt_csv(loss, file_path, 'train_loss')\n",
    "save_history_txt_csv(val_loss, file_path, 'val_loss')\n",
    "save_history_txt_csv(acc, file_path, 'train_acc')\n",
    "save_history_txt_csv(val_acc, file_path, 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = './'+save_folder+'/'+name_experiment + '/' + 'train_history'\n",
    "\n",
    "def save_history_txt_csv(history, file_path, file_name):\n",
    "    if os.path.isdir(file_path) == False:\n",
    "        os.mkdir(file_path)\n",
    "    else:\n",
    "        print('already exist the folder in this path : {}'.format(file_path))\n",
    "    \n",
    "    hist_df = pd.DataFrame(history) \n",
    "\n",
    "    # save to json:  \n",
    "    hist_json_file = file_path + '/' + file_name +'.json' \n",
    "    with open(hist_json_file, mode='w') as f:\n",
    "        hist_df.to_json(f)\n",
    "\n",
    "    # or save to csv: \n",
    "    hist_csv_file = file_path + '/' + file_name + '.csv'\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "        \n",
    "\n",
    "save_history_txt_csv(loss, file_path, 'train_loss')\n",
    "save_history_txt_csv(val_loss, file_path, 'val_loss')\n",
    "save_history_txt_csv(acc, file_path, 'train_acc')\n",
    "save_history_txt_csv(val_acc, file_path, 'val_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss= history.history['val_loss']\n",
    "acc = history.history['dice_coef']\n",
    "val_acc = history.history['val_dice_coef']\n",
    "\n",
    "epochs = range(1,len(acc) +1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = \"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label = \"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('./'+save_folder+'/'+name_experiment+\"/training_loss_result.png\")\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'ro', label = \"Training dice coef\")\n",
    "plt.plot(epochs, val_acc, 'r', label = \"Validation dice coef\")\n",
    "plt.title(\"Training and Validation dice coef\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig('./'+save_folder+'/'+name_experiment+\"/training_acc_result.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
